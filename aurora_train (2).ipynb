{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /datasets/aurora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIcWnWHS6aUa",
    "outputId": "93577fbb-3835-4855-88e2-90a327fb92c4",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch==2.5.0\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.0-cp310-cp310-linux_aarch64.whl (2359.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 GB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting torchvision==0.20.0\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.0-cp310-cp310-linux_aarch64.whl (19.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m130.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting torchaudio==2.5.0\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.0-cp310-cp310-linux_aarch64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch==2.5.0) (3.6.0)\n",
      "Requirement already satisfied: fsspec in /usr/lib/python3/dist-packages (from torch==2.5.0) (2024.3.1)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch==2.5.0) (2.4)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch==2.5.0) (3.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/lib/python3/dist-packages (from torch==2.5.0) (4.9.0)\n",
      "Collecting sympy==1.13.1\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m174.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision==0.20.0) (9.0.1)\n",
      "Collecting numpy\n",
      "  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (14.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m226.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: mpmath, sympy, numpy, torch, torchvision, torchaudio\n",
      "Successfully installed mpmath-1.3.0 numpy-1.26.3 sympy-1.13.1 torch-2.5.0 torchaudio-2.5.0 torchvision-0.20.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting cdsapi\n",
      "  Downloading cdsapi-0.7.5-py2.py3-none-any.whl (12 kB)\n",
      "Collecting dask\n",
      "  Downloading dask-2024.12.1-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting xarray\n",
      "  Downloading xarray-2025.1.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m159.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting netcdf4\n",
      "  Downloading netCDF4-1.7.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (9.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m159.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (8.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m155.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting microsoft-aurora\n",
      "  Downloading microsoft_aurora-1.4.1-py3-none-any.whl (187 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.1/187.1 KB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.35.97-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 KB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting awscli\n",
      "  Downloading awscli-1.36.38-py3-none-any.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m214.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: requests>=2.5.0 in /usr/lib/python3/dist-packages (from cdsapi) (2.25.1)\n",
      "Collecting datapi\n",
      "  Downloading datapi-0.1.2-py3-none-any.whl (26 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting click>=8.1\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 KB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting partd>=1.4.0\n",
      "  Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from dask) (21.3)\n",
      "Collecting importlib_metadata>=4.13.0\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting cloudpickle>=3.0.0\n",
      "  Downloading cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /usr/lib/python3/dist-packages (from dask) (2024.3.1)\n",
      "Collecting toolz>=0.10.0\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 KB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.3.1 in /usr/lib/python3/dist-packages (from dask) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.24 in /home/ubuntu/.local/lib/python3.10/site-packages (from xarray) (1.26.3)\n",
      "Collecting pandas>=2.1\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (66.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /usr/lib/python3/dist-packages (from netcdf4) (2020.6.20)\n",
      "Collecting cftime\n",
      "  Downloading cftime-1.6.4.post1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m135.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.55.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m165.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (312 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.0/312.0 KB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: torch in /home/ubuntu/.local/lib/python3.10/site-packages (from microsoft-aurora) (2.5.0)\n",
      "Collecting timm==0.6.13\n",
      "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m170.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 KB\u001b[0m \u001b[31m153.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (38.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: einops in /usr/lib/python3/dist-packages (from microsoft-aurora) (0.8.0)\n",
      "Requirement already satisfied: torchvision in /home/ubuntu/.local/lib/python3.10/site-packages (from timm==0.6.13->microsoft-aurora) (0.20.0)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0\n",
      "  Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 KB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting botocore<1.36.0,>=1.35.97\n",
      "  Downloading botocore-1.35.97-py3-none-any.whl (13.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m235.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Collecting docutils<0.17,>=0.10\n",
      "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 KB\u001b[0m \u001b[31m142.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting rsa<4.8,>=3.1.2\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in /usr/lib/python3/dist-packages (from awscli) (0.4.4)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/lib/python3/dist-packages (from botocore<1.36.0,>=1.35.97->boto3) (1.26.5)\n",
      "Collecting zipp>=3.20\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=2.1->xarray) (2022.1)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 KB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Collecting python-dateutil>=2.7\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 KB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting locket\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.4.8)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch->microsoft-aurora) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch->microsoft-aurora) (2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/lib/python3/dist-packages (from torch->microsoft-aurora) (4.9.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch->microsoft-aurora) (3.0.3)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch->microsoft-aurora) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch->microsoft-aurora) (1.3.0)\n",
      "Collecting multiurl>=0.3.2\n",
      "  Downloading multiurl-0.3.3.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs in /usr/lib/python3/dist-packages (from datapi->cdsapi) (21.2.0)\n",
      "Building wheels for collected packages: multiurl\n",
      "  Building wheel for multiurl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multiurl: filename=multiurl-0.3.3-py3-none-any.whl size=21245 sha256=ba62b218d15f4bb377564aa2b10e680ef051a7cc2932d0f7294beed214d6c07e\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/be/05/e0/65a6edb0a000498aeaefbadd80228bf5ed1bdbb82840ca1692\n",
      "Successfully built multiurl\n",
      "Installing collected packages: zipp, tzdata, tqdm, toolz, scipy, rsa, python-dateutil, packaging, locket, jmespath, fonttools, docutils, contourpy, cloudpickle, click, cftime, partd, pandas, netcdf4, multiurl, matplotlib, importlib_metadata, huggingface-hub, botocore, xarray, s3transfer, datapi, dask, timm, cdsapi, boto3, awscli, microsoft-aurora\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pipx 1.0.0 requires argcomplete>=1.9.4, but you have argcomplete 1.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed awscli-1.36.38 boto3-1.35.97 botocore-1.35.97 cdsapi-0.7.5 cftime-1.6.4.post1 click-8.1.8 cloudpickle-3.1.0 contourpy-1.3.1 dask-2024.12.1 datapi-0.1.2 docutils-0.16 fonttools-4.55.3 huggingface-hub-0.27.1 importlib_metadata-8.5.0 jmespath-1.0.1 locket-1.0.0 matplotlib-3.10.0 microsoft-aurora-1.4.1 multiurl-0.3.3 netcdf4-1.7.2 packaging-24.2 pandas-2.2.3 partd-1.4.2 python-dateutil-2.9.0.post0 rsa-4.7.2 s3transfer-0.10.4 scipy-1.15.1 timm-0.6.13 toolz-1.0.0 tqdm-4.67.1 tzdata-2024.2 xarray-2025.1.1 zipp-3.21.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (12.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/lib/python3/dist-packages (from scikit-learn) (3.1.0)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 KB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.3)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1\n"
     ]
    }
   ],
   "source": [
    "!sudo apt remove -y python3-numpy python3-scipy\n",
    "!pip install torch==2.5.0 torchvision==0.20.0 torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install cdsapi dask xarray netcdf4 matplotlib microsoft-aurora boto3 awscli\n",
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
    "!pip install scikit-learn\n",
    "!git config --global --add safe.directory /home/ubuntu/globfire-gooddata\n",
    "# !pip install --upgrade numpy scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tthe next two boxes are used for using aws cli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-cli/1.36.22 Python/3.10.12 Linux/6.8.0-1013-nvidia-64k botocore/1.35.81\n"
     ]
    }
   ],
   "source": [
    "!aws --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see awsid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "from aurora import Batch, Metadata\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "import io\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from aurora import Aurora\n",
    "from aurora.normalisation import locations, scales\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import gc\n",
    "# from netCDF4 import Dataset\n",
    "# import h5py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# see awsid for missing line\n",
    "\n",
    "# bucket_name = 'globfire-gooddata'\n",
    "# compression_settings = {'zlib': True, 'complevel': 3}\n",
    "\n",
    "# surf_comb = xr.open_mfdataset(surf_files, combine='nested')\n",
    "# encoding_surf = {var: compression_settings for var in surf_comb.data_vars}\n",
    "# surf_comb.to_netcdf(\"surf_comb.nc\", encoding=encoding_surf)\n",
    "# s3.upload_file(\"surf_comb.nc\", bucket_name, \"surf_comb.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code for joinging 3 days worth of data together to feed into aurora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_path = \"datasets/aurora\"\n",
    "surf_path = f\"../{download_path}/fle\"\n",
    "atmos_path = f\"../{download_path}/atmospheric\"\n",
    "\n",
    "static_vars_ds = xr.open_dataset(f\"../{download_path}/static/static.nc\", engine=\"netcdf4\")\n",
    "atmos_files = glob.glob(f\"../{download_path}/atmospheric/*/*.nc\") \n",
    "atmos_files_2021 = [f for f in atmos_files if int(f.split('/')[-2]) <= 202112]\n",
    "surf_files = glob.glob(f\"../{download_path}/fle/*.nc\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "starty = 2015     ## start of 2015 to end of 2021\n",
    "endy = 2021           \n",
    "date_range = pd.date_range(start=f'{starty}-01-01', end=f'{endy}-12-31', freq='D')\n",
    "\n",
    "download_path = \"datasets/aurora\"\n",
    "surf_path = f\"../{download_path}/fle\"\n",
    "atmos_path = f\"../{download_path}/atmospheric\"\n",
    "\n",
    "atmos_files = glob.glob(f\"../{download_path}/atmospheric/*/*.nc\") \n",
    "# atmos_files = glob.glob(f\"../{download_path}/atmospheric/(201[0-9][0-9]{2}|202(0|1)[0-9]{2})/*.nc\")  \n",
    "atmos_files_2021 = [f for f in atmos_files if int(f.split('/')[-2]) <= 202112]\n",
    "surf_files = glob.glob(f\"../{download_path}/fle/*.nc\") \n",
    "\n",
    "\n",
    "days = 3\n",
    "\n",
    "# ./datasets/aurora/atmospheric/201501/atmospheric_20150111.nc'\n",
    "#../datasets/aurora/fle/surf_2021-11-17.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "date_range[i:i + days]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## basic one day batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data loading:   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'atmos_files_2021' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6270/3452403814.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msurf_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34mrf\".*/surf_{date_window[day].strftime('%Y-%m-%d')}\\.nc$\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0matmos_filt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0matmos_files_2021\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0matmos_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0msurf_filt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msurf_files\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msurf_regex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'atmos_files_2021' is not defined"
     ]
    }
   ],
   "source": [
    "variables_to_keep = ['u10', 'v10', 't2m', 'msl', 'lst', 'fire']\n",
    "date_range = pd.date_range(start=f'{2015}-01-01', end=f'{2015}-1-03', freq='D')\n",
    "days = 1\n",
    "for i in tqdm(range(len(date_range) - days + 1), desc = \"data loading\"):\n",
    "    date_window = date_range[i:i + days]\n",
    "    \n",
    "    atmos_regex = []\n",
    "    surf_regex = []\n",
    "    for day in range(days):\n",
    "        atmos_regex.append( re.compile( rf\".*/{date_window[day].strftime('%Y%m')}/atmospheric_{date_window[day].strftime('%Y%m%d')}\\.nc$\"))\n",
    "        surf_regex.append( re.compile( rf\".*/surf_{date_window[day].strftime('%Y-%m-%d')}\\.nc$\"))\n",
    "    \n",
    "    atmos_filt = [f for f in atmos_files_2021 if any(d.match(f) for d in atmos_regex)]\n",
    "    surf_filt = [f for f in surf_files if any(d.match(f) for d in surf_regex)]\n",
    "\n",
    "    print(atmos_filt)\n",
    "    print(surf_filt)\n",
    "    \n",
    "    \n",
    "    atmos_list = []\n",
    "    surf_list = []\n",
    "    \n",
    "    for day in range(len(atmos_filt)):\n",
    "        atmos_cur = xr.open_dataset(atmos_filt[day])\n",
    "        surf_cur = xr.open_dataset(surf_filt[day])\n",
    "        \n",
    "        # code for dropping variables. makes code run slower. interpolation so fast that it doest matter. \n",
    "        surf_cur = surf_cur.drop_vars([var for var in surf_cur.data_vars if var not in variables_to_keep])\n",
    "\n",
    "        atmos_list.append(atmos_cur)\n",
    "        surf_list.append(surf_cur)\n",
    "    \n",
    "    atmos_comb = xr.concat(atmos_list, dim=\"valid_time\")\n",
    "    surf_comb = xr.concat(surf_list, dim=\"valid_time\")\n",
    "    \n",
    "static_vars_ds = xr.open_dataset(f\"../{download_path}/static/static.nc\", engine=\"netcdf4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PwqH22r8h8L",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "i = 1  # Select this time index in the downloaded data.\n",
    "\n",
    "batch = Batch(\n",
    "    surf_vars={\n",
    "        # First select time points `i` and `i - 1`. Afterwards, `[None]` inserts a\n",
    "        # batch dimension of size one.\n",
    "        \"2t\": torch.from_numpy(surf_comb[\"t2m\"].values[[i - 1, i]][None]),\n",
    "        \"10u\": torch.from_numpy(surf_comb[\"u10\"].values[[i - 1, i]][None]),\n",
    "        \"10v\": torch.from_numpy(surf_comb[\"v10\"].values[[i - 1, i]][None]),\n",
    "        \"msl\": torch.from_numpy(surf_comb[\"msl\"].values[[i - 1, i]][None]),\n",
    "        \"fire\": torch.from_numpy(surf_comb[\"fire\"].values[[i - 1, i]][None]),\n",
    "        \"lst\": torch.from_numpy(surf_comb[\"lst\"].values[[i - 1, i]][None]),\n",
    "    },\n",
    "    static_vars={\n",
    "        # The static variables are constant, so we just get them for the first time.\n",
    "        \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "        \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "        \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "    },\n",
    "    atmos_vars={\n",
    "        \"t\": torch.from_numpy(atmos_comb[\"t\"].values[[i - 1, i]][None]),\n",
    "        \"u\": torch.from_numpy(atmos_comb[\"u\"].values[[i - 1, i]][None]),\n",
    "        \"v\": torch.from_numpy(atmos_comb[\"v\"].values[[i - 1, i]][None]),\n",
    "        \"q\": torch.from_numpy(atmos_comb[\"q\"].values[[i - 1, i]][None]),\n",
    "        \"z\": torch.from_numpy(atmos_comb[\"z\"].values[[i - 1, i]][None]),\n",
    "    },\n",
    "    metadata=Metadata(\n",
    "        lat=torch.from_numpy(surf_comb.latitude.values),\n",
    "        lon=torch.from_numpy(surf_comb.longitude.values),\n",
    "        # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "        # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "        # one value for every batch element.\n",
    "        time=(surf_comb.valid_time.values.astype(\"datetime64[s]\").tolist()[i],),\n",
    "        atmos_levels=tuple(int(level) for level in atmos_comb.pressure_level.values),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# static_vars_ds = xr.open_dataset(f\"../{download_path}/static/static.nc\", engine=\"netcdf4\")\n",
    "# surf_vars_ds = xr.open_dataset(f\"../{download_path}/fle/surf_2015-01-04.nc\", engine=\"netcdf4\")\n",
    "# atmos_vars_ds = xr.open_dataset(f\"../{download_path}/atmospheric/201501/atmospheric_20150104.nc\", engine=\"netcdf4\")\n",
    "\n",
    "\n",
    "j = i+1  # Select this time index in the downloaded data.\n",
    "\n",
    "surf_size = (720, 1440)\n",
    "atmos_size = (720, 1440)\n",
    "\n",
    "surf_vars={\n",
    "    # First select time points `i` and `i - 1`. Afterwards, `[None]` inserts a\n",
    "    # batch dimension of size one.\n",
    "    \"2t\": torch.from_numpy(surf_comb[\"t2m\"].values[[j]][None]),\n",
    "    \"10u\": torch.from_numpy(surf_comb[\"u10\"].values[[j]][None]),\n",
    "    \"10v\": torch.from_numpy(surf_comb[\"v10\"].values[[j]][None]),\n",
    "    \"msl\": torch.from_numpy(surf_comb[\"msl\"].values[[j]][None]),\n",
    "    \"fire\": torch.from_numpy(surf_comb[\"fire\"].values[[j]][None]),\n",
    "    \"lst\": torch.from_numpy(surf_comb[\"lst\"].values[[j]][None]),\n",
    "}\n",
    "static_vars={\n",
    "    # The static variables are constant, so we just get them for the first time.\n",
    "    \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "    \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "    \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "}\n",
    "atmos_vars={\n",
    "    \"t\": torch.from_numpy(atmos_comb[\"t\"].values[[j]][None]),\n",
    "    \"u\": torch.from_numpy(atmos_comb[\"u\"].values[[j]][None]),\n",
    "    \"v\": torch.from_numpy(atmos_comb[\"v\"].values[[j]][None]),\n",
    "    \"q\": torch.from_numpy(atmos_comb[\"q\"].values[[j]][None]),\n",
    "    \"z\": torch.from_numpy(atmos_comb[\"z\"].values[[j]][None]),\n",
    "}\n",
    "\n",
    "output_size = (720, 1440)\n",
    "\n",
    "interpolated_surf_vars = {\n",
    "    key: F.interpolate(value, size=surf_size, mode='bilinear', align_corners=False)\n",
    "    for key, value in surf_vars.items()\n",
    "}\n",
    "\n",
    "interpolated_atmos_vars = {\n",
    "    key: F.interpolate(value.view(-1, 1, 721, 1440), size=atmos_size, mode='bilinear', align_corners=False).view(value.shape[0], value.shape[1], value.shape[2], 720, 1440)\n",
    "    for key, value in atmos_vars.items()\n",
    "}\n",
    "\n",
    "interpolated_static_vars = {\n",
    "    key: F.interpolate(value.unsqueeze(0).unsqueeze(0), size=output_size, mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "    for key, value in static_vars.items()\n",
    "}\n",
    "\n",
    "\n",
    "batch2 = Batch(\n",
    "    surf_vars = interpolated_surf_vars,\n",
    "    static_vars=interpolated_static_vars,\n",
    "    atmos_vars=interpolated_atmos_vars,\n",
    "    metadata=Metadata(\n",
    "        lat=torch.from_numpy(surf_comb.latitude.values),\n",
    "        lon=torch.from_numpy(surf_comb.longitude.values),\n",
    "        # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "        # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "        # one value for every batch element.\n",
    "        time=(surf_comb.valid_time.values.astype(\"datetime64[s]\").tolist()[i],),\n",
    "        atmos_levels=tuple(int(level) for level in atmos_comb.pressure_level.values),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## convert to dataset and dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# using surf_comb is not the best solution\n",
    "# lstdata = torch.from_numpy(surf_comb[\"lst\"].values[[i - 1, i]][None])\n",
    "# Normalisation means:\n",
    "locations[\"fire\"] = 0.0\n",
    "locations[\"lst\"] = 11484.10859\n",
    "\n",
    "# Normalisation standard deviations:\n",
    "scales[\"fire\"] = 1.0\n",
    "scales[\"lst\"] = 8109.33224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_retreive ( atmos_files, surf_files, date_range, days, idx , variables_to_keep = None ):\n",
    "    date_window = date_range[idx:idx + days]\n",
    "\n",
    "    atmos_regex = []\n",
    "    surf_regex = []\n",
    "    for day in range(days):\n",
    "        atmos_regex.append( re.compile( rf\".*/{date_window[day].strftime('%Y%m')}/atmospheric_{date_window[day].strftime('%Y%m%d')}\\.nc$\"))\n",
    "        surf_regex.append( re.compile( rf\".*/surf_{date_window[day].strftime('%Y-%m-%d')}\\.nc$\"))\n",
    "\n",
    "    atmos_filt = [f for f in atmos_files if any(d.match(f) for d in atmos_regex)]\n",
    "    surf_filt = [f for f in surf_files if any(d.match(f) for d in surf_regex)]\n",
    "    atmos_list = []\n",
    "    surf_list = []\n",
    "\n",
    "    for day in range(len(atmos_filt)):\n",
    "        with xr.open_dataset(atmos_filt[day])as atmos_cur, xr.open_dataset(surf_filt[day]) as surf_cur :\n",
    "\n",
    "            # code for dropping variables. makes code run slower. interpolation so fast that it doest matter. \n",
    "            if variables_to_keep is not None:\n",
    "                surf_cur = surf_cur.drop_vars([var for var in surf_cur.data_vars if var not in variables_to_keep])\n",
    "\n",
    "            atmos_list.append(atmos_cur.load())\n",
    "            surf_list.append(surf_cur.load())\n",
    "\n",
    "    atmos_comb = xr.concat(atmos_list, dim=\"valid_time\")\n",
    "    surf_comb = xr.concat(surf_list, dim=\"valid_time\")\n",
    "    return atmos_comb, surf_comb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_label_batch(atmos_comb, surf_comb, static, interpolated_static_vars):\n",
    "    i = 1  \n",
    "    batch = Batch(\n",
    "        surf_vars={\n",
    "            # First select time points `i` and `i - 1`. Afterwards, `[None]` inserts a\n",
    "            # batch dimension of size one.\n",
    "            \"2t\": torch.from_numpy(surf_comb[\"t2m\"].values[[i - 1, i]][None]),\n",
    "            \"10u\": torch.from_numpy(surf_comb[\"u10\"].values[[i - 1, i]][None]),\n",
    "            \"10v\": torch.from_numpy(surf_comb[\"v10\"].values[[i - 1, i]][None]),\n",
    "            \"msl\": torch.from_numpy(surf_comb[\"msl\"].values[[i - 1, i]][None]),\n",
    "            \"fire\": torch.from_numpy(surf_comb[\"fire\"].values[[i - 1, i]][None]),\n",
    "            \"lst\": torch.from_numpy(surf_comb[\"lst\"].values[[i - 1, i]][None]),\n",
    "        },\n",
    "        # static_vars={\n",
    "        #     # The static variables are constant, so we just get them for the first time.\n",
    "        #     \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "        #     \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "        #     \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "        # },\n",
    "        static_vars=static ,\n",
    "        atmos_vars={\n",
    "            \"t\": torch.from_numpy(atmos_comb[\"t\"].values[[i - 1, i]][None]),\n",
    "            \"u\": torch.from_numpy(atmos_comb[\"u\"].values[[i - 1, i]][None]),\n",
    "            \"v\": torch.from_numpy(atmos_comb[\"v\"].values[[i - 1, i]][None]),\n",
    "            \"q\": torch.from_numpy(atmos_comb[\"q\"].values[[i - 1, i]][None]),\n",
    "            \"z\": torch.from_numpy(atmos_comb[\"z\"].values[[i - 1, i]][None]),\n",
    "        },\n",
    "        metadata=Metadata(\n",
    "            lat=torch.from_numpy(surf_comb.latitude.values),\n",
    "            lon=torch.from_numpy(surf_comb.longitude.values),\n",
    "            # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "            # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "            # one value for every batch element.\n",
    "            time=(surf_comb.valid_time.values.astype(\"datetime64[s]\").tolist()[i],),\n",
    "            atmos_levels=tuple(int(level) for level in atmos_comb.pressure_level.values),\n",
    "        )\n",
    "        # metadata=metadata\n",
    "    )\n",
    "    \n",
    "    j = 2  # Select this time index in the downloaded data.\n",
    "\n",
    "    surf_size = (720, 1440)\n",
    "    atmos_size = (720, 1440)\n",
    "\n",
    "    surf_vars={\n",
    "        # First select time points `i` and `i - 1`. Afterwards, `[None]` inserts a\n",
    "        # batch dimension of size one.\n",
    "        \"2t\": torch.from_numpy(surf_comb[\"t2m\"].values[[j]][None]),\n",
    "        \"10u\": torch.from_numpy(surf_comb[\"u10\"].values[[j]][None]),\n",
    "        \"10v\": torch.from_numpy(surf_comb[\"v10\"].values[[j]][None]),\n",
    "        \"msl\": torch.from_numpy(surf_comb[\"msl\"].values[[j]][None]),\n",
    "        \"fire\": torch.from_numpy(surf_comb[\"fire\"].values[[j]][None]),\n",
    "        # ************** Comment out LST\n",
    "        \"lst\": torch.from_numpy(surf_comb[\"lst\"].values[[j]][None]),\n",
    "    }\n",
    "    # static_vars={\n",
    "    #     # The static variables are constant, so we just get them for the first time.\n",
    "    #     \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "    #     \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "    #     \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "    # }\n",
    "    # static_vars=static \n",
    "    atmos_vars={\n",
    "        \"t\": torch.from_numpy(atmos_comb[\"t\"].values[[j]][None]),\n",
    "        \"u\": torch.from_numpy(atmos_comb[\"u\"].values[[j]][None]),\n",
    "        \"v\": torch.from_numpy(atmos_comb[\"v\"].values[[j]][None]),\n",
    "        \"q\": torch.from_numpy(atmos_comb[\"q\"].values[[j]][None]),\n",
    "        \"z\": torch.from_numpy(atmos_comb[\"z\"].values[[j]][None]),\n",
    "    }\n",
    "\n",
    "    output_size = (720, 1440)\n",
    "\n",
    "    interpolated_surf_vars = {\n",
    "        key: F.interpolate(value, size=surf_size, mode='bilinear', align_corners=False)\n",
    "        for key, value in surf_vars.items()\n",
    "    }\n",
    "\n",
    "    interpolated_atmos_vars = {\n",
    "        key: F.interpolate(value.view(-1, 1, 721, 1440), size=atmos_size, mode='bilinear', align_corners=False).view(value.shape[0], value.shape[1], value.shape[2], 720, 1440)\n",
    "        for key, value in atmos_vars.items()\n",
    "    }\n",
    "\n",
    "    # interpolated_static_vars = {\n",
    "    #     key: F.interpolate(value.unsqueeze(0).unsqueeze(0), size=output_size, mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "    #     for key, value in static_vars.items()\n",
    "    # }\n",
    "\n",
    "\n",
    "    batch2 = Batch(\n",
    "        surf_vars = interpolated_surf_vars,\n",
    "        static_vars=interpolated_static_vars,\n",
    "        atmos_vars=interpolated_atmos_vars,\n",
    "        metadata=Metadata(\n",
    "            lat=torch.from_numpy(surf_comb.latitude.values),\n",
    "            lon=torch.from_numpy(surf_comb.longitude.values),\n",
    "            # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "            # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "            # one value for every batch element.\n",
    "            time=(surf_comb.valid_time.values.astype(\"datetime64[s]\").tolist()[j],),\n",
    "            atmos_levels=tuple(int(level) for level in atmos_comb.pressure_level.values),\n",
    "        ),\n",
    "        # metadata=metadata\n",
    "    )\n",
    "    return batch, batch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AuroraDataset(Dataset):\n",
    "    def __init__(self, download_path, variables_to_keep , starty, endy):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            folder_path (str): Path to the folder containing the daily files.\n",
    "            transform (callable, optional): A function/transform to apply to the data.\n",
    "        \"\"\"\n",
    "        with xr.open_dataset(f\"../{download_path}/static/static.nc\", engine=\"netcdf4\") as static_vars_ds:\n",
    "            self.static={\n",
    "                # The static variables are constant, so we just get them for the first time.\n",
    "                \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "                \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "                \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "            }\n",
    "            self.interp_static = {\n",
    "                key: F.interpolate(value.unsqueeze(0).unsqueeze(0), size=(720, 1440), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "                for key, value in self.static.items()\n",
    "            }\n",
    "        self.atmos_files = glob.glob(f\"../{download_path}/atmospheric/*/*.nc\") \n",
    "        self.surf_files = glob.glob(f\"../{download_path}/fle/*.nc\") \n",
    "        \n",
    "        self.window = 3\n",
    "        self.variables_to_keep = variables_to_keep\n",
    "        \n",
    "        self.date_range = pd.date_range(start=f'{starty}-01-01', end=f'{endy}-12-31', freq='D')\n",
    "        \n",
    "        # self.file_names = sorted(os.listdir(folder_path))  # Sort to ensure correct order\n",
    "        # self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of files (days).\"\"\"\n",
    "        return len(self.surf_files) - self.window + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx (int): Index of the file to load.\n",
    "        Returns:\n",
    "            (Tensor, Tensor): Features and labels for the given day.\n",
    "        \"\"\"\n",
    "#         file_path = os.path.join(self.folder_path, self.file_names[idx])\n",
    "        \n",
    "        #                       \n",
    "        atmos, surf = data_retreive(self.atmos_files, self.surf_files, self.date_range\n",
    "                             , self.window, idx, self.variables_to_keep)\n",
    "        \n",
    "        # metadata=Metadata(\n",
    "        #     lat=torch.from_numpy(surf.latitude.values),\n",
    "        #     lon=torch.from_numpy(surf.longitude.values),\n",
    "        #     # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "        #     # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "        #     # one value for every batch element.\n",
    "        #     time=(surf.valid_time.values.astype(\"datetime64[s]\").tolist()[1],),\n",
    "        #     atmos_levels=tuple(int(level) for level in atmos.pressure_level.values),\n",
    "        # )\n",
    "        # Assuming the last column is the label\n",
    "        features, labels = feature_label_batch(atmos, surf, self.static, self.interp_static)\n",
    "         # = label_batch(atmos, surf, self.interp_static, metadata) # metadata technically wrong for labels\n",
    "\n",
    "        # Convert to tensors\n",
    "        return (\n",
    "            features, labels\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aurora_collate(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for handling Batch objects as features and labels.\n",
    "\n",
    "    Args:\n",
    "        batch (list of tuples): Each tuple contains (features, labels), where\n",
    "                                features and labels are instances of `Batch`.\n",
    "\n",
    "    Returns:\n",
    "        Batched features and labels.\n",
    "    \"\"\"\n",
    "    # Separate features and labels from the batch\n",
    "    features_list, labels_list = zip(*batch)\n",
    "\n",
    "    # Function to batch the variables in each component of the `Batch` object\n",
    "    def collate_batch_components(batch_list, key):\n",
    "        return {\n",
    "            var_key: torch.stack([getattr(b, key)[var_key] for b in batch_list])\n",
    "            for var_key in getattr(batch_list[0], key)}\n",
    "\n",
    "    # Combine `surf_vars` and `atmos_vars` for features and labels\n",
    "    batched_features = Batch(\n",
    "        surf_vars=collate_batch_components(features_list, \"surf_vars\"),\n",
    "        static_vars=collate_batch_components(features_list, \"static_vars\"),\n",
    "        atmos_vars=collate_batch_components(features_list, \"atmos_vars\"),\n",
    "        metadata=Metadata(\n",
    "            lat=torch.stack([f.metadata.lat for f in features_list]),\n",
    "            lon=torch.stack([f.metadata.lon for f in features_list]),\n",
    "            time=[f.metadata.time for f in features_list],\n",
    "            atmos_levels=[f.metadata.atmos_levels for f in features_list],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    batched_labels = Batch(\n",
    "        surf_vars=collate_batch_components(labels_list, \"surf_vars\"),\n",
    "        static_vars=collate_batch_components(features_list, \"static_vars\"),\n",
    "        atmos_vars=collate_batch_components(labels_list, \"atmos_vars\"),\n",
    "        metadata=Metadata(\n",
    "            lat=torch.stack([l.metadata.lat for l in labels_list]),\n",
    "            lon=torch.stack([l.metadata.lon for l in labels_list]),\n",
    "            time=[l.metadata.time for l in labels_list],\n",
    "            atmos_levels=[l.metadata.atmos_levels for l in labels_list],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return features_list[0], labels_list[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run as single block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation means:\n",
    "# locations[\"fire\"] = 0.0\n",
    "# locations[\"lst\"] = 11484.10859\n",
    "\n",
    "# Normalisation standard deviations:\n",
    "# scales[\"fire\"] = 1.0\n",
    "# scales[\"lst\"] = 8109.33224\n",
    "\n",
    "# variables_to_keep = ['u10', 'v10', 't2m', 'msl', 'fire']\n",
    "# variables_to_keep = ['u10', 'v10', 't2m', 'msl', 'lst', 'fire']\n",
    "\n",
    "def data_retreive ( atmos_files, surf_files, date_range, days, idx , variables_to_keep = None ):\n",
    "    date_window = date_range[idx:idx + days]\n",
    "    # print(date_range)\n",
    "    # print(idx)\n",
    "    # print(days)\n",
    "    atmos_regex = []\n",
    "    surf_regex = []\n",
    "    for day in range(days):\n",
    "        # note that no need to look at download path here because its already accounted for when globing inside of aurora dataset\n",
    "        # atmos_regex.append( re.compile( rf\"\\.\\./{download_path}/atmospheric/{date_window[day].strftime('%Y%m')}/atmospheric_{date_window[day].strftime('%Y%m%d')}\\.nc$\"))\n",
    "        # surf_regex.append( re.compile( rf\"\\.\\./{download_path}/fle/surf_{date_window[day].strftime('%Y-%m-%d')}\\.nc$\"))\n",
    "        # atmos_regex.append( re.compile( rf\".*/{download_path}.*/{date_window[day].strftime('%Y%m')}/atmospheric_{date_window[day].strftime('%Y%m%d')}\\.nc$\"))\n",
    "        # surf_regex.append( re.compile( rf\".*/{download_path}.*/surf_{date_window[day].strftime('%Y-%m-%d')}\\.nc$\"))\n",
    "        atmos_regex.append( re.compile( rf\".*/{date_window[day].strftime('%Y%m')}/atmospheric_{date_window[day].strftime('%Y%m%d')}\\.nc$\"))\n",
    "        surf_regex.append( re.compile( rf\".*/surf_{date_window[day].strftime('%Y-%m-%d')}\\.nc$\"))\n",
    "\n",
    "    atmos_filt = [f for f in atmos_files if any(d.match(f) for d in atmos_regex)]\n",
    "    surf_filt = [f for f in surf_files if any(d.match(f) for d in surf_regex)]\n",
    "    atmos_list = []\n",
    "    surf_list = []\n",
    "    # print(atmos_filt)\n",
    "    # print(\"surf\")\n",
    "    # print(surf_filt)\n",
    "    ds = xr.open_dataset(atmos_filt[0]).load()\n",
    "    ds.close()\n",
    "\n",
    "    # for day in range(len(atmos_filt)):\n",
    "    for day in range(days):\n",
    "        # surf_cur = None  # Initialize to None\n",
    "        # atmos_cur = None  # Initialize to None\n",
    "        # print(atmos_filt[day])\n",
    "        # with xr.open_dataset(atmos_filt[day])as atmos_cur, xr.open_dataset(surf_filt[day]) as surf_cur :\n",
    "        # try: \n",
    "        # with xr.open_dataset(atmos_filt[day])as atmos_cur, xr.open_dataset(surf_filt[day]) as surf_cur :\n",
    "        with xr.open_dataset(atmos_filt[day])as atmos_cur, xr.open_dataset(surf_filt[day]) as surf_cur :\n",
    "            # atmos_cur = xr.open_dataset(atmos_filt[day])\n",
    "            # surf_cur = xr.open_dataset(surf_filt[day])\n",
    "        \n",
    "\n",
    "            # code for dropping variables. makes code run slower. interpolation so fast that it doest matter. \n",
    "            if variables_to_keep is not None:\n",
    "                surf_cur = surf_cur.drop_vars([var for var in surf_cur.data_vars if var not in variables_to_keep])\n",
    "\n",
    "            atmos_list.append(atmos_cur.load())\n",
    "            surf_list.append(surf_cur.load())\n",
    "            \n",
    "        # finally: \n",
    "        #     if atmos_cur is not None:\n",
    "        #         atmos_cur.close()\n",
    "        #     if surf_cur is not None:\n",
    "        #         surf_cur.close()\n",
    "\n",
    "    atmos_comb = xr.concat(atmos_list, dim=\"valid_time\")\n",
    "    surf_comb = xr.concat(surf_list, dim=\"valid_time\")\n",
    "    return atmos_comb, surf_comb\n",
    "\n",
    "def feature_label_batch(atmos_comb, surf_comb, static, interpolated_static_vars):\n",
    "    i = 1  \n",
    "    batch = Batch(\n",
    "        surf_vars={\n",
    "            # First select time points `i` and `i - 1`. Afterwards, `[None]` inserts a\n",
    "            # batch dimension of size one.\n",
    "            \"2t\": torch.from_numpy(surf_comb[\"t2m\"].values[[i - 1, i]][None]),\n",
    "            \"10u\": torch.from_numpy(surf_comb[\"u10\"].values[[i - 1, i]][None]),\n",
    "            \"10v\": torch.from_numpy(surf_comb[\"v10\"].values[[i - 1, i]][None]),\n",
    "            \"msl\": torch.from_numpy(surf_comb[\"msl\"].values[[i - 1, i]][None]),\n",
    "            \"fire\": torch.from_numpy(surf_comb[\"fire\"].values[[i - 1, i]][None]),\n",
    "            \"lst\": torch.from_numpy(surf_comb[\"lst\"].values[[i - 1, i]][None]),\n",
    "        },\n",
    "        # static_vars={\n",
    "        #     # The static variables are constant, so we just get them for the first time.\n",
    "        #     \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "        #     \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "        #     \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "        # },\n",
    "        static_vars=static ,\n",
    "        atmos_vars={\n",
    "            \"t\": torch.from_numpy(atmos_comb[\"t\"].values[[i - 1, i]][None]),\n",
    "            \"u\": torch.from_numpy(atmos_comb[\"u\"].values[[i - 1, i]][None]),\n",
    "            \"v\": torch.from_numpy(atmos_comb[\"v\"].values[[i - 1, i]][None]),\n",
    "            \"q\": torch.from_numpy(atmos_comb[\"q\"].values[[i - 1, i]][None]),\n",
    "            \"z\": torch.from_numpy(atmos_comb[\"z\"].values[[i - 1, i]][None]),\n",
    "        },\n",
    "        metadata=Metadata(\n",
    "            lat=torch.from_numpy(surf_comb.latitude.values),\n",
    "            lon=torch.from_numpy(surf_comb.longitude.values),\n",
    "            # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "            # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "            # one value for every batch element.\n",
    "            time=(surf_comb.valid_time.values.astype(\"datetime64[s]\").tolist()[i],),\n",
    "            atmos_levels=tuple(int(level) for level in atmos_comb.pressure_level.values),\n",
    "        )\n",
    "        # metadata=metadata\n",
    "    )\n",
    "    \n",
    "    # print(np.unique(batch.surf_vars[\"fire\"].cpu().numpy()))\n",
    "    \n",
    "    j = 2  # Select this time index in the downloaded data.\n",
    "\n",
    "    surf_size = (720, 1440)\n",
    "    atmos_size = (720, 1440)\n",
    "\n",
    "    surf_vars={\n",
    "        # First select time points `i` and `i - 1`. Afterwards, `[None]` inserts a\n",
    "        # batch dimension of size one.\n",
    "        \"2t\": torch.from_numpy(surf_comb[\"t2m\"].values[[j]][None]),\n",
    "        \"10u\": torch.from_numpy(surf_comb[\"u10\"].values[[j]][None]),\n",
    "        \"10v\": torch.from_numpy(surf_comb[\"v10\"].values[[j]][None]),\n",
    "        \"msl\": torch.from_numpy(surf_comb[\"msl\"].values[[j]][None]),\n",
    "        \"fire\": torch.from_numpy(surf_comb[\"fire\"].values[[j]][None]),\n",
    "        # ************** Comment out LST\n",
    "        \"lst\": torch.from_numpy(surf_comb[\"lst\"].values[[j]][None]),\n",
    "    }\n",
    "    # print(np.unique(surf_vars[\"fire\"].cpu().numpy()))\n",
    "    atmos_vars={\n",
    "        \"t\": torch.from_numpy(atmos_comb[\"t\"].values[[j]][None]),\n",
    "        \"u\": torch.from_numpy(atmos_comb[\"u\"].values[[j]][None]),\n",
    "        \"v\": torch.from_numpy(atmos_comb[\"v\"].values[[j]][None]),\n",
    "        \"q\": torch.from_numpy(atmos_comb[\"q\"].values[[j]][None]),\n",
    "        \"z\": torch.from_numpy(atmos_comb[\"z\"].values[[j]][None]),\n",
    "    }\n",
    "\n",
    "    output_size = (720, 1440)\n",
    "\n",
    "\n",
    "    interpolated_surf_vars = {\n",
    "        key: (F.interpolate(value, size=surf_size, mode='bilinear', align_corners=False) >= 0.5).int()\n",
    "        if key == \"fire\" else  F.interpolate(value, size=surf_size, mode='bilinear', align_corners=False)\n",
    "        for key, value in surf_vars.items()\n",
    "    }\n",
    "\n",
    "    # interpolated_surf_vars = {\n",
    "    #     key: F.interpolate(value, size=surf_size, mode='bilinear', align_corners=False)\n",
    "    #     for key, value in surf_vars.items()\n",
    "    # }\n",
    "\n",
    "    # used to check interpolation having a good cutoff value\n",
    "    # print(surf_vars[\"fire\"].squeeze(0).squeeze(0).shape)\n",
    "    # print(\"before count\", surf_vars[\"fire\"].squeeze(0).squeeze(0).count_nonzero() )\n",
    "    # print(\"after count\", interpolated_surf_vars[\"fire\"].squeeze(0).squeeze(0).count_nonzero() )\n",
    "    \n",
    "    interpolated_atmos_vars = {\n",
    "        key: F.interpolate(value.view(-1, 1, 721, 1440), size=atmos_size, mode='bilinear', align_corners=False).view(value.shape[0], value.shape[1], value.shape[2], 720, 1440)\n",
    "        for key, value in atmos_vars.items()\n",
    "    }\n",
    "\n",
    "    batch2 = Batch(\n",
    "        surf_vars = interpolated_surf_vars,\n",
    "        static_vars=interpolated_static_vars,\n",
    "        atmos_vars=interpolated_atmos_vars,\n",
    "        metadata=Metadata(\n",
    "            lat=torch.from_numpy(surf_comb.latitude.values),\n",
    "            lon=torch.from_numpy(surf_comb.longitude.values),\n",
    "            # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "            # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "            # one value for every batch element.\n",
    "            time=(surf_comb.valid_time.values.astype(\"datetime64[s]\").tolist()[j],),\n",
    "            atmos_levels=tuple(int(level) for level in atmos_comb.pressure_level.values),\n",
    "        ),\n",
    "        # metadata=metadata\n",
    "    )\n",
    "    return batch, batch2\n",
    "\n",
    "class AuroraDataset(Dataset):\n",
    "    def __init__(self, download_path, variables_to_keep , date_range):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            folder_path (str): Path to the folder containing the daily files.\n",
    "            transform (callable, optional): A function/transform to apply to the data.\n",
    "        \"\"\"\n",
    "        # self.sumides = 5\n",
    "        # with xr.open_dataset(f\"../{download_path}/static/static.nc\", engine=\"netcdf4\") as static_vars_ds :\n",
    "        #     # static_vars_ds = pstatic_vars_ds\n",
    "            \n",
    "        #     prestatic={\n",
    "        #         # The static variables are constant, so we just get them for the first time.\n",
    "        #         \"z\": torch.from_numpy(np.copy(static_vars_ds[\"z\"].values[0])),\n",
    "        #         \"slt\": torch.from_numpy(np.copy(static_vars_ds[\"slt\"].values[0])),\n",
    "        #         \"lsm\": torch.from_numpy(np.copy(static_vars_ds[\"lsm\"].values[0])),\n",
    "        #     }\n",
    "        #     # prestatic={\n",
    "        #     #     # The static variables are constant, so we just get them for the first time.\n",
    "        #     #     \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0].copy()),\n",
    "        #     #     \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0].copy()),\n",
    "        #     #     \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0].copy()),\n",
    "        #     # }\n",
    "        #     print(prestatic)\n",
    "        #     self.static= prestatic\n",
    "        #     self.interp_static = {\n",
    "        #         key: F.interpolate(value.unsqueeze(0).unsqueeze(0), size=(720, 1440), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "        #         for key, value in prestatic.items()\n",
    "        #     }\n",
    "\n",
    "        # static_vars_ds = xr.open_dataset(f\"../{download_path}/static/static.nc\", engine=\"netcdf4\")\n",
    "        # static={\n",
    "        #         # The static variables are constant, so we just get them for the first time.\n",
    "        #         \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "        #         \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "        #         \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "        #     }\n",
    "        # self.interp_static = {\n",
    "        #         key: F.interpolate(value.unsqueeze(0).unsqueeze(0), size=(720, 1440), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "        #         for key, value in static.items()\n",
    "        #     }\n",
    "        # static_vars_ds.close()\n",
    "\n",
    "        \n",
    "        with xr.open_dataset(f\"../{download_path}/static/static.nc\", engine=\"netcdf4\") as static_vars_ds:\n",
    "            self.static={\n",
    "                # The static variables are constant, so we just get them for the first time.\n",
    "                \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "                \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "                \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "            }\n",
    "            self.interp_static = {\n",
    "                key: F.interpolate(value.unsqueeze(0).unsqueeze(0), size=(720, 1440), mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "                for key, value in self.static.items()\n",
    "            }\n",
    "            \n",
    "        self.atmos_files = glob.glob(f\"../{download_path}/atmospheric/*/*.nc\") \n",
    "        self.surf_files = glob.glob(f\"../{download_path}/fle/*.nc\") \n",
    "        \n",
    "        self.window = 3\n",
    "        self.variables_to_keep = variables_to_keep\n",
    "        \n",
    "        self.date_range = date_range\n",
    "        self.download_path = download_path\n",
    "        \n",
    "        # self.file_names = sorted(os.listdir(folder_path))  # Sort to ensure correct order\n",
    "        # self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of files (days).\"\"\"\n",
    "        # return len(self.surf_files) - self.window + 1\n",
    "        return len(date_range) - self.window + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx (int): Index of the file to load.\n",
    "        Returns:\n",
    "            (Tensor, Tensor): Features and labels for the given day.\n",
    "        \"\"\"\n",
    "#         file_path = os.path.join(self.folder_path, self.file_names[idx])\n",
    "        \n",
    "        #                       \n",
    "        atmos, surf = data_retreive(self.atmos_files, self.surf_files, self.date_range\n",
    "                             , self.window, idx,  self.variables_to_keep)\n",
    "        \n",
    "        # metadata=Metadata(\n",
    "        #     lat=torch.from_numpy(surf.latitude.values),\n",
    "        #     lon=torch.from_numpy(surf.longitude.values),\n",
    "        #     # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "        #     # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "        #     # one value for every batch element.\n",
    "        #     time=(surf.valid_time.values.astype(\"datetime64[s]\").tolist()[1],),\n",
    "        #     atmos_levels=tuple(int(level) for level in atmos.pressure_level.values),\n",
    "        # )\n",
    "        # Assuming the last column is the label\n",
    "        features, labels = feature_label_batch(atmos, surf, self.static, self.interp_static)\n",
    "         # = label_batch(atmos, surf, self.interp_static, metadata) # metadata technically wrong for labels\n",
    "        \n",
    "        # print(\"in getitem feature:\", np.unique(features.surf_vars[\"fire\"].cpu().numpy()))\n",
    "        # print(\"in getitem label:\", np.unique(labels.surf_vars[\"fire\"].cpu().numpy()))\n",
    "        # Convert to tensors\n",
    "        return (\n",
    "            features, labels\n",
    "        )\n",
    "\n",
    "def aurora_collate(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for handling Batch objects as features and labels.\n",
    "\n",
    "    Args:\n",
    "        batch (list of tuples): Each tuple contains (features, labels), where\n",
    "                                features and labels are instances of `Batch`.\n",
    "\n",
    "    Returns:\n",
    "        Batched features and labels.\n",
    "    \"\"\"\n",
    "    # Separate features and labels from the batch\n",
    "    features_list, labels_list = zip(*batch)\n",
    "\n",
    "    # Function to batch the variables in each component of the `Batch` object\n",
    "    def collate_batch_components(batch_list, key):\n",
    "        return {\n",
    "            var_key: torch.stack([getattr(b, key)[var_key] for b in batch_list])\n",
    "            for var_key in getattr(batch_list[0], key)}\n",
    "\n",
    "    # Combine `surf_vars` and `atmos_vars` for features and labels\n",
    "    batched_features = Batch(\n",
    "        surf_vars=collate_batch_components(features_list, \"surf_vars\"),\n",
    "        static_vars=collate_batch_components(features_list, \"static_vars\"),\n",
    "        atmos_vars=collate_batch_components(features_list, \"atmos_vars\"),\n",
    "        metadata=Metadata(\n",
    "            lat=torch.stack([f.metadata.lat for f in features_list]),\n",
    "            lon=torch.stack([f.metadata.lon for f in features_list]),\n",
    "            time=[f.metadata.time for f in features_list],\n",
    "            atmos_levels=[f.metadata.atmos_levels for f in features_list],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    batched_labels = Batch(\n",
    "        surf_vars=collate_batch_components(labels_list, \"surf_vars\"),\n",
    "        static_vars=collate_batch_components(features_list, \"static_vars\"),\n",
    "        atmos_vars=collate_batch_components(labels_list, \"atmos_vars\"),\n",
    "        metadata=Metadata(\n",
    "            lat=torch.stack([l.metadata.lat for l in labels_list]),\n",
    "            lon=torch.stack([l.metadata.lon for l in labels_list]),\n",
    "            time=[l.metadata.time for l in labels_list],\n",
    "            atmos_levels=[l.metadata.atmos_levels for l in labels_list],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return features_list[0], labels_list[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## dataset/loader testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AuroraDataset.__init__() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3984/1435884618.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAuroraDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables_to_keep\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mstarty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maurora_collate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: AuroraDataset.__init__() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "starty = 2015     ## start of 2015 to end of 2021\n",
    "endy = 2021           \n",
    "date_range = pd.date_range(start=f'{starty}-01-01', end=f'{endy}-12-31', freq='D')\n",
    "variables_to_keep = ['u10', 'v10', 't2m', 'msl', 'lst', 'fire']\n",
    "\n",
    "download_path = \"datasets/aurora\"\n",
    "\n",
    "\n",
    "dataset = AuroraDataset(download_path, variables_to_keep , starty, endy)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=aurora_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for features, labels in dataloader:\n",
    "    print(features.surf_vars[\"2t\"].shape)  # Ensure shapes are correct\n",
    "    print(labels.surf_vars[\"2t\"].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch_data, batch_labels in dataloader:\n",
    "    print(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing cell\n",
    "\n",
    "print(batch.surf_vars['2t'].size())\n",
    "print(interpolated_surf_vars['2t'].size())\n",
    "print(interpolated_atmos_vars['t'].size())\n",
    "\n",
    "# print(.size())\n",
    "# print(f\" size: {.size()}\")\n",
    "print(atmos_vars['t'].view(-1, 1, 721, 1440).size())\n",
    "print(atmos_vars['t'].view(-1, 1, 721, 1440).shape[2])\n",
    "\n",
    "# interpolated_surf_vars\n",
    "# surf_vars\n",
    "\n",
    "# print(atmos_vars['t'].size())\n",
    "# print(atmos_vars['u'].size())\n",
    "# print(atmos_vars['v'].size())\n",
    "# print(atmos_vars['q'].size())\n",
    "# print(atmos_vars['z'].size())\n",
    "# torch.from_numpy(surf_comb[\"t2m\"].values[[i - 1, i]][None])\n",
    "\n",
    "print(static_vars['z'].unsqueeze(0).unsqueeze(0).squeeze(0).size())\n",
    "\n",
    "# atmos_vars.items()\n",
    "print(batch2.surf_vars['2t'].size())\n",
    "print(interpolated_surf_vars['2t'].size())\n",
    "batch2.surf_vars['2t']\n",
    "\n",
    "print(f\"batch2 size: {batch2.surf_vars['2t'].size()}\")\n",
    "print(f\"pred size: {pred.surf_vars['2t'].size()}\")\n",
    "batch2.surf_vars['2t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolated_surf_vars['2t']\n",
    "# pred.surf_vars['2t']\n",
    "batch.surf_vars['2t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  torch.from_numpy(surf_vars_ds[\"lst\"].values[[i - 1, i]][None])\n",
    "test.mean()\n",
    "test.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "def loss_func(batch, pred):\n",
    "    crit = nn.L1Loss()\n",
    "    batch = batch.to('cuda')\n",
    "    pred = pred.to('cuda')\n",
    "    v_w = {}\n",
    "    alpha = 0.25\n",
    "    beta = 1\n",
    "    dataset_weight = 2\n",
    "    total_vars = len(batch.surf_vars) + len(batch.atmos_vars)\n",
    "    v_w[\"2t\"] = 3.0\n",
    "    v_w[\"10u\"] = 0.77\n",
    "    v_w[\"10v\"] = 0.66\n",
    "    v_w[\"msl\"] = 1.5\n",
    "    v_w[\"z\"] = 2.8\n",
    "    v_w[\"q\"] = 0.78\n",
    "    v_w[\"t\"] = 1.7\n",
    "    v_w[\"u\"] = 0.87\n",
    "    v_w[\"v\"] = 0.6\n",
    "    v_w[\"fire\"] = 1\n",
    "    # ******* Comment out LST for now \n",
    "    # no need to comment them out as below code only checks for existing ones\n",
    "    v_w[\"lst\"] = 1\n",
    "    l_s = torch.zeros(1, dtype=torch.float32, device=device)\n",
    "    l_a = torch.zeros(1, dtype=torch.float32, device=device)\n",
    "    for key in batch.surf_vars.keys():\n",
    "        l_s += v_w[key]*crit(pred.surf_vars[key] + 1e-8, batch.surf_vars[key] + 1e-8)/(721*1440)\n",
    "    for key in batch.atmos_vars.keys():\n",
    "        l_a += v_w[key]*crit(pred.atmos_vars[key] + 1e-8, batch.atmos_vars[key] + 1e-8)/(721*1440*13)\n",
    "    \n",
    "    l = (2/total_vars)*(l_s * alpha) + (l_a*beta)\n",
    "\n",
    "    return l   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del locations[\"fire\"]\n",
    "# del scales[\"fire\"]\n",
    "# locations\n",
    "# print(locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when changing things, change out instances of it in 5, location/scales, model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation means:\n",
    "locations[\"fire\"] =1e-8\n",
    "locations[\"lst\"] = 11484.10859\n",
    "\n",
    "# Normalisation standard deviations:\n",
    "scales[\"fire\"] = 1.0\n",
    "scales[\"lst\"] = 8109.33224\n",
    "starty = 2015     ## start of 2015 to end of 2021\n",
    "endy = 2015           \n",
    "date_range = pd.date_range(start=f'{starty}-01-01', end=f'{endy}-01-05', freq='D')\n",
    "date_range = pd.date_range(start=f'{starty}-01-01', end=f'{endy}-12-31', freq='D')\n",
    "date_range = pd.date_range(start=f'{starty+1}-01-01', end=f'{endy+1}-12-31', freq='D')\n",
    "# if keyerror, dleete variable\n",
    "# variables_to_keep = ['u10', 'v10', 't2m', 'msl', 'fire']\n",
    "# no need to worry about dong less. manually managug from 5 is way to edit for now\n",
    "variables_to_keep = ['u10', 'v10', 't2m', 'msl', 'lst', 'fire']\n",
    "\n",
    "download_path = \"globfire-gooddata/data\"\n",
    "# download_path = \"globfire-gooddata\"\n",
    "\n",
    "dataset = AuroraDataset(download_path, variables_to_keep , date_range)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))  \n",
    "# train_size = int(0.95 * len(dataset))  \n",
    "test_size = len(dataset) - train_size \n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=aurora_collate)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=1, shuffle=True, collate_fn=aurora_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[0. 1.]\n",
      "torch.Size([721, 1440])\n",
      "before count tensor(7876)\n",
      "after count tensor(7872)\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# xr.set_options(file_cache_maxsize=128)\n",
    "\n",
    "# for batch in dataloader:\n",
    "#     print(1)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "8BjNwqwL8j3n",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from aurora import Aurora, rollout\n",
    "# from aurora.normalisation import locations, scales\n",
    "\n",
    "model = Aurora(\n",
    "    use_lora=False,\n",
    "    autocast=True,      # reduces memory usage\n",
    "    surf_vars=(\"2t\", \"10u\", \"10v\", \"msl\", \"fire\",\"lst\"),\n",
    "    static_vars=(\"lsm\", \"z\", \"slt\"),\n",
    "    atmos_vars=(\"z\", \"u\", \"v\", \"t\", \"q\"),\n",
    ")\n",
    "# model = Aurora(\n",
    "#     use_lora=False,\n",
    "#     autocast=True,      # reduces memory usage\n",
    "#     # surf_vars=(\"2t\", \"10u\", \"10v\", \"msl\"),\n",
    "#     surf_vars=(\"2t\", \"10u\", \"10v\", \"msl\", \"fire\"),\n",
    "#     static_vars=(\"lsm\", \"z\", \"slt\"),\n",
    "#     atmos_vars=(\"z\", \"u\", \"v\", \"t\", \"q\"),\n",
    "# )\n",
    "\n",
    "model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-pretrained.ckpt\", strict=False)\n",
    "model = model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 1\n",
      "Allocated: 10824.03 MB\n",
      "Reserved: 71296.00 MB\n",
      "Allocated: 10824.03 MB\n",
      "Reserved: 28614.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 2\n",
      "Allocated: 10824.24 MB\n",
      "Reserved: 70906.00 MB\n",
      "Allocated: 10824.24 MB\n",
      "Reserved: 36684.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 3\n",
      "Allocated: 10827.73 MB\n",
      "Reserved: 71950.00 MB\n",
      "Allocated: 10827.73 MB\n",
      "Reserved: 31616.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 4\n",
      "Allocated: 10821.36 MB\n",
      "Reserved: 71376.00 MB\n",
      "Allocated: 10821.36 MB\n",
      "Reserved: 28678.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 5\n",
      "Allocated: 10830.46 MB\n",
      "Reserved: 70838.00 MB\n",
      "Allocated: 10830.46 MB\n",
      "Reserved: 31674.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 6\n",
      "Allocated: 10825.92 MB\n",
      "Reserved: 70992.00 MB\n",
      "Allocated: 10825.92 MB\n",
      "Reserved: 30284.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 7\n",
      "Allocated: 10828.16 MB\n",
      "Reserved: 70358.00 MB\n",
      "Allocated: 10828.16 MB\n",
      "Reserved: 25124.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 8\n",
      "Allocated: 10826.23 MB\n",
      "Reserved: 71468.00 MB\n",
      "Allocated: 10826.23 MB\n",
      "Reserved: 27150.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 9\n",
      "Allocated: 10825.65 MB\n",
      "Reserved: 71088.00 MB\n",
      "Allocated: 10825.65 MB\n",
      "Reserved: 28352.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 10\n",
      "Allocated: 10826.55 MB\n",
      "Reserved: 72482.00 MB\n",
      "Allocated: 10826.55 MB\n",
      "Reserved: 27338.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 11\n",
      "Allocated: 10824.85 MB\n",
      "Reserved: 70960.00 MB\n",
      "Allocated: 10824.85 MB\n",
      "Reserved: 29366.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 12\n",
      "Allocated: 10824.65 MB\n",
      "Reserved: 70896.00 MB\n",
      "Allocated: 10824.65 MB\n",
      "Reserved: 29366.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 13\n",
      "Allocated: 10832.71 MB\n",
      "Reserved: 70830.00 MB\n",
      "Allocated: 10832.71 MB\n",
      "Reserved: 29238.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 14\n",
      "Allocated: 10830.48 MB\n",
      "Reserved: 70198.00 MB\n",
      "Allocated: 10830.48 MB\n",
      "Reserved: 32750.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 15\n",
      "Allocated: 10826.89 MB\n",
      "Reserved: 70668.00 MB\n",
      "Allocated: 10826.89 MB\n",
      "Reserved: 32496.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 16\n",
      "Allocated: 10826.87 MB\n",
      "Reserved: 71302.00 MB\n",
      "Allocated: 10826.87 MB\n",
      "Reserved: 33698.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 17\n",
      "Allocated: 10825.74 MB\n",
      "Reserved: 70420.00 MB\n",
      "Allocated: 10825.74 MB\n",
      "Reserved: 28510.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 18\n",
      "Allocated: 10823.51 MB\n",
      "Reserved: 71370.00 MB\n",
      "Allocated: 10823.51 MB\n",
      "Reserved: 27688.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 19\n",
      "Allocated: 10826.94 MB\n",
      "Reserved: 71750.00 MB\n",
      "Allocated: 10826.94 MB\n",
      "Reserved: 28574.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 20\n",
      "Allocated: 10832.59 MB\n",
      "Reserved: 70674.00 MB\n",
      "Allocated: 10832.59 MB\n",
      "Reserved: 31238.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 21\n",
      "Allocated: 10824.98 MB\n",
      "Reserved: 70042.00 MB\n",
      "Allocated: 10824.98 MB\n",
      "Reserved: 29622.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 22\n",
      "Allocated: 10821.46 MB\n",
      "Reserved: 71592.00 MB\n",
      "Allocated: 10821.46 MB\n",
      "Reserved: 30000.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 23\n",
      "Allocated: 10827.08 MB\n",
      "Reserved: 70008.00 MB\n",
      "Allocated: 10827.08 MB\n",
      "Reserved: 33036.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 24\n",
      "Allocated: 10826.29 MB\n",
      "Reserved: 71970.00 MB\n",
      "Allocated: 10826.29 MB\n",
      "Reserved: 32054.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 25\n",
      "Allocated: 10828.33 MB\n",
      "Reserved: 72192.00 MB\n",
      "Allocated: 10828.33 MB\n",
      "Reserved: 28572.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 26\n",
      "Allocated: 10831.73 MB\n",
      "Reserved: 70038.00 MB\n",
      "Allocated: 10831.73 MB\n",
      "Reserved: 29520.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 27\n",
      "Allocated: 10825.85 MB\n",
      "Reserved: 71180.00 MB\n",
      "Allocated: 10825.85 MB\n",
      "Reserved: 31422.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 28\n",
      "Allocated: 10828.48 MB\n",
      "Reserved: 70860.00 MB\n",
      "Allocated: 10828.48 MB\n",
      "Reserved: 27748.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 29\n",
      "Allocated: 10832.39 MB\n",
      "Reserved: 71304.00 MB\n",
      "Allocated: 10832.39 MB\n",
      "Reserved: 28760.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 30\n",
      "Allocated: 10829.20 MB\n",
      "Reserved: 70798.00 MB\n",
      "Allocated: 10829.20 MB\n",
      "Reserved: 30154.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 31\n",
      "Allocated: 10827.18 MB\n",
      "Reserved: 71054.00 MB\n",
      "Allocated: 10827.18 MB\n",
      "Reserved: 29206.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 32\n",
      "Allocated: 10833.36 MB\n",
      "Reserved: 70166.00 MB\n",
      "Allocated: 10833.36 MB\n",
      "Reserved: 30786.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 33\n",
      "Allocated: 10826.40 MB\n",
      "Reserved: 70798.00 MB\n",
      "Allocated: 10826.40 MB\n",
      "Reserved: 30408.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 34\n",
      "Allocated: 10825.17 MB\n",
      "Reserved: 70228.00 MB\n",
      "Allocated: 10825.17 MB\n",
      "Reserved: 27238.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 35\n",
      "Allocated: 10829.28 MB\n",
      "Reserved: 70352.00 MB\n",
      "Allocated: 10829.28 MB\n",
      "Reserved: 29804.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 36\n",
      "Allocated: 10829.90 MB\n",
      "Reserved: 70700.00 MB\n",
      "Allocated: 10829.90 MB\n",
      "Reserved: 29806.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 37\n",
      "Allocated: 10825.48 MB\n",
      "Reserved: 71714.00 MB\n",
      "Allocated: 10825.48 MB\n",
      "Reserved: 28412.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 38\n",
      "Allocated: 10828.49 MB\n",
      "Reserved: 71336.00 MB\n",
      "Allocated: 10828.49 MB\n",
      "Reserved: 29960.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 39\n",
      "Allocated: 10828.03 MB\n",
      "Reserved: 72120.00 MB\n",
      "Allocated: 10828.03 MB\n",
      "Reserved: 35906.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 40\n",
      "Allocated: 10823.05 MB\n",
      "Reserved: 70976.00 MB\n",
      "Allocated: 10823.05 MB\n",
      "Reserved: 34452.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 41\n",
      "Allocated: 10834.86 MB\n",
      "Reserved: 70602.00 MB\n",
      "Allocated: 10834.86 MB\n",
      "Reserved: 31224.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 42\n",
      "Allocated: 10827.35 MB\n",
      "Reserved: 70536.00 MB\n",
      "Allocated: 10827.35 MB\n",
      "Reserved: 32998.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 43\n",
      "Allocated: 10822.72 MB\n",
      "Reserved: 71552.00 MB\n",
      "Allocated: 10822.72 MB\n",
      "Reserved: 36414.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 44\n",
      "Allocated: 10829.03 MB\n",
      "Reserved: 70598.00 MB\n",
      "Allocated: 10829.03 MB\n",
      "Reserved: 31224.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 45\n",
      "Allocated: 10823.84 MB\n",
      "Reserved: 71678.00 MB\n",
      "Allocated: 10823.84 MB\n",
      "Reserved: 34454.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 46\n",
      "Allocated: 10823.95 MB\n",
      "Reserved: 70032.00 MB\n",
      "Allocated: 10823.95 MB\n",
      "Reserved: 30338.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 47\n",
      "Allocated: 10825.96 MB\n",
      "Reserved: 70920.00 MB\n",
      "Allocated: 10825.96 MB\n",
      "Reserved: 28820.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 48\n",
      "Allocated: 10824.83 MB\n",
      "Reserved: 69906.00 MB\n",
      "Allocated: 10824.83 MB\n",
      "Reserved: 29958.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 49\n",
      "Allocated: 10824.74 MB\n",
      "Reserved: 71492.00 MB\n",
      "Allocated: 10824.74 MB\n",
      "Reserved: 32492.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 50\n",
      "Allocated: 10828.27 MB\n",
      "Reserved: 70412.00 MB\n",
      "Allocated: 10828.27 MB\n",
      "Reserved: 28948.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 51\n",
      "Allocated: 10824.46 MB\n",
      "Reserved: 70920.00 MB\n",
      "Allocated: 10824.46 MB\n",
      "Reserved: 30594.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 52\n",
      "Allocated: 10828.39 MB\n",
      "Reserved: 71046.00 MB\n",
      "Allocated: 10828.39 MB\n",
      "Reserved: 29392.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 53\n",
      "Allocated: 10825.89 MB\n",
      "Reserved: 70476.00 MB\n",
      "Allocated: 10825.89 MB\n",
      "Reserved: 33064.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 54\n",
      "Allocated: 10829.87 MB\n",
      "Reserved: 70478.00 MB\n",
      "Allocated: 10829.87 MB\n",
      "Reserved: 35026.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 55\n",
      "Allocated: 10828.39 MB\n",
      "Reserved: 70918.00 MB\n",
      "Allocated: 10828.39 MB\n",
      "Reserved: 33126.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 56\n",
      "Allocated: 10824.67 MB\n",
      "Reserved: 70854.00 MB\n",
      "Allocated: 10824.67 MB\n",
      "Reserved: 35848.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 57\n",
      "Allocated: 10827.92 MB\n",
      "Reserved: 70100.00 MB\n",
      "Allocated: 10827.92 MB\n",
      "Reserved: 29266.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 58\n",
      "Allocated: 10823.73 MB\n",
      "Reserved: 70226.00 MB\n",
      "Allocated: 10823.73 MB\n",
      "Reserved: 32686.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 59\n",
      "Allocated: 10830.06 MB\n",
      "Reserved: 72634.00 MB\n",
      "Allocated: 10830.06 MB\n",
      "Reserved: 33002.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 60\n",
      "Allocated: 10824.66 MB\n",
      "Reserved: 72380.00 MB\n",
      "Allocated: 10824.66 MB\n",
      "Reserved: 30656.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 61\n",
      "Allocated: 10828.22 MB\n",
      "Reserved: 70602.00 MB\n",
      "Allocated: 10828.22 MB\n",
      "Reserved: 28692.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 62\n",
      "Allocated: 10827.08 MB\n",
      "Reserved: 70604.00 MB\n",
      "Allocated: 10827.08 MB\n",
      "Reserved: 33250.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 63\n",
      "Allocated: 10826.88 MB\n",
      "Reserved: 71804.00 MB\n",
      "Allocated: 10826.88 MB\n",
      "Reserved: 33122.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 64\n",
      "Allocated: 10831.90 MB\n",
      "Reserved: 71994.00 MB\n",
      "Allocated: 10831.90 MB\n",
      "Reserved: 31480.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 65\n",
      "Allocated: 10828.98 MB\n",
      "Reserved: 70920.00 MB\n",
      "Allocated: 10828.98 MB\n",
      "Reserved: 31860.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 66\n",
      "Allocated: 10824.38 MB\n",
      "Reserved: 69780.00 MB\n",
      "Allocated: 10824.38 MB\n",
      "Reserved: 32238.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 67\n",
      "Allocated: 10826.92 MB\n",
      "Reserved: 70604.00 MB\n",
      "Allocated: 10826.92 MB\n",
      "Reserved: 32178.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 68\n",
      "Allocated: 10825.58 MB\n",
      "Reserved: 70288.00 MB\n",
      "Allocated: 10825.58 MB\n",
      "Reserved: 28252.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 69\n",
      "Allocated: 10831.79 MB\n",
      "Reserved: 71366.00 MB\n",
      "Allocated: 10831.79 MB\n",
      "Reserved: 32236.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 70\n",
      "Allocated: 10827.07 MB\n",
      "Reserved: 71614.00 MB\n",
      "Allocated: 10827.07 MB\n",
      "Reserved: 31982.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 71\n",
      "Allocated: 10824.69 MB\n",
      "Reserved: 70220.00 MB\n",
      "Allocated: 10824.69 MB\n",
      "Reserved: 35910.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 72\n",
      "Allocated: 10826.45 MB\n",
      "Reserved: 70918.00 MB\n",
      "Allocated: 10826.45 MB\n",
      "Reserved: 30720.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 73\n",
      "Allocated: 10830.98 MB\n",
      "Reserved: 71868.00 MB\n",
      "Allocated: 10830.98 MB\n",
      "Reserved: 32806.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 74\n",
      "Allocated: 10829.23 MB\n",
      "Reserved: 70852.00 MB\n",
      "Allocated: 10829.23 MB\n",
      "Reserved: 33946.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 75\n",
      "Allocated: 10827.90 MB\n",
      "Reserved: 70978.00 MB\n",
      "Allocated: 10827.90 MB\n",
      "Reserved: 32428.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 76\n",
      "Allocated: 10829.12 MB\n",
      "Reserved: 70412.00 MB\n",
      "Allocated: 10829.12 MB\n",
      "Reserved: 29960.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 77\n",
      "Allocated: 10832.50 MB\n",
      "Reserved: 70920.00 MB\n",
      "Allocated: 10832.50 MB\n",
      "Reserved: 29704.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 78\n",
      "Allocated: 10826.83 MB\n",
      "Reserved: 70538.00 MB\n",
      "Allocated: 10826.83 MB\n",
      "Reserved: 28948.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 79\n",
      "Allocated: 10829.88 MB\n",
      "Reserved: 70604.00 MB\n",
      "Allocated: 10829.88 MB\n",
      "Reserved: 30148.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 80\n",
      "Allocated: 10833.04 MB\n",
      "Reserved: 71618.00 MB\n",
      "Allocated: 10833.04 MB\n",
      "Reserved: 34088.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 81\n",
      "Allocated: 10828.39 MB\n",
      "Reserved: 71754.00 MB\n",
      "Allocated: 10828.39 MB\n",
      "Reserved: 35608.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 82\n",
      "Allocated: 10824.69 MB\n",
      "Reserved: 70740.00 MB\n",
      "Allocated: 10824.69 MB\n",
      "Reserved: 32188.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 83\n",
      "Allocated: 10828.77 MB\n",
      "Reserved: 71186.00 MB\n",
      "Allocated: 10828.77 MB\n",
      "Reserved: 34722.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 84\n",
      "Allocated: 10829.60 MB\n",
      "Reserved: 70172.00 MB\n",
      "Allocated: 10829.60 MB\n",
      "Reserved: 29150.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 85\n",
      "Allocated: 10821.65 MB\n",
      "Reserved: 71504.00 MB\n",
      "Allocated: 10821.65 MB\n",
      "Reserved: 29910.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 86\n",
      "Allocated: 10830.71 MB\n",
      "Reserved: 70490.00 MB\n",
      "Allocated: 10830.71 MB\n",
      "Reserved: 30926.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 87\n",
      "Allocated: 10825.51 MB\n",
      "Reserved: 72012.00 MB\n",
      "Allocated: 10825.51 MB\n",
      "Reserved: 36118.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 88\n",
      "Allocated: 10828.11 MB\n",
      "Reserved: 70742.00 MB\n",
      "Allocated: 10828.11 MB\n",
      "Reserved: 32570.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 89\n",
      "Allocated: 10827.59 MB\n",
      "Reserved: 70872.00 MB\n",
      "Allocated: 10827.59 MB\n",
      "Reserved: 29534.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 90\n",
      "Allocated: 10823.79 MB\n",
      "Reserved: 70746.00 MB\n",
      "Allocated: 10823.79 MB\n",
      "Reserved: 30546.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 91\n",
      "Allocated: 10824.74 MB\n",
      "Reserved: 71442.00 MB\n",
      "Allocated: 10824.74 MB\n",
      "Reserved: 32444.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 92\n",
      "Allocated: 10830.48 MB\n",
      "Reserved: 70110.00 MB\n",
      "Allocated: 10830.48 MB\n",
      "Reserved: 32442.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 93\n",
      "Allocated: 10824.55 MB\n",
      "Reserved: 70428.00 MB\n",
      "Allocated: 10824.55 MB\n",
      "Reserved: 33328.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 94\n",
      "Allocated: 10827.40 MB\n",
      "Reserved: 71186.00 MB\n",
      "Allocated: 10827.40 MB\n",
      "Reserved: 35356.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 95\n",
      "Allocated: 10827.85 MB\n",
      "Reserved: 70234.00 MB\n",
      "Allocated: 10827.85 MB\n",
      "Reserved: 31304.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 96\n",
      "Allocated: 10835.00 MB\n",
      "Reserved: 70618.00 MB\n",
      "Allocated: 10835.00 MB\n",
      "Reserved: 32318.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 97\n",
      "Allocated: 10830.72 MB\n",
      "Reserved: 70238.00 MB\n",
      "Allocated: 10830.72 MB\n",
      "Reserved: 33206.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 98\n",
      "Allocated: 10825.04 MB\n",
      "Reserved: 71760.00 MB\n",
      "Allocated: 10825.04 MB\n",
      "Reserved: 32192.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 99\n",
      "Allocated: 10829.77 MB\n",
      "Reserved: 72332.00 MB\n",
      "Allocated: 10829.77 MB\n",
      "Reserved: 31750.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 100\n",
      "Allocated: 10830.04 MB\n",
      "Reserved: 71066.00 MB\n",
      "Allocated: 10830.04 MB\n",
      "Reserved: 26114.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 101\n",
      "Allocated: 10833.32 MB\n",
      "Reserved: 70876.00 MB\n",
      "Allocated: 10833.32 MB\n",
      "Reserved: 30926.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 102\n",
      "Allocated: 10822.54 MB\n",
      "Reserved: 72204.00 MB\n",
      "Allocated: 10822.54 MB\n",
      "Reserved: 35864.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 103\n",
      "Allocated: 10825.25 MB\n",
      "Reserved: 71502.00 MB\n",
      "Allocated: 10825.25 MB\n",
      "Reserved: 32824.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 104\n",
      "Allocated: 10821.22 MB\n",
      "Reserved: 70492.00 MB\n",
      "Allocated: 10821.22 MB\n",
      "Reserved: 24658.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 105\n",
      "Allocated: 10823.08 MB\n",
      "Reserved: 71064.00 MB\n",
      "Allocated: 10823.08 MB\n",
      "Reserved: 33838.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 106\n",
      "Allocated: 10829.90 MB\n",
      "Reserved: 70238.00 MB\n",
      "Allocated: 10829.90 MB\n",
      "Reserved: 30164.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 107\n",
      "Allocated: 10829.29 MB\n",
      "Reserved: 69794.00 MB\n",
      "Allocated: 10829.29 MB\n",
      "Reserved: 28964.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 108\n",
      "Allocated: 10827.48 MB\n",
      "Reserved: 70366.00 MB\n",
      "Allocated: 10827.48 MB\n",
      "Reserved: 30228.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 109\n",
      "Allocated: 10822.95 MB\n",
      "Reserved: 71826.00 MB\n",
      "Allocated: 10822.95 MB\n",
      "Reserved: 31434.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 110\n",
      "Allocated: 10826.03 MB\n",
      "Reserved: 71192.00 MB\n",
      "Allocated: 10826.03 MB\n",
      "Reserved: 32888.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 111\n",
      "Allocated: 10819.87 MB\n",
      "Reserved: 70934.00 MB\n",
      "Allocated: 10819.87 MB\n",
      "Reserved: 36240.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 112\n",
      "Allocated: 10825.59 MB\n",
      "Reserved: 71440.00 MB\n",
      "Allocated: 10825.59 MB\n",
      "Reserved: 34782.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 113\n",
      "Allocated: 10820.76 MB\n",
      "Reserved: 71376.00 MB\n",
      "Allocated: 10820.76 MB\n",
      "Reserved: 31810.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 114\n",
      "Allocated: 10824.70 MB\n",
      "Reserved: 71884.00 MB\n",
      "Allocated: 10824.70 MB\n",
      "Reserved: 35486.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 115\n",
      "Allocated: 10823.96 MB\n",
      "Reserved: 71822.00 MB\n",
      "Allocated: 10823.96 MB\n",
      "Reserved: 31810.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 116\n",
      "Allocated: 10824.84 MB\n",
      "Reserved: 70870.00 MB\n",
      "Allocated: 10824.84 MB\n",
      "Reserved: 37380.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 117\n",
      "Allocated: 10823.46 MB\n",
      "Reserved: 70236.00 MB\n",
      "Allocated: 10823.46 MB\n",
      "Reserved: 32954.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 118\n",
      "Allocated: 10823.35 MB\n",
      "Reserved: 70238.00 MB\n",
      "Allocated: 10823.35 MB\n",
      "Reserved: 29280.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 119\n",
      "Allocated: 10828.09 MB\n",
      "Reserved: 72332.00 MB\n",
      "Allocated: 10828.09 MB\n",
      "Reserved: 30926.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 120\n",
      "Allocated: 10825.75 MB\n",
      "Reserved: 71316.00 MB\n",
      "Allocated: 10825.75 MB\n",
      "Reserved: 29406.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 121\n",
      "Allocated: 10819.81 MB\n",
      "Reserved: 70872.00 MB\n",
      "Allocated: 10819.81 MB\n",
      "Reserved: 32446.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 122\n",
      "Allocated: 10824.83 MB\n",
      "Reserved: 71378.00 MB\n",
      "Allocated: 10824.83 MB\n",
      "Reserved: 31432.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 123\n",
      "Allocated: 10825.32 MB\n",
      "Reserved: 71824.00 MB\n",
      "Allocated: 10825.32 MB\n",
      "Reserved: 29406.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 124\n",
      "Allocated: 10821.88 MB\n",
      "Reserved: 70746.00 MB\n",
      "Allocated: 10821.88 MB\n",
      "Reserved: 31306.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 125\n",
      "Allocated: 10830.32 MB\n",
      "Reserved: 70746.00 MB\n",
      "Allocated: 10830.32 MB\n",
      "Reserved: 29154.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 126\n",
      "Allocated: 10824.06 MB\n",
      "Reserved: 69986.00 MB\n",
      "Allocated: 10824.06 MB\n",
      "Reserved: 28802.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 127\n",
      "Allocated: 10824.38 MB\n",
      "Reserved: 70648.00 MB\n",
      "Allocated: 10824.38 MB\n",
      "Reserved: 33238.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 128\n",
      "Allocated: 10825.24 MB\n",
      "Reserved: 71094.00 MB\n",
      "Allocated: 10825.24 MB\n",
      "Reserved: 31718.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 129\n",
      "Allocated: 10821.86 MB\n",
      "Reserved: 71158.00 MB\n",
      "Allocated: 10821.86 MB\n",
      "Reserved: 31210.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 130\n",
      "Allocated: 10819.59 MB\n",
      "Reserved: 71158.00 MB\n",
      "Allocated: 10819.59 MB\n",
      "Reserved: 36146.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 131\n",
      "Allocated: 10824.75 MB\n",
      "Reserved: 71156.00 MB\n",
      "Allocated: 10824.75 MB\n",
      "Reserved: 32602.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 132\n",
      "Allocated: 10825.39 MB\n",
      "Reserved: 70398.00 MB\n",
      "Allocated: 10825.39 MB\n",
      "Reserved: 29816.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 133\n",
      "Allocated: 10825.17 MB\n",
      "Reserved: 70586.00 MB\n",
      "Allocated: 10825.17 MB\n",
      "Reserved: 34056.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 134\n",
      "Allocated: 10829.35 MB\n",
      "Reserved: 70456.00 MB\n",
      "Allocated: 10829.35 MB\n",
      "Reserved: 32980.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 135\n",
      "Allocated: 10829.70 MB\n",
      "Reserved: 70394.00 MB\n",
      "Allocated: 10829.70 MB\n",
      "Reserved: 33110.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 136\n",
      "Allocated: 10824.29 MB\n",
      "Reserved: 70774.00 MB\n",
      "Allocated: 10824.29 MB\n",
      "Reserved: 31082.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 137\n",
      "Allocated: 10820.73 MB\n",
      "Reserved: 69446.00 MB\n",
      "Allocated: 10820.73 MB\n",
      "Reserved: 29816.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 138\n",
      "Allocated: 10825.96 MB\n",
      "Reserved: 71156.00 MB\n",
      "Allocated: 10825.96 MB\n",
      "Reserved: 30006.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 139\n",
      "Allocated: 10819.70 MB\n",
      "Reserved: 71218.00 MB\n",
      "Allocated: 10819.70 MB\n",
      "Reserved: 29626.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 140\n",
      "Allocated: 10818.03 MB\n",
      "Reserved: 71092.00 MB\n",
      "Allocated: 10818.03 MB\n",
      "Reserved: 33104.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 141\n",
      "Allocated: 10819.60 MB\n",
      "Reserved: 70010.00 MB\n",
      "Allocated: 10819.60 MB\n",
      "Reserved: 31334.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 142\n",
      "Allocated: 10825.18 MB\n",
      "Reserved: 69952.00 MB\n",
      "Allocated: 10825.18 MB\n",
      "Reserved: 30386.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 143\n",
      "Allocated: 10818.76 MB\n",
      "Reserved: 70078.00 MB\n",
      "Allocated: 10818.76 MB\n",
      "Reserved: 30194.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 144\n",
      "Allocated: 10823.01 MB\n",
      "Reserved: 70964.00 MB\n",
      "Allocated: 10823.01 MB\n",
      "Reserved: 32792.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 145\n",
      "Allocated: 10825.24 MB\n",
      "Reserved: 71412.00 MB\n",
      "Allocated: 10825.24 MB\n",
      "Reserved: 31908.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 146\n",
      "Allocated: 10827.00 MB\n",
      "Reserved: 70968.00 MB\n",
      "Allocated: 10827.00 MB\n",
      "Reserved: 33490.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 147\n",
      "Allocated: 10823.91 MB\n",
      "Reserved: 69890.00 MB\n",
      "Allocated: 10823.91 MB\n",
      "Reserved: 32094.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 148\n",
      "Allocated: 10826.17 MB\n",
      "Reserved: 71026.00 MB\n",
      "Allocated: 10826.17 MB\n",
      "Reserved: 32474.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 149\n",
      "Allocated: 10826.90 MB\n",
      "Reserved: 71030.00 MB\n",
      "Allocated: 10826.90 MB\n",
      "Reserved: 30830.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 150\n",
      "Allocated: 10830.22 MB\n",
      "Reserved: 69890.00 MB\n",
      "Allocated: 10830.22 MB\n",
      "Reserved: 29944.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 151\n",
      "Allocated: 10827.47 MB\n",
      "Reserved: 71032.00 MB\n",
      "Allocated: 10827.47 MB\n",
      "Reserved: 28424.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 152\n",
      "Allocated: 10826.27 MB\n",
      "Reserved: 70904.00 MB\n",
      "Allocated: 10826.27 MB\n",
      "Reserved: 29942.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 153\n",
      "Allocated: 10827.75 MB\n",
      "Reserved: 70968.00 MB\n",
      "Allocated: 10827.75 MB\n",
      "Reserved: 30514.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 154\n",
      "Allocated: 10823.14 MB\n",
      "Reserved: 70586.00 MB\n",
      "Allocated: 10823.14 MB\n",
      "Reserved: 29564.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 155\n",
      "Allocated: 10826.79 MB\n",
      "Reserved: 70524.00 MB\n",
      "Allocated: 10826.79 MB\n",
      "Reserved: 28678.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 156\n",
      "Allocated: 10819.81 MB\n",
      "Reserved: 71918.00 MB\n",
      "Allocated: 10819.81 MB\n",
      "Reserved: 28488.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 157\n",
      "Allocated: 10824.05 MB\n",
      "Reserved: 71474.00 MB\n",
      "Allocated: 10824.05 MB\n",
      "Reserved: 29942.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 158\n",
      "Allocated: 10821.08 MB\n",
      "Reserved: 71028.00 MB\n",
      "Allocated: 10821.08 MB\n",
      "Reserved: 28422.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 159\n",
      "Allocated: 10825.78 MB\n",
      "Reserved: 70460.00 MB\n",
      "Allocated: 10825.78 MB\n",
      "Reserved: 31968.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 160\n",
      "Allocated: 10826.90 MB\n",
      "Reserved: 69886.00 MB\n",
      "Allocated: 10826.90 MB\n",
      "Reserved: 31208.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 161\n",
      "Allocated: 10823.09 MB\n",
      "Reserved: 69700.00 MB\n",
      "Allocated: 10823.09 MB\n",
      "Reserved: 29372.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 162\n",
      "Allocated: 10820.00 MB\n",
      "Reserved: 70334.00 MB\n",
      "Allocated: 10820.00 MB\n",
      "Reserved: 30450.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 163\n",
      "Allocated: 10821.89 MB\n",
      "Reserved: 71918.00 MB\n",
      "Allocated: 10821.89 MB\n",
      "Reserved: 29818.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 164\n",
      "Allocated: 10821.88 MB\n",
      "Reserved: 71792.00 MB\n",
      "Allocated: 10821.88 MB\n",
      "Reserved: 32350.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 165\n",
      "Allocated: 10822.35 MB\n",
      "Reserved: 71220.00 MB\n",
      "Allocated: 10822.35 MB\n",
      "Reserved: 28170.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 166\n",
      "Allocated: 10829.26 MB\n",
      "Reserved: 70650.00 MB\n",
      "Allocated: 10829.26 MB\n",
      "Reserved: 36146.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 167\n",
      "Allocated: 10827.21 MB\n",
      "Reserved: 71026.00 MB\n",
      "Allocated: 10827.21 MB\n",
      "Reserved: 33360.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 168\n",
      "Allocated: 10817.80 MB\n",
      "Reserved: 72232.00 MB\n",
      "Allocated: 10817.80 MB\n",
      "Reserved: 33108.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 169\n",
      "Allocated: 10828.28 MB\n",
      "Reserved: 70394.00 MB\n",
      "Allocated: 10828.28 MB\n",
      "Reserved: 32350.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 170\n",
      "Allocated: 10823.23 MB\n",
      "Reserved: 70080.00 MB\n",
      "Allocated: 10823.23 MB\n",
      "Reserved: 28614.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 171\n",
      "Allocated: 10818.85 MB\n",
      "Reserved: 70080.00 MB\n",
      "Allocated: 10818.85 MB\n",
      "Reserved: 32222.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 172\n",
      "Allocated: 10822.68 MB\n",
      "Reserved: 71662.00 MB\n",
      "Allocated: 10822.68 MB\n",
      "Reserved: 35768.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 173\n",
      "Allocated: 10827.79 MB\n",
      "Reserved: 71596.00 MB\n",
      "Allocated: 10827.79 MB\n",
      "Reserved: 33234.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 174\n",
      "Allocated: 10820.89 MB\n",
      "Reserved: 69884.00 MB\n",
      "Allocated: 10820.89 MB\n",
      "Reserved: 33740.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 175\n",
      "Allocated: 10820.63 MB\n",
      "Reserved: 71282.00 MB\n",
      "Allocated: 10820.63 MB\n",
      "Reserved: 31334.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 176\n",
      "Allocated: 10826.99 MB\n",
      "Reserved: 70900.00 MB\n",
      "Allocated: 10826.99 MB\n",
      "Reserved: 32348.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 177\n",
      "Allocated: 10824.90 MB\n",
      "Reserved: 69634.00 MB\n",
      "Allocated: 10824.90 MB\n",
      "Reserved: 35892.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 178\n",
      "Allocated: 10823.39 MB\n",
      "Reserved: 71280.00 MB\n",
      "Allocated: 10823.39 MB\n",
      "Reserved: 33740.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 179\n",
      "Allocated: 10823.01 MB\n",
      "Reserved: 72356.00 MB\n",
      "Allocated: 10823.01 MB\n",
      "Reserved: 35956.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 180\n",
      "Allocated: 10826.69 MB\n",
      "Reserved: 70708.00 MB\n",
      "Allocated: 10826.69 MB\n",
      "Reserved: 32854.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 181\n",
      "Allocated: 10820.66 MB\n",
      "Reserved: 70900.00 MB\n",
      "Allocated: 10820.66 MB\n",
      "Reserved: 31208.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 182\n",
      "Allocated: 10823.05 MB\n",
      "Reserved: 72358.00 MB\n",
      "Allocated: 10823.05 MB\n",
      "Reserved: 33362.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 183\n",
      "Allocated: 10823.16 MB\n",
      "Reserved: 71218.00 MB\n",
      "Allocated: 10823.16 MB\n",
      "Reserved: 31208.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 184\n",
      "Allocated: 10828.85 MB\n",
      "Reserved: 70774.00 MB\n",
      "Allocated: 10828.85 MB\n",
      "Reserved: 32728.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 185\n",
      "Allocated: 10826.37 MB\n",
      "Reserved: 70014.00 MB\n",
      "Allocated: 10826.37 MB\n",
      "Reserved: 34628.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 186\n",
      "Allocated: 10828.40 MB\n",
      "Reserved: 70016.00 MB\n",
      "Allocated: 10828.40 MB\n",
      "Reserved: 33236.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 187\n",
      "Allocated: 10828.67 MB\n",
      "Reserved: 71154.00 MB\n",
      "Allocated: 10828.67 MB\n",
      "Reserved: 37286.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 188\n",
      "Allocated: 10828.70 MB\n",
      "Reserved: 71534.00 MB\n",
      "Allocated: 10828.70 MB\n",
      "Reserved: 33108.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 189\n",
      "Allocated: 10829.87 MB\n",
      "Reserved: 70648.00 MB\n",
      "Allocated: 10829.87 MB\n",
      "Reserved: 30070.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 190\n",
      "Allocated: 10819.93 MB\n",
      "Reserved: 72678.00 MB\n",
      "Allocated: 10819.93 MB\n",
      "Reserved: 30704.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 191\n",
      "Allocated: 10823.76 MB\n",
      "Reserved: 70144.00 MB\n",
      "Allocated: 10823.76 MB\n",
      "Reserved: 30324.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 192\n",
      "Allocated: 10818.71 MB\n",
      "Reserved: 69636.00 MB\n",
      "Allocated: 10818.71 MB\n",
      "Reserved: 26142.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 193\n",
      "Allocated: 10821.89 MB\n",
      "Reserved: 70460.00 MB\n",
      "Allocated: 10821.89 MB\n",
      "Reserved: 32474.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 194\n",
      "Allocated: 10821.33 MB\n",
      "Reserved: 70774.00 MB\n",
      "Allocated: 10821.33 MB\n",
      "Reserved: 33994.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 195\n",
      "Allocated: 10820.12 MB\n",
      "Reserved: 70266.00 MB\n",
      "Allocated: 10820.12 MB\n",
      "Reserved: 38552.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 196\n",
      "Allocated: 10827.48 MB\n",
      "Reserved: 70644.00 MB\n",
      "Allocated: 10827.48 MB\n",
      "Reserved: 37538.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 197\n",
      "Allocated: 10823.46 MB\n",
      "Reserved: 70458.00 MB\n",
      "Allocated: 10823.46 MB\n",
      "Reserved: 32600.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 198\n",
      "Allocated: 10828.76 MB\n",
      "Reserved: 70014.00 MB\n",
      "Allocated: 10828.76 MB\n",
      "Reserved: 32604.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 199\n",
      "Allocated: 10824.16 MB\n",
      "Reserved: 70648.00 MB\n",
      "Allocated: 10824.16 MB\n",
      "Reserved: 33742.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 200\n",
      "Allocated: 10821.08 MB\n",
      "Reserved: 70584.00 MB\n",
      "Allocated: 10821.08 MB\n",
      "Reserved: 32980.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 201\n",
      "Allocated: 10823.05 MB\n",
      "Reserved: 70266.00 MB\n",
      "Allocated: 10823.05 MB\n",
      "Reserved: 28296.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 202\n",
      "Allocated: 10825.19 MB\n",
      "Reserved: 70902.00 MB\n",
      "Allocated: 10825.19 MB\n",
      "Reserved: 30956.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 203\n",
      "Allocated: 10822.14 MB\n",
      "Reserved: 71854.00 MB\n",
      "Allocated: 10822.14 MB\n",
      "Reserved: 29816.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 204\n",
      "Allocated: 10827.48 MB\n",
      "Reserved: 72360.00 MB\n",
      "Allocated: 10827.48 MB\n",
      "Reserved: 31714.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 205\n",
      "Allocated: 10825.87 MB\n",
      "Reserved: 70648.00 MB\n",
      "Allocated: 10825.87 MB\n",
      "Reserved: 29184.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 206\n",
      "Allocated: 10819.59 MB\n",
      "Reserved: 71664.00 MB\n",
      "Allocated: 10819.59 MB\n",
      "Reserved: 28550.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 207\n",
      "Allocated: 10824.28 MB\n",
      "Reserved: 70650.00 MB\n",
      "Allocated: 10824.28 MB\n",
      "Reserved: 31588.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 208\n",
      "Allocated: 10820.85 MB\n",
      "Reserved: 71662.00 MB\n",
      "Allocated: 10820.85 MB\n",
      "Reserved: 32224.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 209\n",
      "Allocated: 10818.72 MB\n",
      "Reserved: 71284.00 MB\n",
      "Allocated: 10818.72 MB\n",
      "Reserved: 36904.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 210\n",
      "Allocated: 10823.64 MB\n",
      "Reserved: 72102.00 MB\n",
      "Allocated: 10823.64 MB\n",
      "Reserved: 35130.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 211\n",
      "Allocated: 10824.23 MB\n",
      "Reserved: 71660.00 MB\n",
      "Allocated: 10824.23 MB\n",
      "Reserved: 31778.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 212\n",
      "Allocated: 10823.72 MB\n",
      "Reserved: 69066.00 MB\n",
      "Allocated: 10823.72 MB\n",
      "Reserved: 30328.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 213\n",
      "Allocated: 10822.21 MB\n",
      "Reserved: 69640.00 MB\n",
      "Allocated: 10822.21 MB\n",
      "Reserved: 31338.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 214\n",
      "Allocated: 10823.23 MB\n",
      "Reserved: 72298.00 MB\n",
      "Allocated: 10823.23 MB\n",
      "Reserved: 32350.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 215\n",
      "Allocated: 10827.22 MB\n",
      "Reserved: 70776.00 MB\n",
      "Allocated: 10827.22 MB\n",
      "Reserved: 32350.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 216\n",
      "Allocated: 10822.76 MB\n",
      "Reserved: 71094.00 MB\n",
      "Allocated: 10822.76 MB\n",
      "Reserved: 30320.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 217\n",
      "Allocated: 10824.76 MB\n",
      "Reserved: 71726.00 MB\n",
      "Allocated: 10824.76 MB\n",
      "Reserved: 31716.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 218\n",
      "Allocated: 10822.52 MB\n",
      "Reserved: 71730.00 MB\n",
      "Allocated: 10822.52 MB\n",
      "Reserved: 30328.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 219\n",
      "Allocated: 10830.65 MB\n",
      "Reserved: 71286.00 MB\n",
      "Allocated: 10830.65 MB\n",
      "Reserved: 29692.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 220\n",
      "Allocated: 10823.99 MB\n",
      "Reserved: 70842.00 MB\n",
      "Allocated: 10823.99 MB\n",
      "Reserved: 30008.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 221\n",
      "Allocated: 10824.10 MB\n",
      "Reserved: 70968.00 MB\n",
      "Allocated: 10824.10 MB\n",
      "Reserved: 31462.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 222\n",
      "Allocated: 10826.90 MB\n",
      "Reserved: 69764.00 MB\n",
      "Allocated: 10826.90 MB\n",
      "Reserved: 29438.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 223\n",
      "Allocated: 10826.87 MB\n",
      "Reserved: 71350.00 MB\n",
      "Allocated: 10826.87 MB\n",
      "Reserved: 30322.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 224\n",
      "Allocated: 10826.11 MB\n",
      "Reserved: 71282.00 MB\n",
      "Allocated: 10826.11 MB\n",
      "Reserved: 33314.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 225\n",
      "Allocated: 10823.99 MB\n",
      "Reserved: 69840.00 MB\n",
      "Allocated: 10823.99 MB\n",
      "Reserved: 33950.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 226\n",
      "Allocated: 10819.35 MB\n",
      "Reserved: 70980.00 MB\n",
      "Allocated: 10819.35 MB\n",
      "Reserved: 33314.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 227\n",
      "Allocated: 10824.96 MB\n",
      "Reserved: 70728.00 MB\n",
      "Allocated: 10824.96 MB\n",
      "Reserved: 35336.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 228\n",
      "Allocated: 10826.66 MB\n",
      "Reserved: 72878.00 MB\n",
      "Allocated: 10826.66 MB\n",
      "Reserved: 35338.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 229\n",
      "Allocated: 10823.70 MB\n",
      "Reserved: 72438.00 MB\n",
      "Allocated: 10823.70 MB\n",
      "Reserved: 30972.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 230\n",
      "Allocated: 10821.62 MB\n",
      "Reserved: 70918.00 MB\n",
      "Allocated: 10821.62 MB\n",
      "Reserved: 32236.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 231\n",
      "Allocated: 10823.16 MB\n",
      "Reserved: 70664.00 MB\n",
      "Allocated: 10823.16 MB\n",
      "Reserved: 31158.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 232\n",
      "Allocated: 10826.73 MB\n",
      "Reserved: 70472.00 MB\n",
      "Allocated: 10826.73 MB\n",
      "Reserved: 29958.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 233\n",
      "Allocated: 10827.36 MB\n",
      "Reserved: 70916.00 MB\n",
      "Allocated: 10827.36 MB\n",
      "Reserved: 30906.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 234\n",
      "Allocated: 10829.77 MB\n",
      "Reserved: 70726.00 MB\n",
      "Allocated: 10829.77 MB\n",
      "Reserved: 36984.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 235\n",
      "Allocated: 10822.66 MB\n",
      "Reserved: 70342.00 MB\n",
      "Allocated: 10822.66 MB\n",
      "Reserved: 30148.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 236\n",
      "Allocated: 10819.18 MB\n",
      "Reserved: 72058.00 MB\n",
      "Allocated: 10819.18 MB\n",
      "Reserved: 29516.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 237\n",
      "Allocated: 10822.84 MB\n",
      "Reserved: 70602.00 MB\n",
      "Allocated: 10822.84 MB\n",
      "Reserved: 29642.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 238\n",
      "Allocated: 10822.46 MB\n",
      "Reserved: 70096.00 MB\n",
      "Allocated: 10822.46 MB\n",
      "Reserved: 30150.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 239\n",
      "Allocated: 10824.03 MB\n",
      "Reserved: 70032.00 MB\n",
      "Allocated: 10824.03 MB\n",
      "Reserved: 30656.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 240\n",
      "Allocated: 10828.15 MB\n",
      "Reserved: 70728.00 MB\n",
      "Allocated: 10828.15 MB\n",
      "Reserved: 35848.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 241\n",
      "Allocated: 10818.52 MB\n",
      "Reserved: 71488.00 MB\n",
      "Allocated: 10818.52 MB\n",
      "Reserved: 34328.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 242\n",
      "Allocated: 10827.94 MB\n",
      "Reserved: 71552.00 MB\n",
      "Allocated: 10827.94 MB\n",
      "Reserved: 30276.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 243\n",
      "Allocated: 10833.36 MB\n",
      "Reserved: 71236.00 MB\n",
      "Allocated: 10833.36 MB\n",
      "Reserved: 28630.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 244\n",
      "Allocated: 10825.89 MB\n",
      "Reserved: 71110.00 MB\n",
      "Allocated: 10825.89 MB\n",
      "Reserved: 30656.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 245\n",
      "Allocated: 10827.77 MB\n",
      "Reserved: 69712.00 MB\n",
      "Allocated: 10827.77 MB\n",
      "Reserved: 30530.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 246\n",
      "Allocated: 10826.95 MB\n",
      "Reserved: 70160.00 MB\n",
      "Allocated: 10826.95 MB\n",
      "Reserved: 29388.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 247\n",
      "Allocated: 10826.95 MB\n",
      "Reserved: 70476.00 MB\n",
      "Allocated: 10826.95 MB\n",
      "Reserved: 33632.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 248\n",
      "Allocated: 10821.15 MB\n",
      "Reserved: 70542.00 MB\n",
      "Allocated: 10821.15 MB\n",
      "Reserved: 34644.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 249\n",
      "Allocated: 10825.12 MB\n",
      "Reserved: 72628.00 MB\n",
      "Allocated: 10825.12 MB\n",
      "Reserved: 36606.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 250\n",
      "Allocated: 10825.17 MB\n",
      "Reserved: 72062.00 MB\n",
      "Allocated: 10825.17 MB\n",
      "Reserved: 32962.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 251\n",
      "Allocated: 10826.08 MB\n",
      "Reserved: 70758.00 MB\n",
      "Allocated: 10826.08 MB\n",
      "Reserved: 29040.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 252\n",
      "Allocated: 10823.65 MB\n",
      "Reserved: 71330.00 MB\n",
      "Allocated: 10823.65 MB\n",
      "Reserved: 32394.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 253\n",
      "Allocated: 10819.76 MB\n",
      "Reserved: 71202.00 MB\n",
      "Allocated: 10819.76 MB\n",
      "Reserved: 36382.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 254\n",
      "Allocated: 10823.32 MB\n",
      "Reserved: 71898.00 MB\n",
      "Allocated: 10823.32 MB\n",
      "Reserved: 33470.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 255\n",
      "Allocated: 10827.32 MB\n",
      "Reserved: 71262.00 MB\n",
      "Allocated: 10827.32 MB\n",
      "Reserved: 32836.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 256\n",
      "Allocated: 10823.85 MB\n",
      "Reserved: 69744.00 MB\n",
      "Allocated: 10823.85 MB\n",
      "Reserved: 31952.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 257\n",
      "Allocated: 10825.54 MB\n",
      "Reserved: 70884.00 MB\n",
      "Allocated: 10825.54 MB\n",
      "Reserved: 32586.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 258\n",
      "Allocated: 10827.76 MB\n",
      "Reserved: 70758.00 MB\n",
      "Allocated: 10827.76 MB\n",
      "Reserved: 30052.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 259\n",
      "Allocated: 10817.34 MB\n",
      "Reserved: 69994.00 MB\n",
      "Allocated: 10817.34 MB\n",
      "Reserved: 31572.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 260\n",
      "Allocated: 10823.42 MB\n",
      "Reserved: 70378.00 MB\n",
      "Allocated: 10823.42 MB\n",
      "Reserved: 31572.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 261\n",
      "Allocated: 10823.49 MB\n",
      "Reserved: 71010.00 MB\n",
      "Allocated: 10823.49 MB\n",
      "Reserved: 30558.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 262\n",
      "Allocated: 10827.07 MB\n",
      "Reserved: 72026.00 MB\n",
      "Allocated: 10827.07 MB\n",
      "Reserved: 30936.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 263\n",
      "Allocated: 10828.15 MB\n",
      "Reserved: 70440.00 MB\n",
      "Allocated: 10828.15 MB\n",
      "Reserved: 32586.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 264\n",
      "Allocated: 10826.77 MB\n",
      "Reserved: 70504.00 MB\n",
      "Allocated: 10826.77 MB\n",
      "Reserved: 32456.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 265\n",
      "Allocated: 10825.25 MB\n",
      "Reserved: 71008.00 MB\n",
      "Allocated: 10825.25 MB\n",
      "Reserved: 30558.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 266\n",
      "Allocated: 10824.59 MB\n",
      "Reserved: 70378.00 MB\n",
      "Allocated: 10824.59 MB\n",
      "Reserved: 30558.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 267\n",
      "Allocated: 10826.09 MB\n",
      "Reserved: 71010.00 MB\n",
      "Allocated: 10826.09 MB\n",
      "Reserved: 32456.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 268\n",
      "Allocated: 10825.83 MB\n",
      "Reserved: 70374.00 MB\n",
      "Allocated: 10825.83 MB\n",
      "Reserved: 34734.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 269\n",
      "Allocated: 10821.20 MB\n",
      "Reserved: 71640.00 MB\n",
      "Allocated: 10821.20 MB\n",
      "Reserved: 33216.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 270\n",
      "Allocated: 10820.87 MB\n",
      "Reserved: 70252.00 MB\n",
      "Allocated: 10820.87 MB\n",
      "Reserved: 31258.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 271\n",
      "Allocated: 10827.47 MB\n",
      "Reserved: 70572.00 MB\n",
      "Allocated: 10827.47 MB\n",
      "Reserved: 30054.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 272\n",
      "Allocated: 10831.83 MB\n",
      "Reserved: 71648.00 MB\n",
      "Allocated: 10831.83 MB\n",
      "Reserved: 31700.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 273\n",
      "Allocated: 10820.90 MB\n",
      "Reserved: 71648.00 MB\n",
      "Allocated: 10820.90 MB\n",
      "Reserved: 32584.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 274\n",
      "Allocated: 10824.84 MB\n",
      "Reserved: 70630.00 MB\n",
      "Allocated: 10824.84 MB\n",
      "Reserved: 27520.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 275\n",
      "Allocated: 10822.70 MB\n",
      "Reserved: 71076.00 MB\n",
      "Allocated: 10822.70 MB\n",
      "Reserved: 29800.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 276\n",
      "Allocated: 10827.05 MB\n",
      "Reserved: 72218.00 MB\n",
      "Allocated: 10827.05 MB\n",
      "Reserved: 31826.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 277\n",
      "Allocated: 10823.07 MB\n",
      "Reserved: 70632.00 MB\n",
      "Allocated: 10823.07 MB\n",
      "Reserved: 29166.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 278\n",
      "Allocated: 10820.66 MB\n",
      "Reserved: 70758.00 MB\n",
      "Allocated: 10820.66 MB\n",
      "Reserved: 30178.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 279\n",
      "Allocated: 10822.74 MB\n",
      "Reserved: 70124.00 MB\n",
      "Allocated: 10822.74 MB\n",
      "Reserved: 31444.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 280\n",
      "Allocated: 10823.08 MB\n",
      "Reserved: 69618.00 MB\n",
      "Allocated: 10823.08 MB\n",
      "Reserved: 27584.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 281\n",
      "Allocated: 10824.91 MB\n",
      "Reserved: 70634.00 MB\n",
      "Allocated: 10824.91 MB\n",
      "Reserved: 26252.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 282\n",
      "Allocated: 10826.16 MB\n",
      "Reserved: 70570.00 MB\n",
      "Allocated: 10826.16 MB\n",
      "Reserved: 32650.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 283\n",
      "Allocated: 10823.60 MB\n",
      "Reserved: 71076.00 MB\n",
      "Allocated: 10823.60 MB\n",
      "Reserved: 31128.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 284\n",
      "Allocated: 10818.01 MB\n",
      "Reserved: 71202.00 MB\n",
      "Allocated: 10818.01 MB\n",
      "Reserved: 36130.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 285\n",
      "Allocated: 10821.52 MB\n",
      "Reserved: 71456.00 MB\n",
      "Allocated: 10821.52 MB\n",
      "Reserved: 35498.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 286\n",
      "Allocated: 10822.27 MB\n",
      "Reserved: 70378.00 MB\n",
      "Allocated: 10822.27 MB\n",
      "Reserved: 30304.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 287\n",
      "Allocated: 10824.75 MB\n",
      "Reserved: 71706.00 MB\n",
      "Allocated: 10824.75 MB\n",
      "Reserved: 32632.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 288\n",
      "Allocated: 10818.12 MB\n",
      "Reserved: 71060.00 MB\n",
      "Allocated: 10818.12 MB\n",
      "Reserved: 34080.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 289\n",
      "Allocated: 10818.28 MB\n",
      "Reserved: 71114.00 MB\n",
      "Allocated: 10818.28 MB\n",
      "Reserved: 32180.00 MB\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3001/3942127936.py:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed batch 290\n",
      "Allocated: 10824.10 MB\n",
      "Reserved: 69594.00 MB\n",
      "Allocated: 10824.10 MB\n",
      "Reserved: 35218.00 MB\n",
      "Epoch [1/1], Loss: inf\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "model.train()\n",
    "model.configure_activation_checkpointing()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=5e-6)\n",
    "# scaler = torch.cuda.amp.GradScaler() #\n",
    "scaler = torch.amp.GradScaler('cuda') #\n",
    "\n",
    "ctr = 1\n",
    "num_epochs = 1\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "for epoch in range(num_epochs):  # Loop over epochs\n",
    "    # model.train()  # Set model to training mode\n",
    "    for batch in dataloader:  # Iterate over batches\n",
    "        # Unpack the batch\n",
    "        features, labels = batch  # Ensure your Dataset and collate function return the right format\n",
    "        # Move data to the appropriate device\n",
    "        # features = {key: val.to(device) for key, val in features.items()}  # For dict-based features\n",
    "        labels = labels.to(device)\n",
    "        features = features.to(device)\n",
    "        # print(features.surf_vars[\"lst\"])\n",
    "        # print(features)\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Forward pass\n",
    "            # outputs = model(features)\n",
    "            pred = model.forward(features)\n",
    "            # print(pred.surf_vars[\"lst\"])\n",
    "            # pred is already on gpu \n",
    "            # pred = pred.to(device)[\n",
    "            # print(features)\n",
    "            # Compute the loss\n",
    "            loss = loss_func(labels,pred)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        scaler.scale(loss).backward()  # Backpropagate  nan occurs here \n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! gradient clipping!\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        # optimizer.step()  # Update the weights\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        # torch.cuda.empty_cache()\n",
    "        print(f\"computed batch {ctr}\")\n",
    "        ctr += 1\n",
    "        \n",
    "        # Debug memory usage\n",
    "        print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "        print(f\"Reserved: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"Allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "        print(f\"Reserved: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## freeing memory after restarting model\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### some debug stuff (not important for runing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training \n",
    "\n",
    "model.train()\n",
    "model.configure_activation_checkpointing()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=5e-6)\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "model.configure_activation_checkpointing()\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "num_epochs = 1\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(num_epochs):  # Loop over epochs\n",
    "    # model.train()  # Set model to training mode\n",
    "    for batch in dataloader:  # Iterate over batches\n",
    "        # Unpack the batch\n",
    "        features, labels = batch  # Ensure your Dataset and collate function return the right format\n",
    "        # Move data to the appropriate device\n",
    "        # features = {key: val.to(device) for key, val in features.items()}  # For dict-based features\n",
    "        labels = labels.to(device)\n",
    "        # features = features.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        # outputs = model(features)\n",
    "        pred = model.forward(features)\n",
    "        # pred is already on gpu \n",
    "        # pred = pred.to(device)[\n",
    "        print(pred)\n",
    "        # Compute the loss\n",
    "        loss = loss_func(labels,pred)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        loss.backward()  # Backpropagate\n",
    "        optimizer.step()  # Update the weights\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"computed first batch\")\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "xprtvhnG_KTC",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(surf_vars={'2t': tensor([[[[248.2111, 250.3261, 250.2283,  ..., 249.8091, 250.0388, 247.3506],\n",
      "          [256.5222, 255.5726, 255.3369,  ..., 255.0719, 255.2536, 245.8392],\n",
      "          [252.1862, 253.3263, 249.0282,  ..., 253.4009, 249.3633, 248.7849],\n",
      "          ...,\n",
      "          [243.7909, 243.7615, 243.8710,  ..., 243.7093, 243.9118, 244.1356],\n",
      "          [244.0923, 243.9736, 244.1088,  ..., 243.8568, 243.9820, 244.0134],\n",
      "          [243.9003, 243.9125, 243.7339,  ..., 243.9700, 243.8595, 243.8047]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), '10u': tensor([[[[  3.5809,   3.3212,   1.3584,  ...,   3.0293,   1.0162,   3.7811],\n",
      "          [ -7.9823,  -7.5491,  -9.8704,  ...,  -7.3736,  -9.8940,  -7.1199],\n",
      "          [ -4.5390,  -4.3756, -10.2827,  ...,  -4.1192, -10.1291,  -8.2069],\n",
      "          ...,\n",
      "          [ -3.3834,  -3.3105,  -3.2968,  ...,  -3.2817,  -3.2331,  -3.3291],\n",
      "          [ -3.0977,  -3.0532,  -3.0555,  ...,  -3.1011,  -3.0014,  -3.0439],\n",
      "          [ -2.4023,  -2.4306,  -2.3970,  ...,  -2.4638,  -2.3741,  -2.2763]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), '10v': tensor([[[[-4.8749, -1.2925, -0.4796,  ..., -1.0154, -0.1611,  0.7960],\n",
      "          [-2.6293, -1.7394, -1.4694,  ..., -1.5712, -1.2151,  3.4068],\n",
      "          [ 0.5379, -0.9354, -0.7567,  ..., -0.7018, -0.6208,  0.2830],\n",
      "          ...,\n",
      "          [-2.6891, -2.6745, -2.6719,  ..., -2.5535, -2.6514, -2.7031],\n",
      "          [-2.9315, -2.9306, -2.8654,  ..., -2.8884, -2.8488, -2.7900],\n",
      "          [-3.1042, -3.1675, -3.1209,  ..., -3.2550, -3.2691, -3.1589]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), 'msl': tensor([[[[103155.7656, 103171.0000, 103361.3047,  ..., 103188.6484,\n",
      "           103373.1875, 103779.3672],\n",
      "          [103120.0859, 103376.4766, 103393.4688,  ..., 103378.6484,\n",
      "           103400.9844, 103553.7812],\n",
      "          [103412.0781, 103079.2734, 103266.9062,  ..., 103085.9062,\n",
      "           103279.3438, 103561.0078],\n",
      "          ...,\n",
      "          [100833.1016, 100828.8125, 100829.6875,  ..., 100808.6406,\n",
      "           100802.8594, 100802.4453],\n",
      "          [100774.3750, 100774.4766, 100769.6016,  ..., 100749.1953,\n",
      "           100748.4609, 100745.7109],\n",
      "          [100688.2344, 100688.4688, 100685.4922,  ..., 100670.0000,\n",
      "           100671.0859, 100670.5078]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>), 'fire': tensor([[[[ 1.5725,  0.3635,  0.8169,  ..., -0.1089,  0.8450, -0.9450],\n",
      "          [-3.1510,  1.6862,  0.6224,  ...,  1.7762,  1.0274,  1.3167],\n",
      "          [-0.6240, -1.8756, -0.5867,  ..., -1.8165, -0.6199,  1.8486],\n",
      "          ...,\n",
      "          [-0.2371, -1.0532,  0.0192,  ..., -1.2139,  0.2721,  0.7380],\n",
      "          [-0.1559, -0.3128, -0.3330,  ...,  0.2921, -0.4360, -0.2993],\n",
      "          [ 0.9598, -0.6867,  0.8512,  ..., -0.9127,  0.7003, -0.1197]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), 'lst': tensor([[[[ 4.8698e+03,  1.5610e+04,  1.5298e+04,  ...,  1.5687e+04,\n",
      "            1.1844e+04, -5.5840e+00],\n",
      "          [ 3.0194e+04,  8.0828e+03,  3.5916e+04,  ...,  1.0033e+04,\n",
      "            3.8131e+04,  1.9069e+04],\n",
      "          [-6.9910e+03,  3.3224e+04,  1.3953e+04,  ...,  3.1893e+04,\n",
      "            1.5527e+04,  3.5842e+03],\n",
      "          ...,\n",
      "          [ 1.4429e+04,  1.1851e+04,  1.4179e+04,  ...,  1.3554e+04,\n",
      "            1.5518e+04,  1.2642e+04],\n",
      "          [ 9.4710e+03,  1.5647e+04,  1.1613e+04,  ...,  1.5155e+04,\n",
      "            1.1074e+04,  6.2063e+02],\n",
      "          [ 1.9149e+04,  7.6491e+03,  8.3493e+03,  ...,  6.5968e+03,\n",
      "            8.6703e+03,  7.4523e+03]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)}, static_vars={'z': tensor([[ 3.2275e-01,  3.2275e-01,  3.2275e-01,  ...,  3.2275e-01,\n",
      "          3.2275e-01,  3.2275e-01],\n",
      "        [ 4.6157e+00,  4.6040e+00,  4.5884e+00,  ...,  4.7915e+00,\n",
      "          4.7329e+00,  4.6743e+00],\n",
      "        [-1.7710e+00, -1.7163e+00, -1.7085e+00,  ..., -1.5093e+00,\n",
      "         -1.6226e+00, -1.7124e+00],\n",
      "        ...,\n",
      "        [ 2.6638e+04,  2.6642e+04,  2.6647e+04,  ...,  2.6627e+04,\n",
      "          2.6631e+04,  2.6634e+04],\n",
      "        [ 2.6958e+04,  2.6961e+04,  2.6965e+04,  ...,  2.6950e+04,\n",
      "          2.6953e+04,  2.6956e+04],\n",
      "        [ 2.7163e+04,  2.7165e+04,  2.7167e+04,  ...,  2.7159e+04,\n",
      "          2.7160e+04,  2.7162e+04]], device='cuda:0'), 'slt': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0'), 'lsm': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')}, atmos_vars={'t': tensor([[[[[253.0678, 252.9532, 252.9864,  ..., 251.7806, 251.8700,\n",
      "            251.9760],\n",
      "           [253.4178, 253.4042, 253.4882,  ..., 252.3365, 252.4279,\n",
      "            252.4541],\n",
      "           [253.7226, 253.7266, 253.7775,  ..., 252.9057, 252.9408,\n",
      "            252.9969],\n",
      "           ...,\n",
      "           [261.3773, 261.2387, 261.1628,  ..., 261.0561, 260.9697,\n",
      "            260.8234],\n",
      "           [261.9394, 261.8354, 261.8147,  ..., 261.9169, 261.9153,\n",
      "            261.9816],\n",
      "           [262.4042, 262.3528, 262.3931,  ..., 262.5049, 262.5680,\n",
      "            262.7904]],\n",
      "\n",
      "          [[252.4198, 252.3776, 252.4197,  ..., 252.1685, 252.2280,\n",
      "            252.2712],\n",
      "           [253.0806, 253.0798, 253.1377,  ..., 252.8577, 252.9245,\n",
      "            252.8753],\n",
      "           [253.7554, 253.7547, 253.7312,  ..., 253.5182, 253.4987,\n",
      "            253.5080],\n",
      "           ...,\n",
      "           [258.3848, 258.4144, 258.4585,  ..., 258.3852, 258.4243,\n",
      "            258.3203],\n",
      "           [258.8112, 258.8616, 258.9091,  ..., 258.9735, 259.0275,\n",
      "            259.0441],\n",
      "           [259.4121, 259.4465, 259.4864,  ..., 259.5492, 259.6006,\n",
      "            259.7372]],\n",
      "\n",
      "          [[252.9567, 252.9086, 252.9028,  ..., 252.6964, 252.7074,\n",
      "            252.6855],\n",
      "           [252.6675, 252.6472, 252.6939,  ..., 252.5457, 252.6081,\n",
      "            252.5219],\n",
      "           [252.5254, 252.5084, 252.5084,  ..., 252.4644, 252.4772,\n",
      "            252.4867],\n",
      "           ...,\n",
      "           [262.9765, 262.9539, 263.0072,  ..., 263.0193, 263.0688,\n",
      "            263.0918],\n",
      "           [263.2308, 263.1952, 263.2193,  ..., 263.2718, 263.3070,\n",
      "            263.3098],\n",
      "           [263.7971, 263.7460, 263.6963,  ..., 263.8141, 263.7764,\n",
      "            263.8120]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[215.7774, 215.7905, 215.7873,  ..., 215.8403, 215.8383,\n",
      "            215.8670],\n",
      "           [215.6535, 215.6604, 215.6744,  ..., 215.7962, 215.8080,\n",
      "            215.8305],\n",
      "           [215.5596, 215.5681, 215.5955,  ..., 215.7561, 215.7763,\n",
      "            215.7827],\n",
      "           ...,\n",
      "           [222.9413, 222.8996, 222.8862,  ..., 222.9042, 222.8959,\n",
      "            222.8888],\n",
      "           [223.0718, 223.0785, 223.1065,  ..., 223.0714, 223.1014,\n",
      "            223.1091],\n",
      "           [223.4280, 223.4832, 223.5437,  ..., 223.4890, 223.5499,\n",
      "            223.5925]],\n",
      "\n",
      "          [[218.2388, 218.2704, 218.3143,  ..., 218.0867, 218.1241,\n",
      "            218.1765],\n",
      "           [218.1566, 218.1404, 218.1792,  ..., 217.8495, 217.8852,\n",
      "            217.9456],\n",
      "           [218.0021, 217.9844, 218.0129,  ..., 217.6137, 217.6475,\n",
      "            217.6447],\n",
      "           ...,\n",
      "           [219.7470, 219.7549, 219.7881,  ..., 219.4391, 219.4781,\n",
      "            219.5555],\n",
      "           [219.6489, 219.5802, 219.5976,  ..., 219.3261, 219.3538,\n",
      "            219.4439],\n",
      "           [219.5512, 219.4889, 219.4921,  ..., 219.3181, 219.3329,\n",
      "            219.4777]],\n",
      "\n",
      "          [[219.1212, 219.0997, 219.1038,  ..., 219.1952, 219.1909,\n",
      "            219.2191],\n",
      "           [219.0377, 218.9825, 218.9808,  ..., 219.1083, 219.1022,\n",
      "            219.1252],\n",
      "           [218.9314, 218.8918, 218.8762,  ..., 219.0464, 219.0352,\n",
      "            218.9960],\n",
      "           ...,\n",
      "           [220.3796, 220.3489, 220.3890,  ..., 219.9069, 219.9408,\n",
      "            219.9239],\n",
      "           [220.2174, 220.2134, 220.2170,  ..., 219.7851, 219.7827,\n",
      "            219.7500],\n",
      "           [220.1246, 220.1093, 220.0896,  ..., 219.7009, 219.6754,\n",
      "            219.6900]]]]], device='cuda:0', grad_fn=<AddBackward0>), 'u': tensor([[[[[ 1.0762e+00,  1.0854e+00,  1.1057e+00,  ...,  1.0287e+00,\n",
      "             1.0687e+00,  1.0801e+00],\n",
      "           [ 6.5479e-01,  6.3843e-01,  6.6259e-01,  ...,  4.5452e-01,\n",
      "             4.8658e-01,  5.4663e-01],\n",
      "           [-1.5553e+00, -1.5866e+00, -1.5640e+00,  ..., -1.5490e+00,\n",
      "            -1.5160e+00, -1.4330e+00],\n",
      "           ...,\n",
      "           [-4.2356e+00, -4.1951e+00, -4.0891e+00,  ..., -4.0725e+00,\n",
      "            -3.9621e+00, -3.8797e+00],\n",
      "           [-4.1658e+00, -4.1273e+00, -4.0059e+00,  ..., -4.1724e+00,\n",
      "            -4.0091e+00, -3.8773e+00],\n",
      "           [-3.6949e+00, -3.6706e+00, -3.5840e+00,  ..., -3.7512e+00,\n",
      "            -3.6220e+00, -3.5105e+00]],\n",
      "\n",
      "          [[ 7.2803e-01,  7.2235e-01,  7.7324e-01,  ...,  5.8227e-01,\n",
      "             6.2560e-01,  6.5693e-01],\n",
      "           [ 2.7366e+00,  2.7021e+00,  2.7070e+00,  ...,  2.4770e+00,\n",
      "             2.4691e+00,  2.4731e+00],\n",
      "           [ 9.2238e-01,  8.9103e-01,  8.7025e-01,  ...,  8.7683e-01,\n",
      "             8.4745e-01,  8.2801e-01],\n",
      "           ...,\n",
      "           [-4.4971e+00, -4.5013e+00, -4.5235e+00,  ..., -4.4392e+00,\n",
      "            -4.4652e+00, -4.4755e+00],\n",
      "           [-4.0764e+00, -4.1040e+00, -4.1268e+00,  ..., -4.0923e+00,\n",
      "            -4.1087e+00, -4.1354e+00],\n",
      "           [-3.5986e+00, -3.6421e+00, -3.6747e+00,  ..., -3.6700e+00,\n",
      "            -3.6863e+00, -3.6594e+00]],\n",
      "\n",
      "          [[ 9.3481e-01,  9.1480e-01,  9.3193e-01,  ...,  7.8862e-01,\n",
      "             8.1288e-01,  8.4617e-01],\n",
      "           [ 3.5463e+00,  3.5405e+00,  3.5248e+00,  ...,  3.3973e+00,\n",
      "             3.3899e+00,  3.3794e+00],\n",
      "           [ 2.0491e+00,  2.0626e+00,  2.0417e+00,  ...,  2.0445e+00,\n",
      "             2.0334e+00,  1.9801e+00],\n",
      "           ...,\n",
      "           [-4.0314e+00, -4.1169e+00, -4.1879e+00,  ..., -3.9975e+00,\n",
      "            -4.0748e+00, -4.0924e+00],\n",
      "           [-3.8320e+00, -3.8847e+00, -3.8979e+00,  ..., -3.8697e+00,\n",
      "            -3.8847e+00, -3.9059e+00],\n",
      "           [-3.4170e+00, -3.4484e+00, -3.4453e+00,  ..., -3.4643e+00,\n",
      "            -3.4507e+00, -3.4422e+00]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-3.8785e-01, -4.8306e-01, -5.2313e-01,  ..., -7.6543e-01,\n",
      "            -8.2480e-01, -9.0477e-01],\n",
      "           [-1.2112e+01, -1.2100e+01, -1.2170e+01,  ..., -1.1839e+01,\n",
      "            -1.1953e+01, -1.2084e+01],\n",
      "           [-1.2122e+01, -1.2142e+01, -1.2079e+01,  ..., -1.1907e+01,\n",
      "            -1.1873e+01, -1.1962e+01],\n",
      "           ...,\n",
      "           [-1.8366e+00, -1.9865e+00, -2.1571e+00,  ..., -2.0648e+00,\n",
      "            -2.2363e+00, -2.4399e+00],\n",
      "           [-1.5947e+00, -1.6515e+00, -1.6455e+00,  ..., -1.6683e+00,\n",
      "            -1.6643e+00, -1.7934e+00],\n",
      "           [-1.4896e+00, -1.5200e+00, -1.4860e+00,  ..., -1.4557e+00,\n",
      "            -1.4316e+00, -1.4954e+00]],\n",
      "\n",
      "          [[-3.7271e-01, -3.8045e-01, -3.7532e-01,  ...,  5.9234e-02,\n",
      "             2.8181e-02,  6.7933e-02],\n",
      "           [-2.4821e+01, -2.4825e+01, -2.4802e+01,  ..., -2.4214e+01,\n",
      "            -2.4219e+01, -2.4066e+01],\n",
      "           [-2.4013e+01, -2.4160e+01, -2.4109e+01,  ..., -2.3522e+01,\n",
      "            -2.3467e+01, -2.3267e+01],\n",
      "           ...,\n",
      "           [-2.3643e+00, -2.7638e+00, -3.1109e+00,  ..., -2.4837e+00,\n",
      "            -2.8030e+00, -3.0901e+00],\n",
      "           [-2.9680e+00, -3.2458e+00, -3.1576e+00,  ..., -3.0336e+00,\n",
      "            -2.9139e+00, -2.8525e+00],\n",
      "           [-3.5974e+00, -3.6203e+00, -3.2345e+00,  ..., -3.3374e+00,\n",
      "            -2.9478e+00, -2.4521e+00]],\n",
      "\n",
      "          [[-1.2704e+00, -1.2701e+00, -1.2004e+00,  ..., -4.0249e-01,\n",
      "            -3.8435e-01, -3.4056e-01],\n",
      "           [-2.9602e+01, -2.9558e+01, -2.9516e+01,  ..., -2.9463e+01,\n",
      "            -2.9479e+01, -2.9442e+01],\n",
      "           [-2.9224e+01, -2.9253e+01, -2.9133e+01,  ..., -2.9136e+01,\n",
      "            -2.9038e+01, -2.8901e+01],\n",
      "           ...,\n",
      "           [-3.5017e+00, -3.9833e+00, -4.5368e+00,  ..., -3.8546e+00,\n",
      "            -4.4206e+00, -4.8193e+00],\n",
      "           [-4.5844e+00, -4.8548e+00, -4.8941e+00,  ..., -4.7224e+00,\n",
      "            -4.7655e+00, -4.6885e+00],\n",
      "           [-5.3787e+00, -5.3912e+00, -5.1718e+00,  ..., -5.3021e+00,\n",
      "            -5.0679e+00, -4.6876e+00]]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>), 'v': tensor([[[[[-0.1439, -0.0378,  0.0457,  ...,  0.0266,  0.1196,  0.2052],\n",
      "           [ 0.7476,  0.8870,  0.9589,  ...,  0.6310,  0.6939,  0.7194],\n",
      "           [ 0.8458,  0.9882,  1.0462,  ...,  0.6539,  0.7319,  0.7490],\n",
      "           ...,\n",
      "           [-1.6353, -1.8233, -2.0816,  ..., -1.8241, -2.1004, -2.3597],\n",
      "           [-2.0015, -2.1386, -2.3180,  ..., -2.0367, -2.2335, -2.4103],\n",
      "           [-1.9367, -2.0118, -2.0975,  ..., -1.9860, -2.0938, -2.2244]],\n",
      "\n",
      "          [[ 0.0601,  0.1564,  0.1570,  ...,  0.0856,  0.1179,  0.0891],\n",
      "           [ 0.1849,  0.2665,  0.2774,  ...,  0.3833,  0.4069,  0.3832],\n",
      "           [ 0.3660,  0.4366,  0.4830,  ...,  0.4886,  0.5375,  0.5621],\n",
      "           ...,\n",
      "           [-1.8977, -2.0183, -2.1157,  ..., -1.9929, -2.0834, -2.2128],\n",
      "           [-2.2929, -2.3458, -2.3735,  ..., -2.2868, -2.3165, -2.4034],\n",
      "           [-2.6694, -2.6601, -2.6430,  ..., -2.6631, -2.6664, -2.7598]],\n",
      "\n",
      "          [[ 0.3854,  0.4470,  0.4661,  ...,  0.3571,  0.4140,  0.4417],\n",
      "           [-0.2293, -0.1463, -0.1009,  ..., -0.1686, -0.1099, -0.0748],\n",
      "           [-0.2768, -0.1530, -0.0562,  ..., -0.1243, -0.0369,  0.0274],\n",
      "           ...,\n",
      "           [-2.1320, -2.1311, -2.1602,  ..., -2.0430, -2.0471, -2.0791],\n",
      "           [-2.3685, -2.3561, -2.3843,  ..., -2.2663, -2.2791, -2.3407],\n",
      "           [-2.5970, -2.5903, -2.6080,  ..., -2.6368, -2.6449, -2.6743]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 0.4233,  0.3810,  0.4165,  ...,  0.4108,  0.4842,  0.6207],\n",
      "           [-3.2482, -3.2240, -3.1537,  ..., -4.1391, -4.0416, -3.9070],\n",
      "           [-2.4103, -2.4057, -2.3373,  ..., -3.2102, -3.1302, -3.0032],\n",
      "           ...,\n",
      "           [ 1.4330,  1.4266,  1.4371,  ...,  1.5219,  1.5354,  1.5183],\n",
      "           [ 1.4096,  1.3056,  1.1992,  ...,  1.3715,  1.2651,  1.1739],\n",
      "           [ 1.6519,  1.4228,  1.2342,  ...,  1.4253,  1.2365,  0.9679]],\n",
      "\n",
      "          [[-0.1239, -0.2172, -0.2713,  ..., -0.2169, -0.2517, -0.2349],\n",
      "           [-4.8543, -4.8110, -4.7477,  ..., -5.5473, -5.4755, -5.3468],\n",
      "           [-4.5133, -4.4932, -4.4277,  ..., -5.2759, -5.2028, -5.0800],\n",
      "           ...,\n",
      "           [ 0.2944,  0.2050,  0.0800,  ...,  0.1119,  0.0190, -0.1348],\n",
      "           [ 0.0878, -0.1579, -0.4043,  ..., -0.2968, -0.5259, -0.8251],\n",
      "           [ 0.0233, -0.2702, -0.6823,  ..., -0.5118, -0.9119, -1.3365]],\n",
      "\n",
      "          [[-0.2060, -0.2902, -0.3001,  ..., -0.3867, -0.4228, -0.4177],\n",
      "           [-2.3641, -2.3090, -2.1760,  ..., -2.7494, -2.6425, -2.5142],\n",
      "           [-2.2168, -2.1785, -2.0516,  ..., -2.5424, -2.4287, -2.3294],\n",
      "           ...,\n",
      "           [ 0.5596,  0.2652, -0.0197,  ...,  0.4764,  0.1967, -0.1468],\n",
      "           [ 0.5612,  0.2917,  0.0341,  ...,  0.4758,  0.2232, -0.0168],\n",
      "           [ 0.6654,  0.4110,  0.1279,  ...,  0.5464,  0.2811,  0.0583]]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), 'q': tensor([[[[[4.9426e-04, 5.1562e-04, 5.2646e-04,  ..., 4.5729e-04,\n",
      "            4.7769e-04, 4.7802e-04],\n",
      "           [5.3328e-04, 5.4159e-04, 5.4558e-04,  ..., 4.8678e-04,\n",
      "            4.9476e-04, 5.0067e-04],\n",
      "           [5.4074e-04, 5.5389e-04, 5.3410e-04,  ..., 5.0518e-04,\n",
      "            4.8393e-04, 4.8613e-04],\n",
      "           ...,\n",
      "           [5.2098e-04, 5.4168e-04, 5.6810e-04,  ..., 5.5508e-04,\n",
      "            5.8315e-04, 5.8383e-04],\n",
      "           [4.6724e-04, 5.0790e-04, 5.2666e-04,  ..., 5.1258e-04,\n",
      "            5.3761e-04, 5.5207e-04],\n",
      "           [4.6079e-04, 4.8549e-04, 5.1996e-04,  ..., 4.7414e-04,\n",
      "            5.1691e-04, 5.3847e-04]],\n",
      "\n",
      "          [[4.8316e-04, 5.0846e-04, 5.2829e-04,  ..., 5.1613e-04,\n",
      "            5.3825e-04, 5.3470e-04],\n",
      "           [5.3821e-04, 5.4529e-04, 5.6039e-04,  ..., 5.6506e-04,\n",
      "            5.7669e-04, 5.8269e-04],\n",
      "           [5.7304e-04, 5.8800e-04, 5.7793e-04,  ..., 6.1407e-04,\n",
      "            5.9796e-04, 5.9863e-04],\n",
      "           ...,\n",
      "           [4.2458e-04, 4.1608e-04, 4.2025e-04,  ..., 4.1749e-04,\n",
      "            4.2603e-04, 4.3917e-04],\n",
      "           [3.6894e-04, 3.9303e-04, 3.8764e-04,  ..., 3.9268e-04,\n",
      "            3.9052e-04, 4.0247e-04],\n",
      "           [3.4996e-04, 3.5526e-04, 3.7220e-04,  ..., 3.6206e-04,\n",
      "            3.7687e-04, 3.8701e-04]],\n",
      "\n",
      "          [[1.9930e-04, 2.0702e-04, 2.1056e-04,  ..., 2.1528e-04,\n",
      "            2.1253e-04, 1.9432e-04],\n",
      "           [2.3547e-04, 2.3308e-04, 2.3489e-04,  ..., 2.5215e-04,\n",
      "            2.4632e-04, 2.3693e-04],\n",
      "           [2.8267e-04, 2.9178e-04, 2.7767e-04,  ..., 3.1301e-04,\n",
      "            2.9244e-04, 2.7613e-04],\n",
      "           ...,\n",
      "           [6.8323e-04, 6.7809e-04, 6.5805e-04,  ..., 6.7973e-04,\n",
      "            6.5955e-04, 6.3310e-04],\n",
      "           [6.8578e-04, 7.0348e-04, 6.8047e-04,  ..., 7.1211e-04,\n",
      "            6.8846e-04, 6.7504e-04],\n",
      "           [6.8027e-04, 7.0837e-04, 7.2111e-04,  ..., 7.3787e-04,\n",
      "            7.5745e-04, 7.6570e-04]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[4.0416e-06, 4.2117e-06, 4.3480e-06,  ..., 4.2685e-06,\n",
      "            4.3593e-06, 4.2851e-06],\n",
      "           [4.0513e-06, 4.0884e-06, 4.1855e-06,  ..., 4.0426e-06,\n",
      "            4.1171e-06, 4.0518e-06],\n",
      "           [3.9099e-06, 3.9317e-06, 3.9435e-06,  ..., 3.8096e-06,\n",
      "            3.8109e-06, 3.8372e-06],\n",
      "           ...,\n",
      "           [2.5676e-06, 2.5066e-06, 2.5761e-06,  ..., 2.5761e-06,\n",
      "            2.6661e-06, 2.6758e-06],\n",
      "           [2.3468e-06, 2.2202e-06, 2.2297e-06,  ..., 2.2595e-06,\n",
      "            2.2781e-06, 2.3795e-06],\n",
      "           [2.4962e-06, 2.2913e-06, 2.1947e-06,  ..., 2.3323e-06,\n",
      "            2.2140e-06, 2.2276e-06]],\n",
      "\n",
      "          [[2.8873e-06, 2.8855e-06, 2.8813e-06,  ..., 2.8858e-06,\n",
      "            2.8817e-06, 2.8761e-06],\n",
      "           [2.8658e-06, 2.8638e-06, 2.8620e-06,  ..., 2.8627e-06,\n",
      "            2.8608e-06, 2.8562e-06],\n",
      "           [2.8390e-06, 2.8372e-06, 2.8375e-06,  ..., 2.8356e-06,\n",
      "            2.8350e-06, 2.8313e-06],\n",
      "           ...,\n",
      "           [2.4948e-06, 2.5120e-06, 2.5156e-06,  ..., 2.5084e-06,\n",
      "            2.5144e-06, 2.5042e-06],\n",
      "           [2.4615e-06, 2.4780e-06, 2.4889e-06,  ..., 2.4872e-06,\n",
      "            2.4979e-06, 2.4963e-06],\n",
      "           [2.4511e-06, 2.4604e-06, 2.4703e-06,  ..., 2.4719e-06,\n",
      "            2.4800e-06, 2.4747e-06]],\n",
      "\n",
      "          [[2.8886e-06, 2.8890e-06, 2.8895e-06,  ..., 2.8843e-06,\n",
      "            2.8847e-06, 2.8852e-06],\n",
      "           [2.8900e-06, 2.8899e-06, 2.8904e-06,  ..., 2.8885e-06,\n",
      "            2.8889e-06, 2.8882e-06],\n",
      "           [2.8864e-06, 2.8857e-06, 2.8863e-06,  ..., 2.8879e-06,\n",
      "            2.8887e-06, 2.8889e-06],\n",
      "           ...,\n",
      "           [2.5637e-06, 2.5780e-06, 2.5852e-06,  ..., 2.5829e-06,\n",
      "            2.5894e-06, 2.5849e-06],\n",
      "           [2.5443e-06, 2.5597e-06, 2.5709e-06,  ..., 2.5653e-06,\n",
      "            2.5759e-06, 2.5760e-06],\n",
      "           [2.5434e-06, 2.5494e-06, 2.5517e-06,  ..., 2.5540e-06,\n",
      "            2.5569e-06, 2.5532e-06]]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>), 'z': tensor([[[[[  1761.7148,   1764.4604,   1766.3538,  ...,   1787.5542,\n",
      "              1787.4548,   1783.9109],\n",
      "           [  1786.0374,   1788.0220,   1788.5989,  ...,   1798.6658,\n",
      "              1798.3684,   1797.7231],\n",
      "           [  1797.9878,   1798.1343,   1802.0554,  ...,   1800.7249,\n",
      "              1804.8792,   1803.4526],\n",
      "           ...,\n",
      "           [   344.1989,    345.8950,    347.1611,  ...,    354.2242,\n",
      "               356.3124,    354.1271],\n",
      "           [   315.5240,    315.6721,    311.7759,  ...,    312.7455,\n",
      "               309.0732,    305.5089],\n",
      "           [   292.1935,    287.4634,    279.4576,  ...,    287.6305,\n",
      "               279.9420,    273.5722]],\n",
      "\n",
      "          [[  7428.7642,   7429.7104,   7431.8838,  ...,   7433.7246,\n",
      "              7435.1704,   7435.8359],\n",
      "           [  7456.6479,   7456.3633,   7456.9067,  ...,   7456.0195,\n",
      "              7456.1450,   7455.7988],\n",
      "           [  7475.6357,   7475.4448,   7476.9043,  ...,   7471.5566,\n",
      "              7472.8281,   7472.9858],\n",
      "           ...,\n",
      "           [  6279.3071,   6277.7061,   6279.8838,  ...,   6275.6484,\n",
      "              6278.7324,   6280.0908],\n",
      "           [  6257.7695,   6258.8730,   6260.1255,  ...,   6252.8701,\n",
      "              6254.8555,   6256.1851],\n",
      "           [  6231.8765,   6234.0840,   6236.5898,  ...,   6236.3247,\n",
      "              6239.0308,   6237.9790]],\n",
      "\n",
      "          [[ 13582.7354,  13585.0078,  13585.2041,  ...,  13583.2393,\n",
      "             13582.8945,  13582.6191],\n",
      "           [ 13608.7061,  13610.2031,  13610.6484,  ...,  13605.8838,\n",
      "             13605.7744,  13606.6670],\n",
      "           [ 13629.3174,  13628.8506,  13630.9160,  ...,  13622.3389,\n",
      "             13623.9785,  13623.2207],\n",
      "           ...,\n",
      "           [ 12695.2959,  12693.5430,  12698.5918,  ...,  12687.1064,\n",
      "             12692.9502,  12696.6182],\n",
      "           [ 12686.7051,  12689.2871,  12690.2744,  ...,  12680.5029,\n",
      "             12681.9297,  12687.2910],\n",
      "           [ 12668.9355,  12673.3105,  12678.2764,  ...,  12667.9004,\n",
      "             12673.1045,  12673.7959]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[108562.4922, 108575.3359, 108566.7812,  ..., 108572.2031,\n",
      "            108563.4141, 108568.6641],\n",
      "           [108494.4844, 108494.6250, 108501.6484,  ..., 108495.4688,\n",
      "            108502.7344, 108536.7578],\n",
      "           [108475.5781, 108464.7578, 108483.3203,  ..., 108470.1875,\n",
      "            108489.5312, 108473.3047],\n",
      "           ...,\n",
      "           [108991.2812, 108983.8672, 108995.6328,  ..., 109022.0547,\n",
      "            109034.7969, 109046.9219],\n",
      "           [108996.4297, 109007.1016, 109009.7500,  ..., 109045.0547,\n",
      "            109049.1797, 109058.5625],\n",
      "           [108994.1641, 109004.1953, 109014.2188,  ..., 109043.0781,\n",
      "            109054.8906, 109055.7891]],\n",
      "\n",
      "          [[151849.5000, 151858.5469, 151855.0156,  ..., 151867.1094,\n",
      "            151863.9375, 151876.0312],\n",
      "           [151726.7812, 151728.8438, 151733.6094,  ..., 151744.2969,\n",
      "            151749.0625, 151776.2188],\n",
      "           [151649.7656, 151650.6562, 151661.2031,  ..., 151671.2344,\n",
      "            151680.8438, 151670.4375],\n",
      "           ...,\n",
      "           [153666.8906, 153660.9531, 153667.0625,  ..., 153697.9531,\n",
      "            153706.0781, 153689.9219],\n",
      "           [153645.9688, 153667.7344, 153667.6094,  ..., 153701.2656,\n",
      "            153703.3281, 153712.5938],\n",
      "           [153619.0000, 153636.4375, 153646.7656,  ..., 153666.2188,\n",
      "            153679.5469, 153678.7188]],\n",
      "\n",
      "          [[195122.4531, 195116.5625, 195119.7969,  ..., 195105.7188,\n",
      "            195108.6875, 195126.4062],\n",
      "           [194978.0469, 194973.2031, 194978.6562,  ..., 194972.2500,\n",
      "            194976.4531, 194984.1250],\n",
      "           [194844.2188, 194861.0469, 194855.2969,  ..., 194869.4062,\n",
      "            194862.3906, 194870.5625],\n",
      "           ...,\n",
      "           [196654.6250, 196658.1094, 196671.3438,  ..., 196638.2500,\n",
      "            196655.7812, 196652.0625],\n",
      "           [196654.4688, 196686.3125, 196692.3906,  ..., 196658.9688,\n",
      "            196667.5312, 196704.0625],\n",
      "           [196666.7344, 196681.0469, 196707.0156,  ..., 196646.6094,\n",
      "            196674.8906, 196689.9219]]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)}, metadata=Metadata(lat=tensor([ 90.0000,  89.7500,  89.5000,  89.2500,  89.0000,  88.7500,  88.5000,\n",
      "         88.2500,  88.0000,  87.7500,  87.5000,  87.2500,  87.0000,  86.7500,\n",
      "         86.5000,  86.2500,  86.0000,  85.7500,  85.5000,  85.2500,  85.0000,\n",
      "         84.7500,  84.5000,  84.2500,  84.0000,  83.7500,  83.5000,  83.2500,\n",
      "         83.0000,  82.7500,  82.5000,  82.2500,  82.0000,  81.7500,  81.5000,\n",
      "         81.2500,  81.0000,  80.7500,  80.5000,  80.2500,  80.0000,  79.7500,\n",
      "         79.5000,  79.2500,  79.0000,  78.7500,  78.5000,  78.2500,  78.0000,\n",
      "         77.7500,  77.5000,  77.2500,  77.0000,  76.7500,  76.5000,  76.2500,\n",
      "         76.0000,  75.7500,  75.5000,  75.2500,  75.0000,  74.7500,  74.5000,\n",
      "         74.2500,  74.0000,  73.7500,  73.5000,  73.2500,  73.0000,  72.7500,\n",
      "         72.5000,  72.2500,  72.0000,  71.7500,  71.5000,  71.2500,  71.0000,\n",
      "         70.7500,  70.5000,  70.2500,  70.0000,  69.7500,  69.5000,  69.2500,\n",
      "         69.0000,  68.7500,  68.5000,  68.2500,  68.0000,  67.7500,  67.5000,\n",
      "         67.2500,  67.0000,  66.7500,  66.5000,  66.2500,  66.0000,  65.7500,\n",
      "         65.5000,  65.2500,  65.0000,  64.7500,  64.5000,  64.2500,  64.0000,\n",
      "         63.7500,  63.5000,  63.2500,  63.0000,  62.7500,  62.5000,  62.2500,\n",
      "         62.0000,  61.7500,  61.5000,  61.2500,  61.0000,  60.7500,  60.5000,\n",
      "         60.2500,  60.0000,  59.7500,  59.5000,  59.2500,  59.0000,  58.7500,\n",
      "         58.5000,  58.2500,  58.0000,  57.7500,  57.5000,  57.2500,  57.0000,\n",
      "         56.7500,  56.5000,  56.2500,  56.0000,  55.7500,  55.5000,  55.2500,\n",
      "         55.0000,  54.7500,  54.5000,  54.2500,  54.0000,  53.7500,  53.5000,\n",
      "         53.2500,  53.0000,  52.7500,  52.5000,  52.2500,  52.0000,  51.7500,\n",
      "         51.5000,  51.2500,  51.0000,  50.7500,  50.5000,  50.2500,  50.0000,\n",
      "         49.7500,  49.5000,  49.2500,  49.0000,  48.7500,  48.5000,  48.2500,\n",
      "         48.0000,  47.7500,  47.5000,  47.2500,  47.0000,  46.7500,  46.5000,\n",
      "         46.2500,  46.0000,  45.7500,  45.5000,  45.2500,  45.0000,  44.7500,\n",
      "         44.5000,  44.2500,  44.0000,  43.7500,  43.5000,  43.2500,  43.0000,\n",
      "         42.7500,  42.5000,  42.2500,  42.0000,  41.7500,  41.5000,  41.2500,\n",
      "         41.0000,  40.7500,  40.5000,  40.2500,  40.0000,  39.7500,  39.5000,\n",
      "         39.2500,  39.0000,  38.7500,  38.5000,  38.2500,  38.0000,  37.7500,\n",
      "         37.5000,  37.2500,  37.0000,  36.7500,  36.5000,  36.2500,  36.0000,\n",
      "         35.7500,  35.5000,  35.2500,  35.0000,  34.7500,  34.5000,  34.2500,\n",
      "         34.0000,  33.7500,  33.5000,  33.2500,  33.0000,  32.7500,  32.5000,\n",
      "         32.2500,  32.0000,  31.7500,  31.5000,  31.2500,  31.0000,  30.7500,\n",
      "         30.5000,  30.2500,  30.0000,  29.7500,  29.5000,  29.2500,  29.0000,\n",
      "         28.7500,  28.5000,  28.2500,  28.0000,  27.7500,  27.5000,  27.2500,\n",
      "         27.0000,  26.7500,  26.5000,  26.2500,  26.0000,  25.7500,  25.5000,\n",
      "         25.2500,  25.0000,  24.7500,  24.5000,  24.2500,  24.0000,  23.7500,\n",
      "         23.5000,  23.2500,  23.0000,  22.7500,  22.5000,  22.2500,  22.0000,\n",
      "         21.7500,  21.5000,  21.2500,  21.0000,  20.7500,  20.5000,  20.2500,\n",
      "         20.0000,  19.7500,  19.5000,  19.2500,  19.0000,  18.7500,  18.5000,\n",
      "         18.2500,  18.0000,  17.7500,  17.5000,  17.2500,  17.0000,  16.7500,\n",
      "         16.5000,  16.2500,  16.0000,  15.7500,  15.5000,  15.2500,  15.0000,\n",
      "         14.7500,  14.5000,  14.2500,  14.0000,  13.7500,  13.5000,  13.2500,\n",
      "         13.0000,  12.7500,  12.5000,  12.2500,  12.0000,  11.7500,  11.5000,\n",
      "         11.2500,  11.0000,  10.7500,  10.5000,  10.2500,  10.0000,   9.7500,\n",
      "          9.5000,   9.2500,   9.0000,   8.7500,   8.5000,   8.2500,   8.0000,\n",
      "          7.7500,   7.5000,   7.2500,   7.0000,   6.7500,   6.5000,   6.2500,\n",
      "          6.0000,   5.7500,   5.5000,   5.2500,   5.0000,   4.7500,   4.5000,\n",
      "          4.2500,   4.0000,   3.7500,   3.5000,   3.2500,   3.0000,   2.7500,\n",
      "          2.5000,   2.2500,   2.0000,   1.7500,   1.5000,   1.2500,   1.0000,\n",
      "          0.7500,   0.5000,   0.2500,   0.0000,  -0.2500,  -0.5000,  -0.7500,\n",
      "         -1.0000,  -1.2500,  -1.5000,  -1.7500,  -2.0000,  -2.2500,  -2.5000,\n",
      "         -2.7500,  -3.0000,  -3.2500,  -3.5000,  -3.7500,  -4.0000,  -4.2500,\n",
      "         -4.5000,  -4.7500,  -5.0000,  -5.2500,  -5.5000,  -5.7500,  -6.0000,\n",
      "         -6.2500,  -6.5000,  -6.7500,  -7.0000,  -7.2500,  -7.5000,  -7.7500,\n",
      "         -8.0000,  -8.2500,  -8.5000,  -8.7500,  -9.0000,  -9.2500,  -9.5000,\n",
      "         -9.7500, -10.0000, -10.2500, -10.5000, -10.7500, -11.0000, -11.2500,\n",
      "        -11.5000, -11.7500, -12.0000, -12.2500, -12.5000, -12.7500, -13.0000,\n",
      "        -13.2500, -13.5000, -13.7500, -14.0000, -14.2500, -14.5000, -14.7500,\n",
      "        -15.0000, -15.2500, -15.5000, -15.7500, -16.0000, -16.2500, -16.5000,\n",
      "        -16.7500, -17.0000, -17.2500, -17.5000, -17.7500, -18.0000, -18.2500,\n",
      "        -18.5000, -18.7500, -19.0000, -19.2500, -19.5000, -19.7500, -20.0000,\n",
      "        -20.2500, -20.5000, -20.7500, -21.0000, -21.2500, -21.5000, -21.7500,\n",
      "        -22.0000, -22.2500, -22.5000, -22.7500, -23.0000, -23.2500, -23.5000,\n",
      "        -23.7500, -24.0000, -24.2500, -24.5000, -24.7500, -25.0000, -25.2500,\n",
      "        -25.5000, -25.7500, -26.0000, -26.2500, -26.5000, -26.7500, -27.0000,\n",
      "        -27.2500, -27.5000, -27.7500, -28.0000, -28.2500, -28.5000, -28.7500,\n",
      "        -29.0000, -29.2500, -29.5000, -29.7500, -30.0000, -30.2500, -30.5000,\n",
      "        -30.7500, -31.0000, -31.2500, -31.5000, -31.7500, -32.0000, -32.2500,\n",
      "        -32.5000, -32.7500, -33.0000, -33.2500, -33.5000, -33.7500, -34.0000,\n",
      "        -34.2500, -34.5000, -34.7500, -35.0000, -35.2500, -35.5000, -35.7500,\n",
      "        -36.0000, -36.2500, -36.5000, -36.7500, -37.0000, -37.2500, -37.5000,\n",
      "        -37.7500, -38.0000, -38.2500, -38.5000, -38.7500, -39.0000, -39.2500,\n",
      "        -39.5000, -39.7500, -40.0000, -40.2500, -40.5000, -40.7500, -41.0000,\n",
      "        -41.2500, -41.5000, -41.7500, -42.0000, -42.2500, -42.5000, -42.7500,\n",
      "        -43.0000, -43.2500, -43.5000, -43.7500, -44.0000, -44.2500, -44.5000,\n",
      "        -44.7500, -45.0000, -45.2500, -45.5000, -45.7500, -46.0000, -46.2500,\n",
      "        -46.5000, -46.7500, -47.0000, -47.2500, -47.5000, -47.7500, -48.0000,\n",
      "        -48.2500, -48.5000, -48.7500, -49.0000, -49.2500, -49.5000, -49.7500,\n",
      "        -50.0000, -50.2500, -50.5000, -50.7500, -51.0000, -51.2500, -51.5000,\n",
      "        -51.7500, -52.0000, -52.2500, -52.5000, -52.7500, -53.0000, -53.2500,\n",
      "        -53.5000, -53.7500, -54.0000, -54.2500, -54.5000, -54.7500, -55.0000,\n",
      "        -55.2500, -55.5000, -55.7500, -56.0000, -56.2500, -56.5000, -56.7500,\n",
      "        -57.0000, -57.2500, -57.5000, -57.7500, -58.0000, -58.2500, -58.5000,\n",
      "        -58.7500, -59.0000, -59.2500, -59.5000, -59.7500, -60.0000, -60.2500,\n",
      "        -60.5000, -60.7500, -61.0000, -61.2500, -61.5000, -61.7500, -62.0000,\n",
      "        -62.2500, -62.5000, -62.7500, -63.0000, -63.2500, -63.5000, -63.7500,\n",
      "        -64.0000, -64.2500, -64.5000, -64.7500, -65.0000, -65.2500, -65.5000,\n",
      "        -65.7500, -66.0000, -66.2500, -66.5000, -66.7500, -67.0000, -67.2500,\n",
      "        -67.5000, -67.7500, -68.0000, -68.2500, -68.5000, -68.7500, -69.0000,\n",
      "        -69.2500, -69.5000, -69.7500, -70.0000, -70.2500, -70.5000, -70.7500,\n",
      "        -71.0000, -71.2500, -71.5000, -71.7500, -72.0000, -72.2500, -72.5000,\n",
      "        -72.7500, -73.0000, -73.2500, -73.5000, -73.7500, -74.0000, -74.2500,\n",
      "        -74.5000, -74.7500, -75.0000, -75.2500, -75.5000, -75.7500, -76.0000,\n",
      "        -76.2500, -76.5000, -76.7500, -77.0000, -77.2500, -77.5000, -77.7500,\n",
      "        -78.0000, -78.2500, -78.5000, -78.7500, -79.0000, -79.2500, -79.5000,\n",
      "        -79.7500, -80.0000, -80.2500, -80.5000, -80.7500, -81.0000, -81.2500,\n",
      "        -81.5000, -81.7500, -82.0000, -82.2500, -82.5000, -82.7500, -83.0000,\n",
      "        -83.2500, -83.5000, -83.7500, -84.0000, -84.2500, -84.5000, -84.7500,\n",
      "        -85.0000, -85.2500, -85.5000, -85.7500, -86.0000, -86.2500, -86.5000,\n",
      "        -86.7500, -87.0000, -87.2500, -87.5000, -87.7500, -88.0000, -88.2500,\n",
      "        -88.5000, -88.7500, -89.0000, -89.2500, -89.5000, -89.7500],\n",
      "       device='cuda:0'), lon=tensor([0.0000e+00, 2.5000e-01, 5.0000e-01,  ..., 3.5925e+02, 3.5950e+02,\n",
      "        3.5975e+02], device='cuda:0'), time=(datetime.datetime(2015, 1, 4, 12, 0),), atmos_levels=(1000, 925, 850, 700, 600, 500, 400, 300, 250, 200, 100, 50), rollout_step=1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed first batch\n",
      "Batch(surf_vars={'2t': tensor([[[[246.5566, 249.0670, 248.9123,  ..., 248.7042, 248.8638, 246.1772],\n",
      "          [254.5370, 254.2614, 253.9191,  ..., 253.9032, 253.9358, 248.8828],\n",
      "          [250.2312, 251.7356, 247.2331,  ..., 251.6860, 247.5735, 246.9567],\n",
      "          ...,\n",
      "          [245.6753, 245.1755, 245.6828,  ..., 246.0768, 246.3116, 246.4983],\n",
      "          [247.3932, 246.8410, 247.1264,  ..., 246.4315, 246.4003, 246.4061],\n",
      "          [245.2274, 245.0392, 245.4596,  ..., 246.7330, 246.5004, 246.3099]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), '10u': tensor([[[[  2.6317,   2.3470,   0.6036,  ...,   1.8345,   0.3006,   2.6186],\n",
      "          [ -8.5061,  -7.9438, -10.3034,  ...,  -7.3911,  -9.7658,  -7.0160],\n",
      "          [ -5.3238,  -5.0784, -10.9660,  ...,  -4.7888, -10.6551,  -8.6438],\n",
      "          ...,\n",
      "          [ -4.4275,  -4.4794,  -4.4256,  ...,  -3.8151,  -3.9774,  -4.1757],\n",
      "          [ -3.8242,  -3.6514,  -3.3166,  ...,  -4.1819,  -4.0720,  -4.0007],\n",
      "          [ -2.8588,  -3.0151,  -3.1744,  ...,  -3.3562,  -3.2996,  -3.2045]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), '10v': tensor([[[[-4.7491, -1.6176, -0.7612,  ..., -1.4165, -0.5728,  0.2893],\n",
      "          [-2.8881, -2.2159, -1.9689,  ..., -2.2295, -1.8949,  2.3415],\n",
      "          [-0.4747, -1.8935, -1.7017,  ..., -2.1070, -1.8317, -1.0392],\n",
      "          ...,\n",
      "          [-1.6352, -1.9366, -1.8378,  ..., -1.3894, -1.5044, -1.5757],\n",
      "          [-2.3182, -2.2129, -1.9340,  ..., -2.1369, -2.0058, -1.8792],\n",
      "          [-2.4786, -2.5525, -2.5754,  ..., -2.8270, -2.7938, -2.6295]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), 'msl': tensor([[[[102834.5391, 102837.0781, 103025.3281,  ..., 102846.4766,\n",
      "           103030.6172, 103434.9531],\n",
      "          [102781.9531, 103022.9141, 103044.7422,  ..., 103046.5781,\n",
      "           103074.0078, 103226.7031],\n",
      "          [103082.3125, 102720.5156, 102909.7344,  ..., 102749.7734,\n",
      "           102940.0469, 103221.5156],\n",
      "          ...,\n",
      "          [100387.4609, 100432.2578, 100446.0938,  ..., 100324.0000,\n",
      "           100320.5859, 100315.9219],\n",
      "          [100378.5547, 100403.3906, 100385.3594,  ..., 100296.4062,\n",
      "           100302.9375, 100300.4453],\n",
      "          [100358.1797, 100340.3281, 100283.6875,  ..., 100229.9219,\n",
      "           100226.4141, 100236.1406]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>), 'fire': tensor([[[[ 1.4000,  0.4946,  0.4597,  ...,  0.0145,  0.6163, -1.2973],\n",
      "          [-2.9834,  1.6034,  0.8447,  ...,  1.6434,  1.2762,  1.4595],\n",
      "          [-0.5256, -1.6139, -0.6010,  ..., -1.6112, -0.5811,  1.9214],\n",
      "          ...,\n",
      "          [-0.5346, -0.7558, -0.2672,  ..., -0.9423,  0.0912,  0.7919],\n",
      "          [ 0.0804, -0.2350, -0.6094,  ...,  0.3667, -0.5326, -0.1285],\n",
      "          [ 0.8870, -0.7816,  1.4725,  ..., -1.0411,  0.5906, -0.2948]]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>), 'lst': tensor([[[[ 6144.7876, 11625.5176, 13603.5322,  ..., 14394.2168,\n",
      "           10728.5205, -2008.1045],\n",
      "          [29104.3164,  5814.5918, 36189.8398,  ...,  6440.6968,\n",
      "           38131.1484, 17418.6641],\n",
      "          [-6850.8525, 34185.3281, 15204.8008,  ..., 31436.2031,\n",
      "           15227.7939,  2587.2207],\n",
      "          ...,\n",
      "          [15447.8086, 13563.4932, 14566.8828,  ..., 13585.0703,\n",
      "           17283.3516, 11065.9502],\n",
      "          [12127.2354, 18459.2168, 12575.8447,  ..., 14825.0049,\n",
      "           10619.8564,  2944.5127],\n",
      "          [19972.0664,  7581.4106,  9182.0479,  ...,  7052.6211,\n",
      "            6492.8052,  8230.0654]]]], device='cuda:0', grad_fn=<AddBackward0>)}, static_vars={'z': tensor([[ 3.2275e-01,  3.2275e-01,  3.2275e-01,  ...,  3.2275e-01,\n",
      "          3.2275e-01,  3.2275e-01],\n",
      "        [ 4.6157e+00,  4.6040e+00,  4.5884e+00,  ...,  4.7915e+00,\n",
      "          4.7329e+00,  4.6743e+00],\n",
      "        [-1.7710e+00, -1.7163e+00, -1.7085e+00,  ..., -1.5093e+00,\n",
      "         -1.6226e+00, -1.7124e+00],\n",
      "        ...,\n",
      "        [ 2.6638e+04,  2.6642e+04,  2.6647e+04,  ...,  2.6627e+04,\n",
      "          2.6631e+04,  2.6634e+04],\n",
      "        [ 2.6958e+04,  2.6961e+04,  2.6965e+04,  ...,  2.6950e+04,\n",
      "          2.6953e+04,  2.6956e+04],\n",
      "        [ 2.7163e+04,  2.7165e+04,  2.7167e+04,  ...,  2.7159e+04,\n",
      "          2.7160e+04,  2.7162e+04]], device='cuda:0'), 'slt': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0'), 'lsm': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')}, atmos_vars={'t': tensor([[[[[252.3774, 252.2945, 252.3273,  ..., 251.6500, 251.7189,\n",
      "            251.7875],\n",
      "           [252.6422, 252.6296, 252.6951,  ..., 252.1444, 252.2133,\n",
      "            252.2300],\n",
      "           [253.2570, 253.2582, 253.3021,  ..., 253.0252, 253.0634,\n",
      "            253.1299],\n",
      "           ...,\n",
      "           [264.6792, 264.4735, 264.3450,  ..., 264.9097, 264.8164,\n",
      "            264.7161],\n",
      "           [265.5323, 265.3532, 265.2997,  ..., 265.6867, 265.6630,\n",
      "            265.7100],\n",
      "           [265.7731, 265.6615, 265.6553,  ..., 266.0635, 266.1049,\n",
      "            266.2934]],\n",
      "\n",
      "          [[253.0310, 252.9886, 253.0017,  ..., 252.8642, 252.8846,\n",
      "            252.8692],\n",
      "           [253.1220, 253.1065, 253.1389,  ..., 253.0272, 253.0603,\n",
      "            252.9821],\n",
      "           [253.4720, 253.4563, 253.4294,  ..., 253.3661, 253.3392,\n",
      "            253.3361],\n",
      "           ...,\n",
      "           [261.5435, 261.5309, 261.5424,  ..., 261.6942, 261.7292,\n",
      "            261.6651],\n",
      "           [262.1307, 262.1441, 262.1745,  ..., 262.3028, 262.3480,\n",
      "            262.3600],\n",
      "           [262.5142, 262.5372, 262.5657,  ..., 262.7040, 262.7420,\n",
      "            262.8462]],\n",
      "\n",
      "          [[252.6878, 252.6485, 252.6337,  ..., 252.4814, 252.4725,\n",
      "            252.4221],\n",
      "           [252.5008, 252.4841, 252.5257,  ..., 252.3455, 252.3915,\n",
      "            252.2821],\n",
      "           [252.3612, 252.3422, 252.3424,  ..., 252.2279, 252.2338,\n",
      "            252.2314],\n",
      "           ...,\n",
      "           [266.7706, 266.7178, 266.7315,  ..., 266.8543, 266.8914,\n",
      "            266.9150],\n",
      "           [267.1185, 267.0588, 267.0525,  ..., 267.0464, 267.0746,\n",
      "            267.0926],\n",
      "           [267.6879, 267.6068, 267.5368,  ..., 267.4385, 267.4129,\n",
      "            267.4601]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[216.4057, 216.4100, 216.4079,  ..., 216.4233, 216.4165,\n",
      "            216.4322],\n",
      "           [216.1671, 216.1650, 216.1785,  ..., 216.2175, 216.2257,\n",
      "            216.2397],\n",
      "           [215.9821, 215.9820, 216.0063,  ..., 216.0350, 216.0546,\n",
      "            216.0631],\n",
      "           ...,\n",
      "           [221.5344, 221.5020, 221.4890,  ..., 221.5345, 221.5337,\n",
      "            221.5358],\n",
      "           [221.7263, 221.7289, 221.7489,  ..., 221.7517, 221.7868,\n",
      "            221.7984],\n",
      "           [222.1796, 222.2359, 222.2815,  ..., 222.2289, 222.2936,\n",
      "            222.3329]],\n",
      "\n",
      "          [[216.2871, 216.2937, 216.2982,  ..., 216.1542, 216.1616,\n",
      "            216.1795],\n",
      "           [216.1660, 216.1373, 216.1534,  ..., 215.9852, 216.0001,\n",
      "            216.0127],\n",
      "           [215.9894, 215.9690, 215.9823,  ..., 215.8046, 215.8162,\n",
      "            215.7923],\n",
      "           ...,\n",
      "           [224.9697, 224.9489, 224.9990,  ..., 224.5139, 224.5565,\n",
      "            224.5749],\n",
      "           [224.7167, 224.6527, 224.6613,  ..., 224.2941, 224.3117,\n",
      "            224.4095],\n",
      "           [224.5340, 224.4138, 224.3934,  ..., 224.1434, 224.1301,\n",
      "            224.2703]],\n",
      "\n",
      "          [[216.5611, 216.4858, 216.4404,  ..., 216.3982, 216.3571,\n",
      "            216.3592],\n",
      "           [216.4693, 216.3705, 216.3330,  ..., 216.3323, 216.2964,\n",
      "            216.3005],\n",
      "           [216.3665, 216.3008, 216.2719,  ..., 216.3131, 216.2844,\n",
      "            216.2524],\n",
      "           ...,\n",
      "           [221.2417, 221.2159, 221.2702,  ..., 220.4533, 220.4974,\n",
      "            220.5000],\n",
      "           [221.0808, 221.0793, 221.0918,  ..., 220.3439, 220.3423,\n",
      "            220.3206],\n",
      "           [220.9647, 220.9679, 220.9572,  ..., 220.2793, 220.2506,\n",
      "            220.2734]]]]], device='cuda:0', grad_fn=<AddBackward0>), 'u': tensor([[[[[ 4.3017e-01,  4.6180e-01,  5.0104e-01,  ...,  5.4468e-01,\n",
      "             5.8731e-01,  5.9429e-01],\n",
      "           [-1.0283e+00, -1.0520e+00, -1.0133e+00,  ..., -8.5369e-01,\n",
      "            -8.0266e-01, -7.3195e-01],\n",
      "           [-2.8945e+00, -2.9496e+00, -2.9383e+00,  ..., -2.5610e+00,\n",
      "            -2.5158e+00, -2.4275e+00],\n",
      "           ...,\n",
      "           [-4.9328e+00, -4.8711e+00, -4.7442e+00,  ..., -4.6491e+00,\n",
      "            -4.5422e+00, -4.4725e+00],\n",
      "           [-4.7713e+00, -4.7595e+00, -4.6453e+00,  ..., -4.6799e+00,\n",
      "            -4.5253e+00, -4.4074e+00],\n",
      "           [-4.2452e+00, -4.2335e+00, -4.1742e+00,  ..., -4.3166e+00,\n",
      "            -4.2047e+00, -4.1137e+00]],\n",
      "\n",
      "          [[ 2.4542e-01,  2.7229e-01,  3.1023e-01,  ...,  1.9747e-01,\n",
      "             2.3825e-01,  2.6239e-01],\n",
      "           [ 7.9175e-01,  7.9159e-01,  7.9335e-01,  ...,  4.4407e-01,\n",
      "             4.4473e-01,  4.5691e-01],\n",
      "           [-7.1103e-01, -7.2071e-01, -7.5226e-01,  ..., -8.6255e-01,\n",
      "            -8.9632e-01, -9.1762e-01],\n",
      "           ...,\n",
      "           [-5.5660e+00, -5.5702e+00, -5.5950e+00,  ..., -4.9691e+00,\n",
      "            -4.9897e+00, -4.9974e+00],\n",
      "           [-5.0617e+00, -5.1195e+00, -5.1483e+00,  ..., -4.7433e+00,\n",
      "            -4.7417e+00, -4.7568e+00],\n",
      "           [-4.5692e+00, -4.6393e+00, -4.6982e+00,  ..., -4.3095e+00,\n",
      "            -4.3115e+00, -4.2995e+00]],\n",
      "\n",
      "          [[ 6.4684e-01,  6.3157e-01,  6.1190e-01,  ...,  4.0365e-01,\n",
      "             3.9706e-01,  4.1428e-01],\n",
      "           [ 1.6508e+00,  1.6410e+00,  1.6126e+00,  ...,  1.3010e+00,\n",
      "             1.2873e+00,  1.2942e+00],\n",
      "           [ 4.0517e-01,  4.0462e-01,  3.7443e-01,  ...,  2.2109e-01,\n",
      "             2.0396e-01,  1.7399e-01],\n",
      "           ...,\n",
      "           [-4.8653e+00, -4.9890e+00, -5.0665e+00,  ..., -4.5825e+00,\n",
      "            -4.7076e+00, -4.7425e+00],\n",
      "           [-4.4291e+00, -4.5512e+00, -4.5971e+00,  ..., -4.4873e+00,\n",
      "            -4.5379e+00, -4.5651e+00],\n",
      "           [-3.9415e+00, -4.0108e+00, -4.0346e+00,  ..., -4.0594e+00,\n",
      "            -4.0864e+00, -4.0953e+00]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 4.7333e-01,  4.4951e-01,  4.7512e-01,  ..., -1.1837e-01,\n",
      "            -9.3856e-02, -1.4098e-02],\n",
      "           [-1.1629e+01, -1.1567e+01, -1.1560e+01,  ..., -1.1215e+01,\n",
      "            -1.1225e+01, -1.1247e+01],\n",
      "           [-1.0943e+01, -1.0942e+01, -1.0852e+01,  ..., -1.0465e+01,\n",
      "            -1.0390e+01, -1.0443e+01],\n",
      "           ...,\n",
      "           [-1.8769e+00, -2.0882e+00, -2.2592e+00,  ..., -1.8874e+00,\n",
      "            -2.0998e+00, -2.2735e+00],\n",
      "           [-1.5519e+00, -1.6832e+00, -1.7080e+00,  ..., -1.4771e+00,\n",
      "            -1.5410e+00, -1.6838e+00],\n",
      "           [-1.1935e+00, -1.2990e+00, -1.3276e+00,  ..., -1.0858e+00,\n",
      "            -1.1474e+00, -1.2900e+00]],\n",
      "\n",
      "          [[ 6.3765e-01,  6.2490e-01,  5.9840e-01,  ...,  6.6461e-01,\n",
      "             6.3113e-01,  6.5657e-01],\n",
      "           [-1.9643e+01, -1.9663e+01, -1.9657e+01,  ..., -1.9683e+01,\n",
      "            -1.9675e+01, -1.9543e+01],\n",
      "           [-1.8820e+01, -1.8976e+01, -1.8949e+01,  ..., -1.8900e+01,\n",
      "            -1.8861e+01, -1.8724e+01],\n",
      "           ...,\n",
      "           [-3.0949e+00, -3.4688e+00, -3.6862e+00,  ..., -2.6615e+00,\n",
      "            -2.8948e+00, -2.9937e+00],\n",
      "           [-3.6680e+00, -4.0176e+00, -4.0031e+00,  ..., -3.2543e+00,\n",
      "            -3.2331e+00, -3.1285e+00],\n",
      "           [-4.1333e+00, -4.2212e+00, -4.0261e+00,  ..., -3.5528e+00,\n",
      "            -3.3449e+00, -2.9863e+00]],\n",
      "\n",
      "          [[ 4.8433e-01,  6.3909e-01,  7.8113e-01,  ...,  1.1685e+00,\n",
      "             1.2871e+00,  1.4845e+00],\n",
      "           [-2.6364e+01, -2.6248e+01, -2.6138e+01,  ..., -2.5930e+01,\n",
      "            -2.5858e+01, -2.5699e+01],\n",
      "           [-2.5717e+01, -2.5675e+01, -2.5558e+01,  ..., -2.5376e+01,\n",
      "            -2.5283e+01, -2.5116e+01],\n",
      "           ...,\n",
      "           [-3.6172e+00, -4.1453e+00, -4.7117e+00,  ..., -3.3122e+00,\n",
      "            -3.8711e+00, -4.2276e+00],\n",
      "           [-4.8291e+00, -5.1559e+00, -5.2679e+00,  ..., -4.5879e+00,\n",
      "            -4.6818e+00, -4.6103e+00],\n",
      "           [-5.5330e+00, -5.6302e+00, -5.5489e+00,  ..., -5.0632e+00,\n",
      "            -4.9161e+00, -4.5610e+00]]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>), 'v': tensor([[[[[-2.8347e-01, -1.5753e-01, -8.1578e-02,  ...,  7.8951e-02,\n",
      "             1.4987e-01,  1.9298e-01],\n",
      "           [ 3.3479e-01,  4.9477e-01,  5.8367e-01,  ...,  9.6620e-02,\n",
      "             1.4837e-01,  1.5331e-01],\n",
      "           [ 1.1867e-01,  2.9251e-01,  3.9293e-01,  ..., -1.2634e-01,\n",
      "            -4.4183e-02, -3.5591e-02],\n",
      "           ...,\n",
      "           [-9.0485e-01, -1.0984e+00, -1.3564e+00,  ..., -1.1245e+00,\n",
      "            -1.3395e+00, -1.5550e+00],\n",
      "           [-1.2449e+00, -1.4377e+00, -1.6949e+00,  ..., -1.5959e+00,\n",
      "            -1.7710e+00, -1.9543e+00],\n",
      "           [-1.4841e+00, -1.6031e+00, -1.7602e+00,  ..., -2.0345e+00,\n",
      "            -2.1173e+00, -2.2440e+00]],\n",
      "\n",
      "          [[-1.6721e-01, -6.3922e-02, -7.4174e-02,  ...,  1.9314e-01,\n",
      "             1.7545e-01,  1.3430e-01],\n",
      "           [ 1.3391e+00,  1.4328e+00,  1.4372e+00,  ...,  1.5609e+00,\n",
      "             1.5489e+00,  1.5167e+00],\n",
      "           [ 1.0519e+00,  1.1409e+00,  1.1964e+00,  ...,  1.1936e+00,\n",
      "             1.2256e+00,  1.2551e+00],\n",
      "           ...,\n",
      "           [-1.2312e+00, -1.3108e+00, -1.3711e+00,  ..., -1.2614e+00,\n",
      "            -1.3023e+00, -1.3735e+00],\n",
      "           [-1.7032e+00, -1.7479e+00, -1.7531e+00,  ..., -1.7478e+00,\n",
      "            -1.7408e+00, -1.7809e+00],\n",
      "           [-2.2618e+00, -2.2768e+00, -2.2584e+00,  ..., -2.3061e+00,\n",
      "            -2.2900e+00, -2.3480e+00]],\n",
      "\n",
      "          [[ 2.0654e-01,  3.0968e-01,  3.6619e-01,  ...,  4.2716e-01,\n",
      "             4.8847e-01,  5.3580e-01],\n",
      "           [ 4.2146e-02,  1.5269e-01,  2.2348e-01,  ...,  2.0734e-01,\n",
      "             2.7340e-01,  3.2950e-01],\n",
      "           [-4.1887e-01, -3.0109e-01, -1.9554e-01,  ..., -2.7938e-01,\n",
      "            -1.8511e-01, -9.5417e-02],\n",
      "           ...,\n",
      "           [-1.2794e+00, -1.2687e+00, -1.2898e+00,  ..., -1.0860e+00,\n",
      "            -1.1062e+00, -1.1551e+00],\n",
      "           [-1.5803e+00, -1.5748e+00, -1.6130e+00,  ..., -1.5250e+00,\n",
      "            -1.5301e+00, -1.5872e+00],\n",
      "           [-2.0062e+00, -2.0160e+00, -2.0511e+00,  ..., -2.1791e+00,\n",
      "            -2.1592e+00, -2.1711e+00]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 2.8700e-01,  3.3414e-01,  3.9681e-01,  ...,  5.0618e-01,\n",
      "             5.5109e-01,  6.1807e-01],\n",
      "           [-5.8099e+00, -5.7223e+00, -5.6051e+00,  ..., -5.7784e+00,\n",
      "            -5.6687e+00, -5.5769e+00],\n",
      "           [-5.5289e+00, -5.4870e+00, -5.3846e+00,  ..., -5.4677e+00,\n",
      "            -5.3648e+00, -5.2787e+00],\n",
      "           ...,\n",
      "           [ 2.5264e-01,  1.7639e-01,  1.5000e-01,  ...,  3.6550e-01,\n",
      "             3.0378e-01,  1.4558e-01],\n",
      "           [ 8.0600e-02, -1.0836e-01, -2.3506e-01,  ...,  6.0837e-02,\n",
      "            -8.8519e-02, -2.9387e-01],\n",
      "           [ 2.0282e-01, -9.1003e-02, -3.3489e-01,  ...,  5.8806e-04,\n",
      "            -2.5067e-01, -6.0203e-01]],\n",
      "\n",
      "          [[-3.8182e-01, -3.4774e-01, -3.5789e-01,  ..., -2.2505e-01,\n",
      "            -2.3280e-01, -2.2769e-01],\n",
      "           [-4.8043e+00, -4.6698e+00, -4.5615e+00,  ..., -5.1366e+00,\n",
      "            -5.0229e+00, -4.9048e+00],\n",
      "           [-5.1336e+00, -5.0353e+00, -4.9209e+00,  ..., -5.3482e+00,\n",
      "            -5.2304e+00, -5.1069e+00],\n",
      "           ...,\n",
      "           [-1.0067e-01, -2.9646e-01, -4.8640e-01,  ..., -4.0748e-02,\n",
      "            -1.8056e-01, -3.6679e-01],\n",
      "           [-5.2004e-01, -8.9640e-01, -1.1648e+00,  ..., -6.8489e-01,\n",
      "            -9.0606e-01, -1.1765e+00],\n",
      "           [-7.8707e-01, -1.2401e+00, -1.6678e+00,  ..., -1.1071e+00,\n",
      "            -1.4897e+00, -1.8898e+00]],\n",
      "\n",
      "          [[-6.0376e-02, -2.9135e-02, -2.4746e-03,  ..., -1.1926e-01,\n",
      "            -1.2008e-01, -1.1856e-01],\n",
      "           [-6.0247e+00, -5.8965e+00, -5.7545e+00,  ..., -6.4905e+00,\n",
      "            -6.3714e+00, -6.2730e+00],\n",
      "           [-6.3754e+00, -6.2914e+00, -6.1592e+00,  ..., -6.7045e+00,\n",
      "            -6.5888e+00, -6.4969e+00],\n",
      "           ...,\n",
      "           [-3.9365e-01, -6.7556e-01, -9.2687e-01,  ..., -5.2899e-02,\n",
      "            -3.1294e-01, -6.3955e-01],\n",
      "           [-5.9159e-01, -9.2470e-01, -1.1911e+00,  ..., -3.3063e-01,\n",
      "            -5.7315e-01, -8.0275e-01],\n",
      "           [-6.6085e-01, -1.0224e+00, -1.3868e+00,  ..., -4.2260e-01,\n",
      "            -7.3061e-01, -9.9722e-01]]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>), 'q': tensor([[[[[4.1727e-04, 4.3268e-04, 4.4436e-04,  ..., 4.0706e-04,\n",
      "            4.2937e-04, 4.3444e-04],\n",
      "           [4.5428e-04, 4.5223e-04, 4.5291e-04,  ..., 4.2855e-04,\n",
      "            4.3856e-04, 4.5185e-04],\n",
      "           [4.5132e-04, 4.6096e-04, 4.4006e-04,  ..., 4.4358e-04,\n",
      "            4.2933e-04, 4.3515e-04],\n",
      "           ...,\n",
      "           [5.8003e-04, 6.0440e-04, 6.2450e-04,  ..., 5.5202e-04,\n",
      "            5.7687e-04, 5.8682e-04],\n",
      "           [5.1718e-04, 5.6651e-04, 5.9106e-04,  ..., 5.0149e-04,\n",
      "            5.2743e-04, 5.4696e-04],\n",
      "           [4.9438e-04, 5.2895e-04, 5.7211e-04,  ..., 4.7273e-04,\n",
      "            5.2210e-04, 5.4555e-04]],\n",
      "\n",
      "          [[3.4961e-04, 3.6575e-04, 3.8077e-04,  ..., 3.7184e-04,\n",
      "            3.8459e-04, 3.7652e-04],\n",
      "           [3.8745e-04, 3.8173e-04, 3.9055e-04,  ..., 3.9312e-04,\n",
      "            3.9871e-04, 4.0809e-04],\n",
      "           [4.0281e-04, 4.1162e-04, 3.9650e-04,  ..., 4.2583e-04,\n",
      "            4.0616e-04, 4.0847e-04],\n",
      "           ...,\n",
      "           [4.7341e-04, 4.6520e-04, 4.6721e-04,  ..., 4.2336e-04,\n",
      "            4.2291e-04, 4.2944e-04],\n",
      "           [4.1314e-04, 4.4613e-04, 4.4577e-04,  ..., 4.0005e-04,\n",
      "            3.8985e-04, 3.9282e-04],\n",
      "           [3.9036e-04, 4.0972e-04, 4.3226e-04,  ..., 3.6311e-04,\n",
      "            3.7575e-04, 3.7482e-04]],\n",
      "\n",
      "          [[1.3012e-04, 1.3147e-04, 1.3159e-04,  ..., 1.4627e-04,\n",
      "            1.4493e-04, 1.3011e-04],\n",
      "           [1.5321e-04, 1.4213e-04, 1.3700e-04,  ..., 1.5685e-04,\n",
      "            1.5187e-04, 1.5257e-04],\n",
      "           [1.4556e-04, 1.5198e-04, 1.3527e-04,  ..., 1.7239e-04,\n",
      "            1.5632e-04, 1.4731e-04],\n",
      "           ...,\n",
      "           [6.8900e-04, 6.9676e-04, 6.8343e-04,  ..., 6.7602e-04,\n",
      "            6.6229e-04, 6.4743e-04],\n",
      "           [6.8573e-04, 7.1557e-04, 7.0299e-04,  ..., 6.9579e-04,\n",
      "            6.7834e-04, 6.7191e-04],\n",
      "           [6.6568e-04, 7.0730e-04, 7.3201e-04,  ..., 7.0963e-04,\n",
      "            7.2813e-04, 7.3705e-04]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[3.0883e-06, 3.2500e-06, 3.3774e-06,  ..., 3.2895e-06,\n",
      "            3.3877e-06, 3.3552e-06],\n",
      "           [3.1963e-06, 3.2198e-06, 3.2748e-06,  ..., 3.2472e-06,\n",
      "            3.2824e-06, 3.1944e-06],\n",
      "           [3.1014e-06, 3.0931e-06, 3.0543e-06,  ..., 3.1476e-06,\n",
      "            3.0983e-06, 3.1477e-06],\n",
      "           ...,\n",
      "           [2.9104e-06, 2.8069e-06, 2.8602e-06,  ..., 2.8640e-06,\n",
      "            2.9394e-06, 2.9572e-06],\n",
      "           [2.5730e-06, 2.4053e-06, 2.4039e-06,  ..., 2.4047e-06,\n",
      "            2.4414e-06, 2.5883e-06],\n",
      "           [2.7058e-06, 2.4620e-06, 2.3218e-06,  ..., 2.4454e-06,\n",
      "            2.3389e-06, 2.3667e-06]],\n",
      "\n",
      "          [[2.8199e-06, 2.8191e-06, 2.8164e-06,  ..., 2.8159e-06,\n",
      "            2.8136e-06, 2.8114e-06],\n",
      "           [2.8077e-06, 2.8062e-06, 2.8059e-06,  ..., 2.8010e-06,\n",
      "            2.8007e-06, 2.7993e-06],\n",
      "           [2.7918e-06, 2.7904e-06, 2.7915e-06,  ..., 2.7891e-06,\n",
      "            2.7893e-06, 2.7885e-06],\n",
      "           ...,\n",
      "           [2.4817e-06, 2.4904e-06, 2.4893e-06,  ..., 2.4903e-06,\n",
      "            2.4897e-06, 2.4811e-06],\n",
      "           [2.4411e-06, 2.4524e-06, 2.4587e-06,  ..., 2.4557e-06,\n",
      "            2.4627e-06, 2.4622e-06],\n",
      "           [2.4199e-06, 2.4311e-06, 2.4400e-06,  ..., 2.4395e-06,\n",
      "            2.4494e-06, 2.4437e-06]],\n",
      "\n",
      "          [[2.9674e-06, 2.9682e-06, 2.9688e-06,  ..., 2.9735e-06,\n",
      "            2.9727e-06, 2.9730e-06],\n",
      "           [2.9738e-06, 2.9740e-06, 2.9748e-06,  ..., 2.9795e-06,\n",
      "            2.9787e-06, 2.9776e-06],\n",
      "           [2.9763e-06, 2.9775e-06, 2.9785e-06,  ..., 2.9841e-06,\n",
      "            2.9834e-06, 2.9830e-06],\n",
      "           ...,\n",
      "           [2.5677e-06, 2.5788e-06, 2.5841e-06,  ..., 2.5821e-06,\n",
      "            2.5877e-06, 2.5814e-06],\n",
      "           [2.5430e-06, 2.5562e-06, 2.5658e-06,  ..., 2.5583e-06,\n",
      "            2.5686e-06, 2.5681e-06],\n",
      "           [2.5349e-06, 2.5400e-06, 2.5419e-06,  ..., 2.5417e-06,\n",
      "            2.5441e-06, 2.5389e-06]]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>), 'z': tensor([[[[[1.6842e+03, 1.6858e+03, 1.6863e+03,  ..., 1.7088e+03,\n",
      "            1.7080e+03, 1.7051e+03],\n",
      "           [1.6969e+03, 1.6985e+03, 1.6983e+03,  ..., 1.7122e+03,\n",
      "            1.7121e+03, 1.7110e+03],\n",
      "           [1.6950e+03, 1.6951e+03, 1.6979e+03,  ..., 1.7043e+03,\n",
      "            1.7082e+03, 1.7073e+03],\n",
      "           ...,\n",
      "           [1.3454e+02, 1.3720e+02, 1.4128e+02,  ..., 1.2507e+02,\n",
      "            1.2934e+02, 1.3093e+02],\n",
      "           [1.0452e+02, 1.0448e+02, 1.0150e+02,  ..., 8.6210e+01,\n",
      "            8.2102e+01, 7.9669e+01],\n",
      "           [8.8417e+01, 8.3929e+01, 7.6226e+01,  ..., 6.2858e+01,\n",
      "            5.2565e+01, 4.4564e+01]],\n",
      "\n",
      "          [[7.3445e+03, 7.3456e+03, 7.3469e+03,  ..., 7.3625e+03,\n",
      "            7.3635e+03, 7.3638e+03],\n",
      "           [7.3624e+03, 7.3627e+03, 7.3628e+03,  ..., 7.3750e+03,\n",
      "            7.3750e+03, 7.3748e+03],\n",
      "           [7.3732e+03, 7.3720e+03, 7.3735e+03,  ..., 7.3811e+03,\n",
      "            7.3827e+03, 7.3829e+03],\n",
      "           ...,\n",
      "           [6.0651e+03, 6.0653e+03, 6.0697e+03,  ..., 6.0607e+03,\n",
      "            6.0645e+03, 6.0670e+03],\n",
      "           [6.0459e+03, 6.0488e+03, 6.0520e+03,  ..., 6.0448e+03,\n",
      "            6.0470e+03, 6.0499e+03],\n",
      "           [6.0312e+03, 6.0347e+03, 6.0387e+03,  ..., 6.0357e+03,\n",
      "            6.0391e+03, 6.0387e+03]],\n",
      "\n",
      "          [[1.3496e+04, 1.3498e+04, 1.3498e+04,  ..., 1.3514e+04,\n",
      "            1.3514e+04, 1.3514e+04],\n",
      "           [1.3515e+04, 1.3516e+04, 1.3516e+04,  ..., 1.3527e+04,\n",
      "            1.3527e+04, 1.3527e+04],\n",
      "           [1.3527e+04, 1.3526e+04, 1.3527e+04,  ..., 1.3533e+04,\n",
      "            1.3535e+04, 1.3534e+04],\n",
      "           ...,\n",
      "           [1.2510e+04, 1.2510e+04, 1.2518e+04,  ..., 1.2504e+04,\n",
      "            1.2510e+04, 1.2515e+04],\n",
      "           [1.2511e+04, 1.2516e+04, 1.2518e+04,  ..., 1.2511e+04,\n",
      "            1.2513e+04, 1.2519e+04],\n",
      "           [1.2506e+04, 1.2512e+04, 1.2518e+04,  ..., 1.2508e+04,\n",
      "            1.2513e+04, 1.2515e+04]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[1.0829e+05, 1.0830e+05, 1.0829e+05,  ..., 1.0830e+05,\n",
      "            1.0829e+05, 1.0830e+05],\n",
      "           [1.0821e+05, 1.0821e+05, 1.0822e+05,  ..., 1.0822e+05,\n",
      "            1.0822e+05, 1.0826e+05],\n",
      "           [1.0820e+05, 1.0818e+05, 1.0820e+05,  ..., 1.0819e+05,\n",
      "            1.0821e+05, 1.0819e+05],\n",
      "           ...,\n",
      "           [1.0897e+05, 1.0897e+05, 1.0898e+05,  ..., 1.0899e+05,\n",
      "            1.0900e+05, 1.0902e+05],\n",
      "           [1.0898e+05, 1.0899e+05, 1.0900e+05,  ..., 1.0901e+05,\n",
      "            1.0902e+05, 1.0903e+05],\n",
      "           [1.0898e+05, 1.0899e+05, 1.0900e+05,  ..., 1.0901e+05,\n",
      "            1.0902e+05, 1.0902e+05]],\n",
      "\n",
      "          [[1.5133e+05, 1.5134e+05, 1.5133e+05,  ..., 1.5134e+05,\n",
      "            1.5134e+05, 1.5135e+05],\n",
      "           [1.5122e+05, 1.5122e+05, 1.5123e+05,  ..., 1.5123e+05,\n",
      "            1.5124e+05, 1.5127e+05],\n",
      "           [1.5116e+05, 1.5115e+05, 1.5117e+05,  ..., 1.5117e+05,\n",
      "            1.5118e+05, 1.5117e+05],\n",
      "           ...,\n",
      "           [1.5390e+05, 1.5391e+05, 1.5393e+05,  ..., 1.5388e+05,\n",
      "            1.5390e+05, 1.5390e+05],\n",
      "           [1.5389e+05, 1.5392e+05, 1.5394e+05,  ..., 1.5389e+05,\n",
      "            1.5391e+05, 1.5393e+05],\n",
      "           [1.5389e+05, 1.5392e+05, 1.5394e+05,  ..., 1.5389e+05,\n",
      "            1.5390e+05, 1.5391e+05]],\n",
      "\n",
      "          [[1.9408e+05, 1.9407e+05, 1.9407e+05,  ..., 1.9408e+05,\n",
      "            1.9407e+05, 1.9409e+05],\n",
      "           [1.9395e+05, 1.9394e+05, 1.9395e+05,  ..., 1.9395e+05,\n",
      "            1.9395e+05, 1.9397e+05],\n",
      "           [1.9385e+05, 1.9385e+05, 1.9385e+05,  ..., 1.9387e+05,\n",
      "            1.9387e+05, 1.9387e+05],\n",
      "           ...,\n",
      "           [1.9688e+05, 1.9689e+05, 1.9691e+05,  ..., 1.9680e+05,\n",
      "            1.9682e+05, 1.9682e+05],\n",
      "           [1.9688e+05, 1.9692e+05, 1.9694e+05,  ..., 1.9682e+05,\n",
      "            1.9684e+05, 1.9687e+05],\n",
      "           [1.9688e+05, 1.9690e+05, 1.9693e+05,  ..., 1.9680e+05,\n",
      "            1.9683e+05, 1.9685e+05]]]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)}, metadata=Metadata(lat=tensor([ 90.0000,  89.7500,  89.5000,  89.2500,  89.0000,  88.7500,  88.5000,\n",
      "         88.2500,  88.0000,  87.7500,  87.5000,  87.2500,  87.0000,  86.7500,\n",
      "         86.5000,  86.2500,  86.0000,  85.7500,  85.5000,  85.2500,  85.0000,\n",
      "         84.7500,  84.5000,  84.2500,  84.0000,  83.7500,  83.5000,  83.2500,\n",
      "         83.0000,  82.7500,  82.5000,  82.2500,  82.0000,  81.7500,  81.5000,\n",
      "         81.2500,  81.0000,  80.7500,  80.5000,  80.2500,  80.0000,  79.7500,\n",
      "         79.5000,  79.2500,  79.0000,  78.7500,  78.5000,  78.2500,  78.0000,\n",
      "         77.7500,  77.5000,  77.2500,  77.0000,  76.7500,  76.5000,  76.2500,\n",
      "         76.0000,  75.7500,  75.5000,  75.2500,  75.0000,  74.7500,  74.5000,\n",
      "         74.2500,  74.0000,  73.7500,  73.5000,  73.2500,  73.0000,  72.7500,\n",
      "         72.5000,  72.2500,  72.0000,  71.7500,  71.5000,  71.2500,  71.0000,\n",
      "         70.7500,  70.5000,  70.2500,  70.0000,  69.7500,  69.5000,  69.2500,\n",
      "         69.0000,  68.7500,  68.5000,  68.2500,  68.0000,  67.7500,  67.5000,\n",
      "         67.2500,  67.0000,  66.7500,  66.5000,  66.2500,  66.0000,  65.7500,\n",
      "         65.5000,  65.2500,  65.0000,  64.7500,  64.5000,  64.2500,  64.0000,\n",
      "         63.7500,  63.5000,  63.2500,  63.0000,  62.7500,  62.5000,  62.2500,\n",
      "         62.0000,  61.7500,  61.5000,  61.2500,  61.0000,  60.7500,  60.5000,\n",
      "         60.2500,  60.0000,  59.7500,  59.5000,  59.2500,  59.0000,  58.7500,\n",
      "         58.5000,  58.2500,  58.0000,  57.7500,  57.5000,  57.2500,  57.0000,\n",
      "         56.7500,  56.5000,  56.2500,  56.0000,  55.7500,  55.5000,  55.2500,\n",
      "         55.0000,  54.7500,  54.5000,  54.2500,  54.0000,  53.7500,  53.5000,\n",
      "         53.2500,  53.0000,  52.7500,  52.5000,  52.2500,  52.0000,  51.7500,\n",
      "         51.5000,  51.2500,  51.0000,  50.7500,  50.5000,  50.2500,  50.0000,\n",
      "         49.7500,  49.5000,  49.2500,  49.0000,  48.7500,  48.5000,  48.2500,\n",
      "         48.0000,  47.7500,  47.5000,  47.2500,  47.0000,  46.7500,  46.5000,\n",
      "         46.2500,  46.0000,  45.7500,  45.5000,  45.2500,  45.0000,  44.7500,\n",
      "         44.5000,  44.2500,  44.0000,  43.7500,  43.5000,  43.2500,  43.0000,\n",
      "         42.7500,  42.5000,  42.2500,  42.0000,  41.7500,  41.5000,  41.2500,\n",
      "         41.0000,  40.7500,  40.5000,  40.2500,  40.0000,  39.7500,  39.5000,\n",
      "         39.2500,  39.0000,  38.7500,  38.5000,  38.2500,  38.0000,  37.7500,\n",
      "         37.5000,  37.2500,  37.0000,  36.7500,  36.5000,  36.2500,  36.0000,\n",
      "         35.7500,  35.5000,  35.2500,  35.0000,  34.7500,  34.5000,  34.2500,\n",
      "         34.0000,  33.7500,  33.5000,  33.2500,  33.0000,  32.7500,  32.5000,\n",
      "         32.2500,  32.0000,  31.7500,  31.5000,  31.2500,  31.0000,  30.7500,\n",
      "         30.5000,  30.2500,  30.0000,  29.7500,  29.5000,  29.2500,  29.0000,\n",
      "         28.7500,  28.5000,  28.2500,  28.0000,  27.7500,  27.5000,  27.2500,\n",
      "         27.0000,  26.7500,  26.5000,  26.2500,  26.0000,  25.7500,  25.5000,\n",
      "         25.2500,  25.0000,  24.7500,  24.5000,  24.2500,  24.0000,  23.7500,\n",
      "         23.5000,  23.2500,  23.0000,  22.7500,  22.5000,  22.2500,  22.0000,\n",
      "         21.7500,  21.5000,  21.2500,  21.0000,  20.7500,  20.5000,  20.2500,\n",
      "         20.0000,  19.7500,  19.5000,  19.2500,  19.0000,  18.7500,  18.5000,\n",
      "         18.2500,  18.0000,  17.7500,  17.5000,  17.2500,  17.0000,  16.7500,\n",
      "         16.5000,  16.2500,  16.0000,  15.7500,  15.5000,  15.2500,  15.0000,\n",
      "         14.7500,  14.5000,  14.2500,  14.0000,  13.7500,  13.5000,  13.2500,\n",
      "         13.0000,  12.7500,  12.5000,  12.2500,  12.0000,  11.7500,  11.5000,\n",
      "         11.2500,  11.0000,  10.7500,  10.5000,  10.2500,  10.0000,   9.7500,\n",
      "          9.5000,   9.2500,   9.0000,   8.7500,   8.5000,   8.2500,   8.0000,\n",
      "          7.7500,   7.5000,   7.2500,   7.0000,   6.7500,   6.5000,   6.2500,\n",
      "          6.0000,   5.7500,   5.5000,   5.2500,   5.0000,   4.7500,   4.5000,\n",
      "          4.2500,   4.0000,   3.7500,   3.5000,   3.2500,   3.0000,   2.7500,\n",
      "          2.5000,   2.2500,   2.0000,   1.7500,   1.5000,   1.2500,   1.0000,\n",
      "          0.7500,   0.5000,   0.2500,   0.0000,  -0.2500,  -0.5000,  -0.7500,\n",
      "         -1.0000,  -1.2500,  -1.5000,  -1.7500,  -2.0000,  -2.2500,  -2.5000,\n",
      "         -2.7500,  -3.0000,  -3.2500,  -3.5000,  -3.7500,  -4.0000,  -4.2500,\n",
      "         -4.5000,  -4.7500,  -5.0000,  -5.2500,  -5.5000,  -5.7500,  -6.0000,\n",
      "         -6.2500,  -6.5000,  -6.7500,  -7.0000,  -7.2500,  -7.5000,  -7.7500,\n",
      "         -8.0000,  -8.2500,  -8.5000,  -8.7500,  -9.0000,  -9.2500,  -9.5000,\n",
      "         -9.7500, -10.0000, -10.2500, -10.5000, -10.7500, -11.0000, -11.2500,\n",
      "        -11.5000, -11.7500, -12.0000, -12.2500, -12.5000, -12.7500, -13.0000,\n",
      "        -13.2500, -13.5000, -13.7500, -14.0000, -14.2500, -14.5000, -14.7500,\n",
      "        -15.0000, -15.2500, -15.5000, -15.7500, -16.0000, -16.2500, -16.5000,\n",
      "        -16.7500, -17.0000, -17.2500, -17.5000, -17.7500, -18.0000, -18.2500,\n",
      "        -18.5000, -18.7500, -19.0000, -19.2500, -19.5000, -19.7500, -20.0000,\n",
      "        -20.2500, -20.5000, -20.7500, -21.0000, -21.2500, -21.5000, -21.7500,\n",
      "        -22.0000, -22.2500, -22.5000, -22.7500, -23.0000, -23.2500, -23.5000,\n",
      "        -23.7500, -24.0000, -24.2500, -24.5000, -24.7500, -25.0000, -25.2500,\n",
      "        -25.5000, -25.7500, -26.0000, -26.2500, -26.5000, -26.7500, -27.0000,\n",
      "        -27.2500, -27.5000, -27.7500, -28.0000, -28.2500, -28.5000, -28.7500,\n",
      "        -29.0000, -29.2500, -29.5000, -29.7500, -30.0000, -30.2500, -30.5000,\n",
      "        -30.7500, -31.0000, -31.2500, -31.5000, -31.7500, -32.0000, -32.2500,\n",
      "        -32.5000, -32.7500, -33.0000, -33.2500, -33.5000, -33.7500, -34.0000,\n",
      "        -34.2500, -34.5000, -34.7500, -35.0000, -35.2500, -35.5000, -35.7500,\n",
      "        -36.0000, -36.2500, -36.5000, -36.7500, -37.0000, -37.2500, -37.5000,\n",
      "        -37.7500, -38.0000, -38.2500, -38.5000, -38.7500, -39.0000, -39.2500,\n",
      "        -39.5000, -39.7500, -40.0000, -40.2500, -40.5000, -40.7500, -41.0000,\n",
      "        -41.2500, -41.5000, -41.7500, -42.0000, -42.2500, -42.5000, -42.7500,\n",
      "        -43.0000, -43.2500, -43.5000, -43.7500, -44.0000, -44.2500, -44.5000,\n",
      "        -44.7500, -45.0000, -45.2500, -45.5000, -45.7500, -46.0000, -46.2500,\n",
      "        -46.5000, -46.7500, -47.0000, -47.2500, -47.5000, -47.7500, -48.0000,\n",
      "        -48.2500, -48.5000, -48.7500, -49.0000, -49.2500, -49.5000, -49.7500,\n",
      "        -50.0000, -50.2500, -50.5000, -50.7500, -51.0000, -51.2500, -51.5000,\n",
      "        -51.7500, -52.0000, -52.2500, -52.5000, -52.7500, -53.0000, -53.2500,\n",
      "        -53.5000, -53.7500, -54.0000, -54.2500, -54.5000, -54.7500, -55.0000,\n",
      "        -55.2500, -55.5000, -55.7500, -56.0000, -56.2500, -56.5000, -56.7500,\n",
      "        -57.0000, -57.2500, -57.5000, -57.7500, -58.0000, -58.2500, -58.5000,\n",
      "        -58.7500, -59.0000, -59.2500, -59.5000, -59.7500, -60.0000, -60.2500,\n",
      "        -60.5000, -60.7500, -61.0000, -61.2500, -61.5000, -61.7500, -62.0000,\n",
      "        -62.2500, -62.5000, -62.7500, -63.0000, -63.2500, -63.5000, -63.7500,\n",
      "        -64.0000, -64.2500, -64.5000, -64.7500, -65.0000, -65.2500, -65.5000,\n",
      "        -65.7500, -66.0000, -66.2500, -66.5000, -66.7500, -67.0000, -67.2500,\n",
      "        -67.5000, -67.7500, -68.0000, -68.2500, -68.5000, -68.7500, -69.0000,\n",
      "        -69.2500, -69.5000, -69.7500, -70.0000, -70.2500, -70.5000, -70.7500,\n",
      "        -71.0000, -71.2500, -71.5000, -71.7500, -72.0000, -72.2500, -72.5000,\n",
      "        -72.7500, -73.0000, -73.2500, -73.5000, -73.7500, -74.0000, -74.2500,\n",
      "        -74.5000, -74.7500, -75.0000, -75.2500, -75.5000, -75.7500, -76.0000,\n",
      "        -76.2500, -76.5000, -76.7500, -77.0000, -77.2500, -77.5000, -77.7500,\n",
      "        -78.0000, -78.2500, -78.5000, -78.7500, -79.0000, -79.2500, -79.5000,\n",
      "        -79.7500, -80.0000, -80.2500, -80.5000, -80.7500, -81.0000, -81.2500,\n",
      "        -81.5000, -81.7500, -82.0000, -82.2500, -82.5000, -82.7500, -83.0000,\n",
      "        -83.2500, -83.5000, -83.7500, -84.0000, -84.2500, -84.5000, -84.7500,\n",
      "        -85.0000, -85.2500, -85.5000, -85.7500, -86.0000, -86.2500, -86.5000,\n",
      "        -86.7500, -87.0000, -87.2500, -87.5000, -87.7500, -88.0000, -88.2500,\n",
      "        -88.5000, -88.7500, -89.0000, -89.2500, -89.5000, -89.7500],\n",
      "       device='cuda:0'), lon=tensor([0.0000e+00, 2.5000e-01, 5.0000e-01,  ..., 3.5925e+02, 3.5950e+02,\n",
      "        3.5975e+02], device='cuda:0'), time=(datetime.datetime(2015, 1, 3, 12, 0),), atmos_levels=(1000, 925, 850, 700, 600, 500, 400, 300, 250, 200, 100, 50), rollout_step=1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at /pytorch/aten/src/ATen/native/cudnn/MHA.cpp:674.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed first batch\n",
      "Epoch [1/1], Loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "# model training \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model.train()\n",
    "model.configure_activation_checkpointing()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=5e-6)\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "model.configure_activation_checkpointing()\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "num_epochs = 1\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(num_epochs):  # Loop over epochs\n",
    "    # model.train()  # Set model to training mode\n",
    "    for batch in dataloader:  # Iterate over batches\n",
    "        # Unpack the batch\n",
    "        features, labels = batch  # Ensure your Dataset and collate function return the right format\n",
    "        # Move data to the appropriate device\n",
    "        # features = {key: val.to(device) for key, val in features.items()}  # For dict-based features\n",
    "        labels = labels.to(device)\n",
    "        # features = features.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        # outputs = model(features)\n",
    "        pred = model.forward(features)\n",
    "        # pred is already on gpu \n",
    "        # pred = pred.to(device)\n",
    "        print(pred)\n",
    "        # Compute the loss\n",
    "        loss = loss_func(labels,pred)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        loss.backward()  # Backpropagate\n",
    "        optimizer.step()  # Update the weights\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"computed first batch\")\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\"\n",
    "# !export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:64 3.17 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(os.getenv(\"PYTORCH_CUDA_ALLOC_CONF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2457/1207869413.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"aurora_fire_weights_all.pth\"), strict=False)\n"
     ]
    }
   ],
   "source": [
    "model = Aurora(\n",
    "    use_lora=False,\n",
    "    autocast=True,      # reduces memory usage\n",
    "    surf_vars=(\"2t\", \"10u\", \"10v\", \"msl\", \"fire\",\"lst\"),\n",
    "    static_vars=(\"lsm\", \"z\", \"slt\"),\n",
    "    atmos_vars=(\"z\", \"u\", \"v\", \"t\", \"q\"),\n",
    ")\n",
    "# model = Aurora(\n",
    "#     use_lora=False,\n",
    "#     autocast=True,      # reduces memory usage\n",
    "#     # surf_vars=(\"2t\", \"10u\", \"10v\", \"msl\"),\n",
    "#     surf_vars=(\"2t\", \"10u\", \"10v\", \"msl\", \"fire\"),\n",
    "#     static_vars=(\"lsm\", \"z\", \"slt\"),\n",
    "#     atmos_vars=(\"z\", \"u\", \"v\", \"t\", \"q\"),\n",
    "# )\n",
    "\n",
    "# model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-pretrained.ckpt\", strict=False)\n",
    "model.load_state_dict(torch.load(\"aurora_fire_weights_all.pth\"), strict=False)\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "torch.Size([1, 1, 720, 1440])\n",
      "torch.Size([1, 1, 720, 1440])\n",
      "lab_fire: (1036800,) int64 [0 0 0 ... 0 0 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "torch.Size([1, 1, 720, 1440])\n",
      "torch.Size([1, 1, 720, 1440])\n",
      "lab_fire: (1036800,) int64 [0 0 0 ... 0 0 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "torch.Size([1, 1, 720, 1440])\n",
      "torch.Size([1, 1, 720, 1440])\n",
      "lab_fire: (1036800,) int64 [0 0 0 ... 0 0 0]\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2457/484601965.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Disable gradient computations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# for batch in dataloader_test:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m  \u001b[0;31m# Ensure your Dataset and collate function return the right format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2457/4225867865.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         atmos, surf = data_retreive(self.atmos_files, self.surf_files, self.date_range\n\u001b[0m\u001b[1;32m    259\u001b[0m                              , self.window, idx,  self.variables_to_keep)\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2457/3401360106.py\u001b[0m in \u001b[0;36mdata_retreive\u001b[0;34m(atmos_files, surf_files, date_range, days, idx, variables_to_keep)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0msurf_cur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurf_cur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msurf_cur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables_to_keep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0matmos_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matmos_cur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0msurf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurf_cur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlazy_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m                 \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \"\"\"\n\u001b[0;32m-> 1006\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/namedarray/pycompat.py\u001b[0m in \u001b[0;36mto_duck_array\u001b[0;34m(data, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExplicitlyIndexed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-untyped-call, no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36mget_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36m_ensure_cached\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ensure_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36mget_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_duck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_oindex_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOuterIndexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36mget_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0;31m# If the array is not an ExplicitlyIndexedNDArrayMixin,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0;31m# it may wrap a BackendArray so use its __getitem__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# self.array[self.key] is now a numpy array when\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         return indexing.explicit_indexing_adapter(\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexingSupport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/indexing.py\u001b[0m in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \"\"\"\n\u001b[1;32m   1012\u001b[0m     \u001b[0mraw_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecompose_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexing_support\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_indexing_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnumpy_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;31m# index the loaded np.ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatastore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0moriginal_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;31m# Catch IndexError in netCDF4 and return a more informative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\n",
    "\n",
    "accuracy = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "f1 = 0\n",
    "iou = 0\n",
    "total_samples = 0\n",
    "\n",
    "threshold = 0.5 \n",
    "\n",
    "\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computations\n",
    "    # for batch in dataloader_test:\n",
    "    for batch in dataloader_test:\n",
    "        \n",
    "        features, labels = batch  # Ensure your Dataset and collate function return the right format\n",
    "        \n",
    "\n",
    "        # print(\"label unique:\", np.unique(labels.surf_vars[\"fire\"].cpu().numpy())[:10])\n",
    "        # print(\"feature unique:\",np.unique(features.surf_vars[\"fire\"].cpu().numpy()))\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        features = features.to(device)\n",
    "        \n",
    "        pred = model.forward(features)\n",
    "        # pred = pred.to(device)\n",
    "        # print(pred.surf_vars[\"fire\"].shape)\n",
    "        # print(labels.surf_vars[\"fire\"].shape)\n",
    "\n",
    "        # flatten turns 720, 1440 into 1036800 \n",
    "        pred_fire = pred.surf_vars[\"fire\"].cpu().numpy().flatten() \n",
    "        pred_fire = np.nan_to_num(pred_fire, nan=0)\n",
    "        pred_fire = (pred_fire > threshold).astype(int)\n",
    "        lab_fire = labels.surf_vars[\"fire\"].cpu().numpy().flatten()\n",
    "        lab_fire = (lab_fire > threshold).astype(int)\n",
    "        \n",
    "        # print(\"lab_fire:\", lab_fire.shape, lab_fire.dtype, lab_fire)\n",
    "        # print(\"pred_fire:\", pred_fire.shape, pred_fire.dtype, pred_fire)\n",
    "        # print(len(np.unique(lab_fire)))\n",
    "        # print((np.unique(lab_fire)))\n",
    "        # print(len(np.unique(pred_fire)))\n",
    "        # print((np.unique(pred_fire)))\n",
    "\n",
    "        # Assume `preds` and `labels` are your predicted and true grids (flattened for metrics)\n",
    "        # pred_fire = pred_fire.cpu().numpy().flatten()\n",
    "        # lab_fire = lab_fire.cpu().numpy().flatten()\n",
    "        # pred_fire = pred_fire.numpy().flatten()\n",
    "        # lab_fire = lab_fire.numpy().flatten()\n",
    "\n",
    "        # Compute metrics\n",
    "        accuracy += accuracy_score(lab_fire, pred_fire)\n",
    "        precision += precision_score(lab_fire, pred_fire, zero_division=1)\n",
    "        recall += recall_score(lab_fire, pred_fire, zero_division=1)\n",
    "        f1 += f1_score(lab_fire, pred_fire, zero_division=1)\n",
    "        iou += jaccard_score(lab_fire, pred_fire)\n",
    "        # total_samples += labels.size(0)\n",
    "        total_samples += 1\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"IoU: {iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same code but with visalizaztions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "in getitem feature: [0. 1.]\n",
      "in getitem label: [0 1]\n",
      "Accuracy: 56.8897\n",
      "Precision: 0.2784\n",
      "Recall: 13.6826\n",
      "F1 Score: 0.5448\n",
      "IoU: 0.2735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score\n",
    "\n",
    "accuracy = 0\n",
    "precision = 0\n",
    "recall = 0\n",
    "f1 = 0\n",
    "iou = 0\n",
    "total_samples = 0\n",
    "\n",
    "threshold = 0.5 \n",
    "\n",
    "# Initialize an array to hold the sum of predicted fires for visualization\n",
    "pred_grid = np.zeros((720, 1440))\n",
    "lab_grid = np.zeros((720, 1440))\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient computations\n",
    "    # for batch in dataloader_test:\n",
    "    for batch in dataloader_test:        \n",
    "        features, labels = batch  # Ensure your Dataset and collate function return the right format\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        features = features.to(device)\n",
    "        \n",
    "        pred = model.forward(features)\n",
    "        \n",
    "        # flatten turns 720, 1440 into 1036800 \n",
    "        pred_fire = pred.surf_vars[\"fire\"].cpu().numpy().reshape(720, 1440)\n",
    "        pred_fire = np.nan_to_num(pred_fire, nan=0)\n",
    "        pred_fire = (pred_fire > threshold).astype(int)\n",
    "        lab_fire = labels.surf_vars[\"fire\"].cpu().numpy().reshape(720, 1440)\n",
    "        lab_fire = (lab_fire > threshold).astype(int)\n",
    "\n",
    "        # adding to grid\n",
    "        pred_grid += pred_fire\n",
    "        lab_grid += lab_fire\n",
    "\n",
    "        # flattening fr fr\n",
    "        pred_fire = pred_fire.flatten()\n",
    "        lab_fire = lab_fire.flatten()\n",
    "\n",
    "        # Compute metrics\n",
    "        accuracy += accuracy_score(lab_fire, pred_fire)\n",
    "        precision += precision_score(lab_fire, pred_fire, zero_division=1)\n",
    "        recall += recall_score(lab_fire, pred_fire, zero_division=1)\n",
    "        f1 += f1_score(lab_fire, pred_fire, zero_division=1)\n",
    "        iou += jaccard_score(lab_fire, pred_fire)\n",
    "        # total_samples += labels.size(0)\n",
    "        total_samples += 1\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"IoU: {iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0. ...  2.  0. 68.]\n",
      " [ 0.  0.  5. ...  0.  6. 40.]\n",
      " [ 2. 31.  0. ... 37.  0. 73.]\n",
      " ...\n",
      " [ 1.  8.  3. ... 15.  3. 18.]\n",
      " [60.  1.  0. ...  3.  0. 59.]\n",
      " [41. 70.  1. ... 71.  3. 49.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0 1 0 ... 1 0 1]\n",
      " [0 0 1 ... 0 1 1]\n",
      " [1 1 0 ... 1 0 1]\n",
      " ...\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 0 ... 1 0 1]\n",
      " [1 1 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(pred_grid)\n",
    "print(lab_grid)\n",
    "\n",
    "pred_grid_flat = (pred_grid > threshold).astype(int)\n",
    "print(pred_grid_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#plotting\n",
    "fig, axes  = plt.subplots(1, 2, figsize = (16,8))\n",
    "axes[0].imshow(pred_grid, cmap = 'hot', interpolation = 'nearest')\n",
    "axes[0].set_title('pred fires')\n",
    "axes[0].set_xlabel('longitude')\n",
    "axes[0].set_ylabel('latitude')\n",
    "axes[0].colorbar = fig.colorbar(axes[0].images[0], ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "axes[1].imshow(lab_grid, cmap = 'hot', interpolation = 'nearest')\n",
    "axes[1].set_title('lab fires')\n",
    "axes[1].set_xlabel('longitude')\n",
    "axes[1].set_ylabel('latitude')\n",
    "axes[1].colorbar = fig.colorbar(axes[1].images[0], ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "\n",
    "# plt.colorbar(label='Number of predictions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"aurora_fire_weights_all.pth\")\n",
    "\n",
    "### see aws id for missing line\n",
    "# bucket_name = 'globfire-gooddata'\n",
    "# s3.upload_file(\"aurora_fire_weights.pth\", bucket_name, \"aurora_fire_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArQeaY0b8iht"
   },
   "outputs": [],
   "source": [
    "from aurora import Aurora\n",
    "\n",
    "model = Aurora(\n",
    "    use_lora=False,  # Model was not fine-tuned.\n",
    "    autocast=True,  # Use AMP.\n",
    ")\n",
    "model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-pretrained.ckpt\")\n",
    "\n",
    "batch = ...  # Load some data.\n",
    "\n",
    "model = model.cuda()\n",
    "model.train()\n",
    "model.configure_activation_checkpointing()\n",
    "\n",
    "pred = model.forward(batch)\n",
    "loss = ...\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trying to see if thing works with generic aah data 721 - 720 check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "static_vars_ds = xr.open_dataset(f\"../{download_path}/static/static.nc\", engine=\"netcdf4\")\n",
    "surf_vars_ds = xr.open_dataset(f\"../{download_path}/fle/surf_2015-01-04.nc\", engine=\"netcdf4\")\n",
    "atmos_vars_ds = xr.open_dataset(f\"../{download_path}/atmospheric/201501/atmospheric_20150104.nc\", engine=\"netcdf4\")\n",
    "\n",
    "\n",
    "i = 0  # Select this time index in the downloaded data.\n",
    "\n",
    "batch3 = Batch(\n",
    "    surf_vars={\n",
    "        # First select time points `i` and `i - 1`. Afterwards, `[None]` inserts a\n",
    "        # batch dimension of size one.\n",
    "        \"2t\": torch.from_numpy(surf_vars_ds[\"t2m\"].values[[i - 1, i]][None]),\n",
    "        \"10u\": torch.from_numpy(surf_vars_ds[\"u10\"].values[[i - 1, i]][None]),\n",
    "        \"10v\": torch.from_numpy(surf_vars_ds[\"v10\"].values[[i - 1, i]][None]),\n",
    "        \"msl\": torch.from_numpy(surf_vars_ds[\"msl\"].values[[i - 1, i]][None])\n",
    "    },\n",
    "    static_vars={\n",
    "        # The static variables are constant, so we just get them for the first time.\n",
    "        \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "        \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "        \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "    },\n",
    "    atmos_vars={\n",
    "        \"t\": torch.from_numpy(atmos_vars_ds[\"t\"].values[[i - 1, i]][None]),\n",
    "        \"u\": torch.from_numpy(atmos_vars_ds[\"u\"].values[[i - 1, i]][None]),\n",
    "        \"v\": torch.from_numpy(atmos_vars_ds[\"v\"].values[[i - 1, i]][None]),\n",
    "        \"q\": torch.from_numpy(atmos_vars_ds[\"q\"].values[[i - 1, i]][None]),\n",
    "        \"z\": torch.from_numpy(atmos_vars_ds[\"z\"].values[[i - 1, i]][None])\n",
    "    },\n",
    "    metadata=Metadata(\n",
    "        lat=torch.from_numpy(surf_vars_ds.latitude.values),\n",
    "        lon=torch.from_numpy(surf_vars_ds.longitude.values),\n",
    "        # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "        # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "        # one value for every batch element.\n",
    "        time=(surf_vars_ds.valid_time.values.astype(\"datetime64[s]\").tolist()[i],),\n",
    "        atmos_levels=tuple(int(level) for level in atmos_vars_ds.pressure_level.values),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0  # Select this time index in the downloaded data.\n",
    "\n",
    "batch4 = Batch(\n",
    "    surf_vars={\n",
    "        # First select time points `i` and `i - 1`. Afterwards, `[None]` inserts a\n",
    "        # batch dimension of size one.\n",
    "        \"2t\": torch.from_numpy(surf_comb[\"t2m\"].values[[i - 1, i]][None]),\n",
    "        \"10u\": torch.from_numpy(surf_comb[\"u10\"].values[[i - 1, i]][None]),\n",
    "        \"10v\": torch.from_numpy(surf_comb[\"v10\"].values[[i - 1, i]][None]),\n",
    "        \"msl\": torch.from_numpy(surf_comb[\"msl\"].values[[i - 1, i]][None]),\n",
    "    },\n",
    "    static_vars={\n",
    "        # The static variables are constant, so we just get them for the first time.\n",
    "        \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "        \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "        \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "    },\n",
    "    atmos_vars={\n",
    "        \"t\": torch.from_numpy(atmos_comb[\"t\"].values[[i - 1, i]][None]),\n",
    "        \"u\": torch.from_numpy(atmos_comb[\"u\"].values[[i - 1, i]][None]),\n",
    "        \"v\": torch.from_numpy(atmos_comb[\"v\"].values[[i - 1, i]][None]),\n",
    "        \"q\": torch.from_numpy(atmos_comb[\"q\"].values[[i - 1, i]][None]),\n",
    "        \"z\": torch.from_numpy(atmos_comb[\"z\"].values[[i - 1, i]][None]),\n",
    "    },\n",
    "    metadata=Metadata(\n",
    "        lat=torch.from_numpy(surf_comb.latitude.values),\n",
    "        lon=torch.from_numpy(surf_comb.longitude.values),\n",
    "        # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "        # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "        # one value for every batch element.\n",
    "        time=(surf_comb.valid_time.values.astype(\"datetime64[s]\").tolist()[i],),\n",
    "        atmos_levels=tuple(int(level) for level in atmos_comb.pressure_level.values),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurora import Aurora, rollout\n",
    "\n",
    "model2 = Aurora(use_lora=False)  # The pretrained version does not use LoRA.\n",
    "model2.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-pretrained.ckpt\")\n",
    "\n",
    "model2.eval()\n",
    "model2 = model2.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.inference_mode():\n",
    "    preds = [pred.to(\"cpu\") for pred in rollout(model2, batch4, steps=2)]\n",
    "\n",
    "model2 = model2.to(\"cpu\")\n",
    "\n",
    "# torch.stack(list(pred.surf_vars.values())).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[1].surf_vars['2t'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
